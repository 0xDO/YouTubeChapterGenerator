In his video, "Robotics and the Future of AI," David Shapiro discusses the recent advancements in robotics technology and how they are integrating with large language models. He cites the example of SayCan, which uses large language models to plan actions and figure out what it can do through affordances. He predicts that this will lead to robots becoming more sophisticated and able to hold long-term conversations. He also discusses the company Engineer Arts, which has integrated GPT3 with their robot platform to enable open-ended conversations. Shapiro concludes that AGI will be realized slowly and in degrees, and that we don't need full AGI in order to create useful and dangerous robots.

We are in the midst of an exciting time in the development of artificial cognition, as large language models are being integrated with robotic platforms. This has the potential to create systems that are able to think and solve problems in ways that are similar to humans.

One of the challenges in this area is how to make these systems smarter or faster, and able to solve more complex problems. This is where cognitive architectures come in. These are systems that are designed to simulate or replicate the workings of the human mind.

One example of a cognitive architecture is the Amica robot, which is being developed with the aim of integrating it with a robotic operating system. This will allow the robot to carry out tasks in a more human-like way.

Another example is the gpt3 language model. This is a system that is designed to be used in data centers, and is capable of handling large amounts of data.

As these systems continue to be developed, it will be interesting to see how they are used in robotic platforms and how they evolve over time.