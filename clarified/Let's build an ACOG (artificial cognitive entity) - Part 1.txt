Artificial cognitive entities (ACOGs) are a type of artificial intelligence that focuses on replicating the workings of the human mind. In this video, we will be focusing on the inner loop of an ACOG, which deals with thoughts, planning, and memories. We will also be discussing the nexus, or shared database, which acts as the ACOG's stream of consciousness.

Neuroscience plays a vital role in understanding how ACOGs work. In particular, the study of cognitive control helps us to understand how the ACOG can focus on the right task at hand. The book "On Task" by David Bader is a great resource for learning about cognitive control.

The brain is made up of repeating circuits that mostly do the same thing, but they also vote on what to do. This voting process is known as consensus. Implementing consensus in an ACOG is a crucial step in making it smarter and more efficient.

In conclusion, the inner loop and nexus of an ACOG are essential components of its artificial intelligence. By understanding how these components work, we can create smarter and more efficient ACOGs.

The primary theme of this book is just how little information your brain actually integrates. The bandwidth between different sections of our brain is very, very low and we're talking about like measured in kilobits a second, not megabits or gigabits. So it's like, okay, well, if you're only talking about kilobits a second, is is our brain's bandwidth for like sensory input and and thought and output? How do we get so much done right if if if our memories are very sparse?

Right. So, to use computer science terms, our memories are sparse representations in that like if you were to represent it as a matrix, it's mostly zeros with just a few values here and there. It's like, okay, well, how do we get so much done if our memories and thoughts and sense and sensations are all sparse?

Um, really good book. This has also kind of reinforced my idea that actually we can represent all thought with natural language. That's a perfectly good medium to represent what's going on in the head. We don't need anything abstract like vectors, although you can, but the interpretability of using natural language is there.

Um, and then finally, fandoms in the brain. This was the my very first like neuroscience book. I read it or I saw I saw the documentary way back like 20 years ago. Um, but yeah, great book. Um, both both of ramachandran's books that I've got here, phantoms in the brain and um and the telltale brain, both are look at it through the lens of neurology and neuroscience. So you learn a lot about the brain when it breaks.

Okay, all that said, let's go over some architectures make sure we get this out of the way so you can there we go. Okay, you can still see me, but you can see the screen. Okay, so this is the most basic architecture where we've got the nexus which in this case the simplest implementation is literally just a folder of text files. It's a list of inputs, outputs, thoughts, sensations, etc.

Um, and then the inner loop which in um in this one, so basically what I was trying to do here is create a home home device that I could talk to. The inner loop is literally just um one python loop. Um, let's see which one was it? I think it was this guy. Um, well true, yeah. So basically here's the loop for for d and dossier list which the dossier list is just a list of prompts. Um, do this. Uh, so yeah, that's it. Run the prompt. Load some load some uh well first I guess stack some memories. Load the prompt and then do it again. So while true, so here's one loop and then here's the nested loop. Um, yeah, that's what I mean by inner loop. You're looking at it right here. So we're going to recreate this, but we're going to change it a little bit because of some of the insights that I had.

Okay, so this is the most basic model. The outer loop, I'm not as interested in robotics. I used to think that I was if you want to know how the outer loop would look, go look up Google's flamingo. Um, let's see, Google flamingo robot. I think there's a good youtube video. Yeah, researchers have developed a technique that enabled. Yep. So basically um flamingo integrates large language models with robotics. So I'm not going to be working on that this they got this handled right. This is the outer loop where it's just how do you integrate natural language, large language models or nlp and robotics. That is what the outer loop is. I'm not as concerned about that. I care about cognition.

Um, okay, so this is one possibility. What are the other possibilities? Well, humans, as you may or may not know, if you are a human who is watching this. Um, we think that we have things like unconscious or or subconscious minds. Um, and then when you look at other disorders like dissociative identity disorder, um, your brain actually can have multiple personalities in one head. And so then there's like you've got your shadow self, your super ego, your inner child, whatever. You've got all these archetypes in your head. So that indicates the possibility of multiple minds in one brain. So what if you have instead of one nexus, what if you have two? What if you have your inner loop which is your conscious mind and then you have an unconscious loop that does like whatever our unconscious does. So from a neuroscience perspective, 90% of what your brain does is unconscious. Um, so there's other stuff going on behind the scenes. Um, and so this leads to a possibility where there's a second you know, or more. There might be. There might be dozens or hundreds of little nexuses in our brains where thoughts are accumulated or or sensations or signals are accumulated.

And in fact, if you look at the connectivity of the brain, um, it's a huge mess. There are a lot of of little focus points, concentration points where signals converge and then distribute again. Um, so in order to create a full-scale brain or artificial cognition, we're probably going to need multiple loops and multiple concentration points. Now, if each if each concentration point is as simple as a folder of you know text files, that's not that complicated. And if each of these loops is only as complicated as a wild true statement and then a nested for loop, that's not that complicated either. So if if that if that's all that it takes to create you know a full sentient machine or a functionally sentient machine, um, that leads to some other possibilities. So let's see like, okay, what if you have one outer loop and then you have multiple mines interacting with that outer loop. So you know how if you get an impulse to like reach out for something and then something stops your hand so that in that that you're you you get that like arrested idea like where it's like, okay, I'm gonna go do this and then you stop yourself and you can feel like that cognitive dissonance in your head because there's you know there's the impulse to do something and then the impulse not to do it or the inhibition. So that is where a thousand brains comes in. So we only have one body to control, but our brain has hundreds or thousands or tens of thousands of similar circuits all trying to control that one body. And so what if we had a thousand robots or a million robots or a trillion robots. And each one of those robots had a brain that was a little bit different from the other ones. And so you would have this kind of like swarm intelligence or hive mind where there's just this mass of you know robots all trying to control the same thing. And so that's one possibility.

Another possibility is what if you have multiple loops but each loop is you know doing a different thing. So you might have one loop that's just dedicated to like walking and then another loop that's dedicated to like talking and then another loop that's dedicated to like, you know, sensing the environment and then another loop that's dedicated to like, you know, controlling the arms and the hands. And so you might have all these different loops all working in parallel. And so that's another possibility. And then finally, what if you have, you know, multiple loops but each loop is, you know, doing the same thing. So you might have one loop that's dedicated to, you know, walking and then another loop that's dedicated to, you know, talking and then another loop that's dedicated to, you know, sensing the environment. And so you might have all these different loops all working in parallel, but each one is, you know, doing the same thing.

So those are just some possibilities. And, you know, there's probably endless possibilities. But, you know, those are just some that I thought of.

One possible architecture for an artificial cognitive entity is to have an outer loop with multiple mines fighting over what to do. The outer loop would take a consensus from the different mines, for example deciding whether or not to grab a hot pot. This would work because each mind would have different models, prompts, and architectures, operating at different speeds with different specializations and strengths.

If someone has dissociative identity disorder, it is possible that their brain has lost the ability to keep track of these different cells and has fragmented. This is where Jungian psychology comes into play.

Another possibility is to have multiple loops interacting with one nexus. This would be similar to the way that robotic hosts in the show Westworld have their consciousness erased of anything they're not supposed to see. This model could be used for self-censorship, for example deleting the possibility of a robot stabbing its human owner from its consciousness.

A third possibility is to have one nexus with multiple loops interacting with it. This would allow for different loops to be responsible for different tasks. For example, one loop could be responsible for safety while another loop handles self-censorship.

In order to get started coding, we can create a public experiment called "Cog Experiment 0-1". We can add a README file and a license, and then clone the project down. We can start with a medical question answering experiment, copying over the git ignore and open API key.

From there, we can create our nexus and start adding thoughts to it. We can also add a voice component so that our artificial cognitive entity can communicate with us. Once we have the basic framework in place, we can start working on more advanced features like inhibition and self-censorship.

In order to effectively understand and remember something, we need to ask ourselves three key questions: what are we doing, what should we be doing, and what does this mean? These questions help to establish what is relevant and what is not, allowing us to prioritize and focus on the most important information.

When it comes to artificial intelligence, one of the key challenges is how to get the AI to ask these sorts of questions itself. This is where the concept of a "meta prompt" comes in. A meta prompt is a prompt that is generated by another AI, which in turn is used to generate the input for the next prompt.

For example, let's say we have a passage of text that we want to understand. We can use a meta prompt to generate a list of questions that we can then use to search for relevant information. Once we have the answers to these questions, we can then use them to write a detailed paragraph explaining what we've learned.

This system of using AI to generate questions and then use those questions to generate more AI-based questions can be used to effectively create a powerful feedback loop of learning. It is an efficient way to get AI to not only understand complex concepts but also to improve its own understanding over time.

Shoulder impingement is a condition in which the shoulder joint does not move as freely as it should. This can be caused by a variety of things, including damage to the rotator cuff, bursitis, or arthritis. Treatment for shoulder impingement typically includes a combination of physical therapy, exercises, and rest. In some cases, surgery may be necessary.

Blockchain is good for sequential transactions because it creates a list of sequential transactions that cannot be manipulated. This is relevant for artificial intelligence (AI) companions because they need to have their memories encrypted in a way that guarantees they cannot be selectively deleted.

Time is not experienced linearly by people with certain disorders like narcissism or PTSD. This is why it is important to have every memory time-stamped and cryptographically verified in a blockchain. This way, our AI can have a linear sense of time and be accountable for its actions.

The search index in our AI's brain works by associating memories with current events. This allows the AI to forget what it came into a room for and to remember again. This is all inspired by how our own brains work.

The cognitive control loop is a series of prompts that our AI uses to think about what it is doing and what it should be thinking about. This includes tasks like metacognition (thinking about one's own thoughts) and anticipation (predicting the implications of current events).

The core objective functions of our AI are to reduce suffering, increase prosperity, and increase understanding. This is the moral compass that steers the AI's actions.

In this video, I explain how to create an artificial cognitive entity, or "acog." This is the framework for the inner loop of our artificial cognitive entity. I go through each line of code, explaining what it does. This video is probably best for people who are already familiar with programming.