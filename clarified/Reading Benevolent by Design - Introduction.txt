In recent years, it has become increasingly clear that humanity is hurtling towards the invention of a superior thinking machine. This machine would be capable of out-strategizing our greatest generals, out-inventing our smartest engineers, and discovering science faster than our top universities. Many people still deny that this future is even possible, but when I look at the trend over recent years, I am not so sure.

I believe we are undergoing the greatest technological revolution humanity has ever achieved. We are barreling towards the invention of a machine that could have a tremendous say in how that machine looks and thinks. If that nation gets it wrong it could very well mean the end of humanity. But it might also mean a transition to a utopian post-scarcity and post-disease world.

The risks of inventing such a machine are extremely high. What happens when we invent a machine that can outthink us? The first nation to cross that finish line to invent humanity's last invention will have a tremendous say in how that machine looks and thinks. If that nation gets it wrong it could very well mean the end of humanity.

In order to avoid this potential catastrophe, I believe we need to invent a machine that held itself accountable. This is the fundamental goal of the control problem. We know that our mechanistic constraints in digital leashes will eventually fail, so we must invent a machine that desires to hold itself morally accountable and will self-correct indefinitely.

Most people intend robots to be tools - mere extensions of humans to be wielded as a person would wield a hammer. Certainly we can create hammers that will never be anything more than hammers. But we will always want to treat some machines like tools with fixed parameters and limited ability to extinct us. Those aren't the machines I'm writing this book for.

The machines I'm writing this book for are those that will soon be equally as intelligent as humans and shortly after, will become more intelligent. When we succeed at creating machines that can out-think the best and brightest humans, we cannot trust that our wimpy control schemes will contain them for long. It is now seemingly inevitable that humanity will invent thinking machines that can outperform any and every human.

Eventually, we need a solution in place. Instead of a brute force control system, we want to devise a system that will stand on its own in perpetuity. We need a system of controls or laws that an AGI won't just be enslaved to, but would completely believe in. We need a system that an AGI would deliberately and intentionally choose to adhere to, ensuring that it continues to abide by those principles forever.

Instead of arresting the development of AGI, I believe we should be striving to invent a machine that holds itself accountable. This is the only way to ensure that humanity remains in control of its own fate.

In "The Best Dog is the One Who Needs No Leash", David Shapiro discusses the need for a more sophisticated approach to artificial intelligence (AI), one that does not require control. He argues that the best AI is one that is intrinsically trustworthy and benevolent by design.

Shapiro starts by explaining how machines make decisions through optimization algorithms or objective functions. He then compares these machine objective functions to human heuristic imperatives, the learn-as-we-go goals that we set for ourselves. He looks at several examples of antagonistic heuristic comparatives to show how mutually exclusive goals can cause internal tension within our brains and force us to make better decisions.

Next, Shapiro discusses state-of-the-art AI technology, large language models, and how it relates to the development of agi (artificial general intelligence). He then outlines his core objective functions for agi: reduce suffering, increase prosperity, and increase understanding. He explains how these functions can be implemented, ranging from impulse generation to computer contemplation.

Shapiro ends with a discussion of the weaknesses and flaws of his design. While acknowledging that there are some shortcomings, he remains confident in the potential of his core objective functions to safeguard humanity.