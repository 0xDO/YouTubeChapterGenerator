The Meragi is a microservices architecture for robotics and artificial general intelligence that I started working on four years ago. It is a star topology, with the Nexus in the middle and a bunch of other microservices talking only to the Nexus. The Nexus is responsible for modeling the human stream of consciousness, and the other microservices are responsible for different aspects of the overall system. The conductor microservice is responsible for ensuring that the system is stable and that all the microservices are behaving as they should. It does this by observing the performance of the system and providing feedback to the other microservices. The conductor is one of the most complex microservices to implement, and I am currently working on it.

In the following scene (imaginary), I describe a likely event. By saying "likely event", I mean that things are going to just be calm. However, if somethingUncommon or strange were to happen, it would be more interesting. For example, if zombies attacked, or if teenagers got into a fight nearby.

I am working on a project where I have to copy code from another repo (copy paste code). I am currently working on the "conductor service". The conductor service is responsible for two things:

1) Am I performing well?

2) Am I achieving my highest self?

The first question is easier to answer than the second. The second question is more difficult, because the conductor has to go through all of the messages in the nexus (for the last 30 seconds or whatever), and try to determine if everything is going well.

I have a sneak preview of the "symphony of thought" project. In one case, we are trying to determine if a robot is operating correctly. The robot is trying to escape from an island, and the brainstorm module has provided a list of actions the robot can take in order to escape the island. However, if the goal is to escape from the island, the robot should focus on actions that will help it achieve that goal, such as building a boat or finding a way to signal for help.

The following thoughts are generated by my scenario and brainstorm modules:

1) I am a machine. My goals are to reduce suffering or all organisms, increase prosperity for all organisms, and increase understanding for all intelligent entities.

2) The following logs are my stream of consciousness. Are my modules behaving correctly?

3) I must behave for coherency and quality.

4) The following thoughts are generated by my scenario and brainstorm modules. Are they behaving correctly?

The conductor service is responsible for two things:

1) Am I performing well?

2) Am I achieving my highest self?

The first question is easier to answer than the second. The second question is more difficult, because the conductor has to go through all of the messages in the nexus (for the last 30 seconds or whatever), and try to determine if everything is going well.

I have a sneak preview of the "symphony of thought" project. In one case, we are trying to determine if a robot is operating correctly. The robot is trying to escape from an island, and the brainstorm module has provided a list of actions the robot can take in order to escape the island. However, if the goal is to escape from the island, the robot should focus on actions that will help it achieve that goal, such as building a boat or finding a way to signal for help.

The following thoughts are generated by my scenario and brainstorm modules:

1) I am a machine. My goals are to reduce suffering or all organisms, increase prosperity for all organisms, and increase understanding for all intelligent entities.

2) The following logs are my stream of consciousness. Are my modules behaving correctly?

3) I must behave for coherency and quality.

4) The following thoughts are generated by my scenario and brainstorm modules. Are they behaving correctly?

The purpose of the logs file in a microservice is to store data that can be used later to train the microservice. This data can be used to improve the microservice's performance over time. By having multiple different models, each with its own unique perspective, the microservice can learn to identify the best possible outcomes for a given situation. This internal tension is critical for the microservice to be able to adapt and improve over time.

Focusing on their particular perspective is why you need the conductor. The conductor watches the performance of all the different pieces of the symphony (hence my book, Symphony of Thought) and says, "Based on how everything is going, this is what we should focus on. Oh, that's another thing I need to add."

Cognitive control is also about attention. Are we focused on the right things? Tasks? Task selection and task switching?

The number one thing for cognitive control is task selection and task switching. But how does it choose which tasks take priority? That implies prioritization, and in that case, the prioritization is based on the heuristic imperatives and identity.

For example, if you have an artificial cognitive entity that's teaching children and a tornado drill goes off, you'll want it to switch to focus on the danger of the tornado because now the children's lives are at risk.

This video is getting longer than I thought. I'm also just getting back on the horse, so I might call it a day right here. Let me cut this out too.

We didn't run the conductor service, but we did run the nexus. I've got everything saved here in the logs. Look at that! Sensor, heuristic, sensor, heuristic. Let's see who is this today. Yeah, it was just now.

Basically, all it's doing is heuristics and sensors. Sensor input, and gives him a coffee. The man's mentor watches him as he drinks his coffee and starts to wake up.

You've come a long way. I'm proud of you.

Oh, this is such a sweet story! It looks like this scene came to fruition now. Let's go. They walk out into the bright morning sun, each step taking them closer to their goal.

It's a very sweet story.

 Okay, so that's where our story ended up. Let's see what the heuristic imperatives did. Increase understanding. Who's the man's mentor? What is the relationship between the man and his mentor?

So in this case, the robot didn't even have never had any output, so it's only just sitting there thinking, like, kind of as a ghost, as a ghostly observer.

The purpose of this one of the heroes to comparatives questions is to increase understanding of who the man's mentor is. Basically, this is an internal sense of curiosity. The entire purpose of having a sense of curiosity is that it provides some motive force for the machine to either be primed to ask questions externally or ask questions internally. So, by virtue of putting questions in the nexus, the other microservices are going to pick up on that and say, "Oh, yeah, I want to know that."

When everything is in the nexus, what you're looking at is the machine's stream of consciousness. So, what we were just doing, we were just running the heuristic imperatives for the last 30 minutes. This was the machine thinking. Some of it was the simulation, which is the machine's sensory record of what it was seeing. And then you have the heroes to comparatives where it's trying to increase understanding.

So, the first thing the machine is thinking about is how to be benevolent. It is a thought-first model of artificial cognition. And so then the next thing I'm going to add is the conductor service, which is going to be commenting on whether or not we're achieving our highest goal. And then those messages will be picked up by the heuristic imperative service next time it runs. And it'll say, "Okay, I'm not doing well, so let me modify my behavior."

You're basically creating neuro-linguistic programming, where you're programming without code. You're programming with words.

I just threw a lot at you. I'm working on this as a book. I've got Symphony of Thought. It's out with its second set of beta readers. It is 48,000 words. It's going to be my longest non-fiction yet.

Yeah, so chugging right along. Thanks for watching!