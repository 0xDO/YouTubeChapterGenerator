There has been a lot of consternation lately about the state of AI art. In particular, there is concern about what is in the training data for these AI art generators. I have seen firsthand that subreddits are starting to ban AI art, and that Twitter has purged most unstable diffusion tags.

There is a legitimate concern for copyright law existing artists, but this is a whole new space. It is impossible to put the genie back in the bottle. There are also countless examples throughout history of when new technologies cause a lot of pain and grumpiness. For example, the VCR (video copying and recording) was met with a lot of backlash when it was first introduced.

The reason that unstable diffusion was banned so quickly is actually credit card companies. Credit card companies stand behind all internet transactions, and if they see child porn or other illegal content, they will shut down the site.

Other illegal content may be taken down by payment processors if it tarnishes their reputation. A great documentary on this topic is available on the comments section of this blog.

The breaking mechanism refers to the process of change that occurs throughout history. One group of people always wants change while another group fights it. This is simply human nature. The process is working itself out and should not be legislated against.

Lexica is a search engine that allows you to find stable diffusion and mid-journey or just ai art generations and the prompts used to create them. Some of the images and prompts are disturbing.

Transform X is a conference hosted by scale AI that is coming up at the end of the month. There are going to be a lot of speakers from all the big players, such as Google, Waymo, OpenAI, IBM, and Berkeley AI Lab.

Forefront AI is a small and growing NLP company. The founder is he's a great guy and he will answer questions. NLP Cloud is another group that is a little bit larger. They have a lot of models and use cases ready to go. Their documentation is definitely up to snuff.

Check out Scale.com events slash transform x for more information on the conference.

The Cloud NLP platform offers a variety of pre-trained models, including one called "GPT Neo-X." I haven't used it myself yet, but some people on the Discord chat swear by it. They say it performs just as well as the models in OpenAI's GPT3 "instruct" series, but it's open source. I believe it's trained on Alan AI's "instruct" series.

So there you have it. Thanks for watching. This is my second "state of the industry" address, so thanks for watching, and I'll check in with you next time.