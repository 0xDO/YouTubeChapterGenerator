all right hey everybody it's been an exciting day and I am getting some fresh air to clear my mind and think about it so taking a big step back let's think about what Sam mman leaving open AI means for AGI so Sam Alman is going to Microsoft he's first and foremost a business guy but he's a very charismatic leader and he's got a Clear Vision which you might say okay well he's not the technical expert uh so therefore it doesn't matter but that's not necessarily how things work as a inspirational technology leader myself with some of my various projects like the ace framework and the and the uh agent swarm project I will say that that Charisma and vision are absolutely a really critical set of skills and abilities to organize labor um and and to inspire people to get things done and to reach higher um and so that is kind of like it's kind of like the same thing as like why Captain peard was such an inspiration leader is because like collectively the crew that he attracted the level of expertise is what made him the leader that he was and vice versa it's a two-way street so that's one thing to keep in mind about Sam Alman you know good bad ugly um you know I've I've of course voiced some some criticisms of his approach and his mentality in the past nobody's perfect but as more information comes out it seems like the the characterization that Ilia Suk made a just a grievous miscalculation um is kind of an accurate uh representation of what happened and I think I think a shortly after I made my last video something like 80% of open AI signed a letter like asking the board to resign and to bring Sam back Sam's not coming back so open AI is going to Crater um and as they said like open AI is nothing without its people well if 80% of the people leave some of them are going to go to Microsoft some of them are going elsewhere I've heard on the Grapevine that many of them have have already been applying um and of course you know Talent poaching is something you can expect so I think that I think that open AI is just dead like dead in the water um I'm not sure how the how the uh how the contract Works between Microsoft and open aai but basically if open AI can't deliver I suspect that Microsoft has like right of first refusal to to purchase their their assets um which if that's the case then you know the net effect is Sam Alman still gets most of open AI just under the Microsoft Banner which of course like that runs directly contrary to a lot of stuff that he has said about incentives and and that sort of thing so it's like yeah that kind of proves the point of like okay you said something about nonprofit and all sorts of things like that so yeah Money Talks though that's that's like Follow The Money Money Talks um now I I obviously I don't I don't know whether or not Sam is doing it for the money but other people sure as heck are um and that's kind of like where having your head in the clouds and saying oh well money won't matter in the future Money Matters today bro so okay so that's kind of setting the stage but what does this mean for AGI as I've said uh recently um one something like 90 plus perc of all the research that's leading to AGI is open source it's done by universities like Stanford it's done by Microsoft research which publishes it open source it's done by meta which does a lot of Open Source so like a majority of the research that's leading to AGI is public anyways who cares um now that being said the big companies are the ones with the money to train the frontier models they're the ones and it's not just it's not just the training cost it's the hundreds of employees of of top talent some of whom are are paid millions of dollars per year to also build those those those Frontier models so that's not to say that like oh well just because 90% of the research is open source anyone can do it that's not the case um it's kind of like the same reason that um when India and China first started uh industrializing very quickly they kept having buildings and and bridges collapse because they they they had technically studied you know uh civil engineering in the west but they didn't have the in-house expertise and so they followed you know they followed the blueprint and the textbook but they didn't have the the firsthand experience to know how to do it right um and so likewise I think that you'll probably see the same kind of thing where that last 10% is the expertise that only people that have have appr proven track record will be able to do it so the where the talent goes this is going to result in kind of what what you might think of as a massive amount of cross-pollination because now that open AI it looks to me it seems like a foregone conclusion that they're going to implode um it seems like it's a foregone conclusion that they are going to um get scattered to the Four Winds which means that that expertise that last 10% is going to go to Apple it's going to go to meta it's going to go to Google it's going to go to Microsoft um and and Nvidia and everywhere else but also the thing is is yes some of these people are experts and and some of them are like there there is definitely a scarcity of like Frontier Model experts in the world you know there might be a thousand Frontier Model experts in the world there might be fewer than that I don't know um so but at at the same time you know two or three or four years ago there were not a thousand Frontier Model experts these can be like you can create more experts over time by investing in the education and finding the people with the right skills and the right you know disposition and then ensuring that they get the experience um so that's that's going to be it's it's a slow thing because the number of people who are just intrinsically capable like they have the math background they have the the intellect the wit to learn these things is going to be limited but the the the simple fact of the matter is there will be more uh Frontier Model experts this time next year than there are right now so that is that is a temporary constraint um it's still a major constraint just like uh you know how there's always going to be you know the top 100 Experts of you know nuclear energy or quantum physics in the world there's always going to be kind of a a gradient or a set of ranks um but it's not it just because open AI implodes doesn't mean that those experts suddenly don't exist and in fact the cross-pollination that we're going to see means I think that they're going to get even more valuable experience and they're all going to be even smarter because now they're going to get they're going to they're going to leave the open AI uh culture and go get experience at other tech companies like Microsoft like Google Deep Mind like meta like apple and so that cross-pollination is going to be good not just for the companies but the individuals the actual experts who are driving um the the the thing forward and so net effect like like I said I'm I'm I'm pretty confident that this is actually good for both AGI and for safety cuz again open AI under Ilia SS was very tightfisted and and he El s said many times this needs to remain close Source it needs to be a very small group of people um and it's coming out that like he had a very kind of peculiar take on this stuff and I have been like open source open source open and now I'm not saying like release the weights for everything you know all Frontier models up front but I think this this proves uh by and large that uh that this information wants to spread there is a tremendous amount of energy and money behind it and all of the other companies are going to benefit and I think that in this respect this will benefit all of us Downstream and I know a lot of you are very skeptical about Mega corporations and I agree which is why I talk about a new social contract where we need to empower the government to also uh police these companies a little bit better um but that's a whole other topic of conversation I hope you're not hearing the uh siren in the background there's a highway just a quarter mile that way um anyways so okay the fire truck is gone there is no one on the road right now I don't know why they were blaring their horns and Sirens like that anyways so all right so principle number one there's there's plenty of AI experts and there's going to be more and they're going to learn from the from these changes that's net effect a good thing they're going to get exposed to different cultures of safety of corporate cultures of profit motives which is a good thing because they're going to learn um so there's going to be more Frontier Model like AGI experts and they're going to be better AGI experts because of this that's a good thing um between all the different competitors and their different uh dispositions towards open source Google deepmind publishes plenty of Open Source stuff about Frontier models likewise for meta likewise for Microsoft uh open aai was probably the least open source of all of them honestly other than Apple cuz you know apple is like they're patent crazy um but I think that this is going to be a good thing because now there's going to be a lot more cross collaboration ation between all the different shops and what I mean by that is is is you know cuz some some of the papers like you'll have authors from Google Deep Mind and Microsoft research um I think that we're going to start seeing a little bit more of that I hope um because they're going to realize we are stronger together and uh also all these people all the former the the open open AI alums they all know each other they're going to still talk right they're they're of course going to sign ndas um so there there's certain things that they won't be able to share but they have those relationships they have those social relationships which will um help kind of stitch Silicon Valley together um even if not on an official capacity on an unofficial capacity because this whole thing is just too compelling this is one of the things that I think everyone agrees on is that the ramp up to AGI and super intelligence and whatever else is coming is far too important um for one closed group to do and it's far too compelling to ignore um and so the the kind of the last point that I'll leave you with is the implosion of open AI proves to me unequivocally that one small group cannot handle this should not handle it it never should have been just up to open a open AI it was it should never have been the responsibility of a small cloer group to say we are the only ones that can do this we are the only ones who can possibly do this responsibly that was very vain um and that was very uh kind of um shortsighted let's say that's I'll I I'll use that term to be charitable was very shortsighted and it was very vain um and so I think that this just shows like yeah if you want Democratic inputs to AI it needs to be a conversation not just with open AI it needs to be a conversation of all of the tech companies it needs to be a conversation with all of all of us humans all of US citizens all the governments that's what democratic inputs means it's not some tech solution where you have some you know form or whatever like Democratic inputs means building consensus through public discourse right like ancient Athens figured this out with the Agra right like you go and and you have your public debates which is why I'm here on YouTube honestly so all right well that's my rant for the day my second rant for the day um yeah thanks for watching cheers have a good one etc etc