hey folks I wanted to just kind of Riff and free associate on the sudden and surprise firing of Sam Alman yesterday let me know if you like this new format mostly I just want to get my thoughts out there so Sam Alman was very suddenly uh fired by the board of directors of open Ai and a few people have released statements since then um there was a leaked transcript of an internal company call with ilot setk it seems like Ilia was maybe I don't want to say the ring leader but kind of the the Catalyst but it also sounds like that he wasn't alone um and so the the tldr of that is that uh there was increasing tension between the direction that Sam was taking the company and the scientific and safety directions that uh others wanted to go shortly after that uh Greg Brockman released a statement or a tweet basically saying that he quit because he wasn't happy about the uh the power move or I'm not sure how he characterized it exactly uh but there was some rumors that that Greg and Sam kind of formed a kind of a Duo that reinforced each other and so it because I saw in the original announcement that Greg uh stepped down as part of this I kind of felt like there was a power Dynamic there uh so this means that two key players not just one but Sam Alman and Greg both leaving um uh it sounds like Greg kind of quit um even though they wanted him to stay so Greg is gone Sam is gone Mera moradi is stepping up as the CEO and this is a really interesting move because merera is she's much more grounded she has uh she doesn't have her head in the clouds quite as much as Sam uh and so you know Sam is like you know we're going to make AGI and it's going to be the best thing ever and you know he said things like you know open AI is going to or AI is going to generate aund trillion of value and open AI is going to capture most of it and so on and so forth um now again like I don't think that those are incorrect things uh well I do think it's a little bit uh was a little bit silly to think that open AI a company with only 600 people could capture 100 trillion dollars worth of value um there's no way in heck that Microsoft and Amazon and meta would allow a single company to carve off The Lion Share of that space so one of the initial things that I thought and I texted a few people like is this a power move by Microsoft but apparently Microsoft was just as shocked by this develop you know it took Microsoft by surprise does this set the stage for open AI to be acquired by Microsoft a lot of folks think no that that would actually still go against open ai's Charter um and their mission and it sounds like with Ilia taking the helm who's more of a pure scientist uh I do think that it is unlikely um that that open AI will be acquired by Microsoft but looking at like kind of not not even reading the tea leaves just looking at what people are talking about uh you know some of the big players it sounds like the the the primary tension with Sam was uh it twofold one that Sam was uh making it too commercial too fast so you know kind of throwing caution to the wind and and focusing on making as much money as possible and there is an instrumental goal for that because I think part of the uh part of the agreement with Microsoft is once they generate hundred billion they're free to go uh from Microsoft and please correct me if I'm wrong but that's my understanding of their their uh their negotiation their current like contract or whatever with Microsoft so there is a there is benefit to having open aai generate more money more Revenue quickly rather than slowly because the sooner that they make that investment uh or or make that contribution to Microsoft and then can break free and then continue doing their own thing uh now basically open AI kicked off the current race condition that we're in with chat GPT and then like you know put the put the floor the pedal to the floor and you know they're still out ahead of Google they're out ahead of meta um and so it's like you know kind of the way that I characterize it earlier this year is that open aai you know Sam Alman was going around telling people oh you need to regulate us and it's like basically stop us from from expanding the fire that we started um and so that is you know like open AI started this fire you know cuz Transformers are nothing new Google came up with it back in like what 2015 2016 um and so but it was it was and Google was happy to continue working on it at a slower Pace now a lot of us are already using this AI stuff on a daily basis um if it wasn't valuable we wouldn't be using it so with that in mind you know like yes it's good that the that the narrative has been Advanced and that the Overton window is Shifting but at the same time safety was very in in hindsight becoming less and less of a priority uh at open Ai and it sounds like it was uh under the direction of Sam um and so in this respect if if the board of directors is reasserting itself saying like we need more safety this is probably going to be a good thing overall now is this going to slow down their research who knows I mean the way that I think about it is that once you have maximum safety like you like you know slow as smooth smooth as fast you know that's kind of how I think of it um and as an automation engineer that's kind of that that's just the philosophy that you use because if you if you do shoty automation it breaks stuff and creates even more work for you uh you know you you botch a a firmware upgrade you botch you know server upgrades um you offline stuff one you lose your job but you know things go offline but if you take your time and make sure that your automation is safe and robust then once you hit go it's s set and forget so the the the profit motive ver versus safety seems like one of the primary tensions but another thing that was brought up in some of these tweets and leaked transcripts was that um that Sam or maybe maybe not the tweets but other people commenting on it I don't remember where but uh the observation that Sam was focusing on building his own Fame and when you look at the fact that he just spent the last 6 months uh talking to world leaders you know he talked to Congress multiple times he talked to Business Leaders he talked to presidents around the world uh he just got the the Steven Hawking award at what was it Cambridge uh so he was very much focused on building up his personal brand um which is like I I called that like in a video a few weeks ago you know because he told Congress he's like I don't have any Financial motivation here I don't have any incentive but I'm like yeah that's that's complete like hogwash because he was building up his personal brand he was building up his his personal Fame and his social status uh which you know whe whether or not you're financially motivated all humans are motivated by some level of status some marker of success whether it is you know physical Financial commercial uh celebrity or whatever and so like you know he was on time magazines you know 100 you know 100 top people of AI so this is like how am I trying to say this I wonder if he was oblivious to his own motivations or if he was very conscientiously trying to make himself as famous as possible or if it was just you know he was just high on the ride and just like yeah let's keep going you know um I don't know but so now I want to Pivot that's what happened great water under the bridge open AI is still there Microsoft is still there so what does this mean like where is this going what's going to change I had a a a few people ask me like okay does this change your estimate on when we're going to get AGI looking at the fact that open AI is reasserting itself in terms of safety I think that this could slow down AGI but again uh slow as smooth smooth as fast so you know once you once you understand safety that actually allows you to go faster I actually outlined this in my book benevolent by Design and I've talked about it extensively over the last few months is that once you have something that is perfectly safe you don't need to supervise it which means that if you figure out safety first and then you build something that you can trust to do the alignment research to do the model research that will actually probably accelerate it further faster in the long run in the short term by focusing on safety and stability and reliability first it will appear to go slower but this is part of what I call the automation Paradox which is that and some people corrected say that's the parto principle I disagree the PTO principle is a little bit different um but anyways that's neither here nor there the point being is that with when you're doing something that is analogous to automation or is a kind of automation you have to be thorough and meticulous and rigorous and very systematic in testing every component of an automation system and that's what they've talked about with super alignment their super alignment uh research is they want to automate all the research as much as possible they want to have ai that's doing the data that's doing algorithms it's doing the fine tuning that's doing the alignment that's doing the policy research that sounds like something that came from Ilia so if Ilia gets what Ilia wants now I suspect that they're going to double down on this automation stuff that they're going to that they're going to double down on automating the Safety Research as much as possible getting humans further and further out of the loop just supervising which means that these these engines it's going to be a flywheel so you get this flywheel effect where the better the algorithms the better the data the better the models the faster it goes and the higher quality output it generates and so then once they do that the path from from self-aligning self-correcting fully autonomous AI research because that's I mean that those are the principles that I have been talking about for years um I outlined it in benevolent by Design and a few other places but like you create something that is self-correcting and principle driven and Mission driven and that it understands what it's trying to do and can detect it own fault then you just you push the button and you watch the flywheel go faster and faster so it might delay it a little bit but I think that in the long run like I said this is going to steepen the curve for a little while so like I've talked about like are we on an exponential growth curve are we on a sigmoid growth curve I think that this might in the short term and when I say short term I mean like six months this might be the six month pause that Max techark was asking for um But like after that 6 months of of focusing exclusively on safety or not maybe not exclusively but like let's say that open AI doubles or triples or quadruples their effort on safety they figure that out then it's like you know all bets are off for how fast you can go after that um so that's kind of my prediction for where it's going to go um in terms of the new leadership Mira Mora she might stick around as CEO um she is a very well composed very dignified very intelligent woman um I think she's probably qualified for it so then it's just matter of how well she performs the fact that this decision was made this quickly um meant that it was kind of a an activist board move because they didn't have someone um you know ready waiting in the wings um apparently Meera was informed only the night before that this move was going to happen so she had less than 24 hours to prepare um to step up as CEO um that's not much time to think and provide an answer um but you know again like strange times interesting uh extreme times call for Extreme Measures uh it remains to be seen like how she'll uh how she'll perform but having watched her interviews she's much more like a mainstream Silicon Valley CEO like her demeanor and her Outlook and her addiction is much more similar to people like Sachi nadela than Sam so taking a step back it's not uncommon for startups to go through transitions so like Sam Alman having come from y combinator is he's a scrappy startup CEO that's what he does that's what he's learned for the last 10 or 15 years um and what what often happens and I've had multiple people explain this to me um is that uh startups go through phases and so you have like the initial like crazy growth phase and then you transition to a more mature company and so I'm I think that this was probably just going to happen anyways because Sam mman has never led a large Enterprise um he's not a large Enterprise CEO he doesn't have that experience now I don't know that mea does but now they're going from you know the so when you go from like eight employees to 600 that's one growth phase when you go from 600 to 6,000 that is an entirely different domain that is an entirely different kind of company um and so that's a different that's a different phase of open AI uh you know overarching trajectory are they going to go to 6,000 employees who knows I don't discount the possibility that open AI might decide uh that it would be better to just fully be integrated with Microsoft again as people pointed out to me that very well could violate their Charter um so who knows and again if Ilia is in charge I think that uh I think that they're reasserting their mission to create AGI and create it safely um and merging with Microsoft probably wouldn't uh serve uh that goal that's I I don't think that's likely to happen but I still won't discount the possibility um or or it's maybe it's possible that they'll sell off some aspects of of open AI um who knows but you know chat GPT generates a bunch of revenue for them so maybe it doesn't make sense for them to sell it off who knows anyways those are kind of my highlevel thoughts as to where things are going and what this changes in the grand scheme of things I don't think it changes too much um but the more that I think about it the more I do a gut check and talk with people the more I think that that this is actually a really good move and that this will be better for everyone in the long run it'll be better for open AI um because you don't have a CEO that's trying to make his own image as big as possible um you don't have a CEO that's pulling it in the direction of profit first um now you've got a board that's reasserting itself and has had a major shakeup and that is going to focus more on the science and safety side um so I think that I think that this is going to be net net effect is a very good thing for everyone if it does create a slight delay I'm not worried about that because again once you understand all the principles of safety once you understand all the principles of of self-correction and and and self-alignment um that enables you to go much faster in the long run um you know that's how I in back in my automation days I was able to create things that automated not just one data center but four data centers um and and was responsible for you know many thousands of of servers Mission critical servers and pedabytes worth of data because once you create something that is that robust and you can trust it like the the machine that you can trust that doesn't need any oversight that just says like hey boss I did the thing it worked and it's like great good job you get a gold star um that's the that's the Paradigm that that you want to see in any Automation and especially in AI AGI and super intelligence and super alignment so um yeah that's kind of that's kind of my my decomposition of what's going on thanks for watching um yeah I hope you got a lot out of this let me know what you think in the comments have a good have a good weekend cheers every