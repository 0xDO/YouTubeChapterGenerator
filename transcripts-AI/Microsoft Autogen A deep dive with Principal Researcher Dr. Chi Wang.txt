Chi thanks for jumping on it's a pleasure to meet you um I was really excited yeah you're you're quite welcome um obviously like autogen is all the rage right now uh very popular there's lots and lots of videos being made about autogen um but before we dive into that I was wondering if you could just tell me a little bit more about your time at Microsoft as a principal researcher like how did you get into that position what's it been like uh yeah so just give me the give me the story oh thank you yeah my name is CH I um principal researcher at Microsoft research uh I joined long time ago joined about nine years ago in Microsoft uh and I've been working on many different projects apparently now I'm focus on autogen and before that I worked on Automated machine learning machine learning for systems uh data science data analytics data mining so quite quite a a lot of different things um and uh some of the work is more like on the theoretical set as side and some of them is more to the system side um and yeah being uh focusing on autogen recently uh so very happy to be here and excellent yeah you know with with all the progress that's been made on large language models and working on assistants and and agents um and then of course working on agents working with other agents let me ask kind of a big question like what was the Genesis behind autogen like did how did how how was that project proposed like how like how did it come together like what was the theoretical work behind it and and how did you get from from zero to where you are today yeah so that's that's very interesting question and uh to fully answer that question I need to tell a long story um but let me first tell you a short one short answer is like with this big kind of um opportunities with larg models so powerful techniques at MSR we want to ask the question like what is the future right we won't be forward looking we won't be futuristic uh kind of take the S leadership and because the one of the famous quote from the founder of micros research Rec sh that um the best science will be indistinguishable from Magic so that's what like the level of ambition we have um so we ask the question what is the future of AI applications and how do we Empower every developer to build them um yeah so that's a fundamental driving question uh and now uh a longer version of the answer is that I started from as I told you before I work on autogen I worked on Automated machine learning uh which is another open source project called flamm um Flo is a solution for automating uh model selection hyper Prim tuning essentially blackbox optimation uh to navigate large sear space without knowing the gradient um so uh this is very powerful technique but that was uh started before the Ling model uh T takes the storm um and when chat gbt released right and that's a big big kind of upgrade of the model capabilities uh and so I started working on uh similar problem as Ultimate Machine learning I started working on inference hyper parameter tuning for these chb models uh for example how do you select the best model how do you select the right prompt temperature and all the other inference parameters so that you can maximize the utility from the models while minimizing your cost um so that's that's initial work on on this uh Direction uh and when gb4 is released that's another big upgrade of level capabilities so then start really to uh ask the question okay um if we kind of want to bring the best power of the model and to really solve really difficult problems what should be the right way to do it an agent is apparently a very powerful notion uh it's another kind of level of the automation as opposed to the previous Automation in the uh 20 machine learning work I did um so yeah so that that's where where they started um and uh uh of course uh it's a whole new area no of agent is not new it's um has been there for a long time and I remember back in college as works on some like game competition like building agents that can play games with each other can compete but at that time we were using many of Ru based methods we had lot of deal with a lot of corner cases and so on so it's not not viable it's it's a good notion but not viable and this um L model is especially the op models really make it viable and um a reality that we can build new software based on and to to to study this new area we we kind of need to think many things from scratch to and try to uh to think try to take some of the first principles and what is the right approach and uh basically leverage every lesson we learn from the previous projects previous experience uh but try to add them build this um one um multi-agent framework that is really generic uh can can support diverse applications um yeah so um there are many different examples of sources like ofir I I can give you uh but in one nutshell it's like using everything I learned and also take every feedback I received um from everyone and and and inspirate on that and so that's how we come here today yeah excellent yeah no I mean there's a lot to unpack there you know it it's fascinating to me that it started as sort of like an like autom ml like op like automating the optimization and I can see how going to like optimizing prompts and optimizing hyperparameters and and parameter tuning could then lead to the agents especially like you said if if the idea is thinking to the Future like what is the Sci-Fi version of enabling uh application development in the future so I wanted to follow up with a kind of a a two-part question so in the most basic level what is autogen but more specifically what is the vision like what is it that you're trying to solve with autogen right now yeah um so yeah in one word autogen is the multiagent AI framework uh and especially focusing on multi-agent conversations so that we can connect models tools and human inputs uh together to solve complex tasks there can be multiple ways to understand this uh so one way is to understand as a uh programming framework um for developers to build applications easily with some simple and unified abstraction uh so that they don't need to worry too much about the low Lev details but can focus on uh how to define agents how to get them to uh work work with each other and eventually reach the goal it can also be understood as a tool to kind of um scale up scale up the power of L models and U makes them even more useful by connecting with other tools non model tools uh or human collaborators um and uh kind of scale up the both the complexity of problem they can solve the the degree of automation uh to some extent yeah this is kind of relatively abstract introduction but if you think about it about uh how how people use it it's quite simple uh so when developers build applications with autogen it basically boils down to Two Steps step one is to Define agents and step two is to get them talk so as simple as that um yeah so we'll try to try to make it very useful um and generic but on the other hand we want have a very simple interface for what people use it yeah that I mean that that's exactly the vision that that I kind of settled on for my like hierarchical autonomous agent swarm idea um but I I don't want to talk I don't want to make it about about that um right now I just it's fascinating that we kind of converged on a very similar like principle like let's make the deployment of software uh as as easy as possible and so there's two things that you mentioned like layers of abstraction because that I think that's a really good intuitive way of thinking about it like in the same way that a python interpreter was a layer of abstraction from compiled code and then maybe language models are another layer of abstraction where it's natural language interface this could be seen as again another layer of abstraction where instead of looking at the interacting with the language model directly it is now a type of interpreter but this is you know the agents and the the multi-agent framework on top of it that that's my intuition do you agree with that or disagree or like how do you think of of those layers of abstraction yeah that's very fantastic question uh the abstraction uh is indeed at the higher level of the agent abstraction um it's unifies a number of different things uh one is lar models uh so when we use a single instance of lar model we usually do prompt engineering uh and try to give some input uh text and get some output text out of it um this agent abstraction uh can encapsulate that underneath and provide more intuitive way to think of it as agent that can converse with you uh to not not just one single uh text completion inference anymore it can can do tasks uh can proess some states and continue to take your feedback and uh produce more refined result and so on right so so that's a uh larang model based agent uh but there are two two other kinds of uh backends uh that can be encapsulated one is uh you can think of that as programming language or tool based uh agent which doesn't use LR model but they can still perform uh very useful actions uh they can do code execution for example or you can execute predefined functions or it can basically execute any programming logic you you you uh uh Define there uh and third one is the human kind of backed agents uh so these agents can be considered as some kind of user proxy um so when when uh they need human input uh the human can take over and uh just play just um participate the multi-agent workflow as one of Agents so you can think about several agents some of them are larger and model based some are tool based others are like human based uh so that you know uh they can just cooperate together through a very natural interface which is a conversational uh interface um yeah so that's kind of layer of abstraction we provide yeah yeah no I I appreciate that and I'm reminded of uh during I think it was the ignite keynote speech Sachi Nadella said you know think of it as a reasoning engine and a natural language interface and that was like the two simplest ways to think of of uh generative AI at least the language side um so the other topic that I wanted to ask about to kind of dig into was thinking about it as a kind of automation um so you know there's there's the agent based there's the tools based but then overall kind of and this is this is a messaging kind of a framing that I've adopted when talking to people is and of course it's an oversimplification but AI is one AI is not new like machine learning has been around for a while this is just a step function in terms of capabilities that models have um but it's also just the simplest way to think about it from a production standpoint or from a software standpoint is it's a new suite of automation tools right that's kind of how I think of it is that is that a fair characterization or or is there something that I'm missing from that because I do feel like there might be something missing or that or something that that characterization doesn't fully convey but it is it is still fundamentally new automation right is um so if we if you try to understand it from automation point of view uh I think agent is um fundamentally a automation concept uh the automation is more like about instead of giving every detailed uh instructions using Code let's say step one do this step two do do that using from prely defined uh program language specification now we can uh make some more vague uh specification using like natural language specification say I want a company certain task and could the agent do it for me so and and and then underneath the agent needs to kind of um bre down a big complex task into maybe smaller uh solvable tasks and until each task can be uh comen is solved by a simple inference uh and produce some produce a corresponding code to solve that task and then eventually we need to recompose them all of these intermediate steps and get the final output back so that is one part of the automation story um and another part of it is um think about is automating some tasks that human had to do autogen really uh started with some very simple kind of automation uh just about how you use chb um you as a human uh need to ask questions and chb give you some answer sometimes they give you the code and then human need to take that code right and uh run it by yourself uh and get some result if it's not correct you send it back and uh JT give you some R for the game uh and here in this kind of interaction humans do need to do a lot of work but but many of the work can be automated uh if we we use agents and uh even even some kind of human feedback um like not non non code if say if I U don't like the results I uh but I know my preferences I will tell tell it uh such as change the chart uh from using dollar to percentage that kind of requirement uh or uh teach me this um lesson uh teach me about math but using a concrete money example right so that those kind of requirements can be somewhat automated uh using all different ways some sometimes we can use larger models uh sometimes we can use some um retrieve argumented approach to inform retrieval to get the uh knowledge um from from somewhere that's that kind of another kind of interesting automation we can make yeah yeah no and and with in that those automation stories cuz you know some of the examples uh what was it how did you say it like a kind of a vague specification right a natural language specification that is not quite as rigorous as you know software development might have required in the past um and then of course with these models they have the ability to um to kind of think through it or you know break it break it down into steps so with with all that and some of the work that I have found is or or some of the problems that I've confronted because it can think in general principles it does know a lot about software development and and I mean the language models know a lot about a lot of things so with with respect to autogen and kind of getting to where you're at today what are some of the biggest challenges that you've overcome so far or that you haven't overcome maybe that would be more interesting story yeah sure I can talk about both for what we have uh overcome um I think we have kind of figure out the abstraction I told you earlier uh about how to unify these different types of uh capabilities uh different uh ways of uh making them work together uh we have found one uh very simple interface that can accommodate a variety of different communication inter uh communication patterns so one example is the so there are s examples one is the simple like onetoone conversation uh another is um hierarchical chat like suppose One agent is more sit on top and talk to several sub agents it manages and they can be nested structure hierarchal structure and uh another example is um multiple oneon-one draw the chat so there's no one that is um thally sit on top everyone talks every else uh but it's um multiple one one which are connected so I talk to you you talk to Katie Katy talk to me uh this kind of triangle or multiple joint chat and there's also a group chat meaning um it's not one one TR anymore so everybody send messages to everyone else so we we see each other's message uh and there's a hidden group chat manager which does this kind of work so architectural wise it's it's still like one chat but uh on the surface we can create the a um experience uh that simulates the group chat and they can Nest it the chat in some way like for example we can start with a oneone conversation now uh but at some time I decide to consult KY uh so I will hold on my current conversation and have some conversation with her and then uh after I finish the conversation with her I get back and continue the conversation with you so that is kind of n chat I believe that essentially you have the building blocks right now right uh these are some very common building blocks and we we compose them together in different ways uh we can build really complex uh workflows in general so any any arbit complex uh communication patterns can be essentially build up with this building blocks but I think that is what we have a che and we have also many examples for different applications of using these different type of uh patterns um this is another thing second thing we figure out and the third thing I think is uh the ability to take human input and human control in a very natural way and I told you earlier it's like every agent can be configured to have to to enable the human input or disable that uh depending on like what you need uh and also you can decide the uh type of involvement from Human you can you can you can take over every time or you can only itivity chiming at certain time um so that's a very useful feature because when you U develop this automation initially you don't know which step is easy to automate um and which step is necessary for human to to to get in um so you can start from the more like uh human in Loop way and when you figure out that one step is you can confidently automate then you can gradually reduce your human temperation right so uh this this come in is um is is very useful for like doing all the experiments and figure out the right way um and make sure still make sure that uh human has a control when when they need to okay this is a third thing I think one more thing is the modularity and reusability of the agents uh that is very important design part of it um so make sure like if you develop one useful agent uh in a different application you could either directly use or S modify it or extend uh from different ways and um make sure the re hard workk is not lost I think that's also very uh important thing when we uh like work together to to build more and more complex applications these are a number of things I think we're uh kind of figure out uh and there are indeed a lot of challenges we we haven't and yeah shall we get to that part yeah no I just want to reflect on um you know some of the some of the processes that you outlined like removing humans from the loop step by step back in my time as an automation engineer that's exactly what I would do is like okay I can you know I write a script that does one part easily cool now what what's the next part and then where do I have to jump in um and some of the some of the other problems that you solv like knowing so this this I think is really important because some of the members of my team and my projects have found the same thing is that knowing when to be quiet yeah knowing when not to jump in is is in many respects more important because you don't want to end up with too much noise or wasted tokens um so that's really fascinating before before we talk about problems you haven't overcome can you talk about some insights from that like that inhibition signal or or you know keeping the the noise lower what were what were the key insights there like how did you test that and figure it out and have you do you have any general principles for anyone else building agents yeah this is very good question uh this is also related to another uh question about uh when do you add agents uh to provide a feedback and when uh that is not helpful right uh because I assume the noise you you're talking about is uh when you add more agents to serve as for example critics uh um or agents that um try to try to Define the other what the other agent is doing right they they serve as a as a channel to PR feedback and some but sometimes that feedback can be misleading and actually prevent uh the original agent doing the right thing um yeah we do observe that and also U it's not like the more agents the better it's not necessary that for example uh if you use gbd4 uh as the backend for a assistant agent for large number of problems uh you need a simple two agent workflow one assistant agent another us user proxy agent yeah probably I need to explain what the US pration is uh basically it's it refers to what I meant earlier about automating some of the work that human does for example using tools to execute pass on code or run some predefined functions so here you if you use one TBT assistant agent to suggest solution such as code or function and use another proxy to ex them and just uh provide the feedback back and forth you can solve large number of problems uh very well and some of them are are also complicated can involve multiple steps but if you use gbt 3.5 uh turbo then it's much less uh to to work in in this way so uh adding more agents will be much more helpful and for even for gbd4 when you the problem complexity goes to above above certain level uh it it stops to follow uh the main instructions because the the trick for one single agent work is actually put a lot of careful instructions uh in the system message and make it know how to deal with some complex situations but we notied that uh if you put too many of them even for dd4 and for complex tasks it will forget start to forget these instructions and uh um not not do things as you want otherwise otherwise you can just give it simple uh instruction to say try your try your best to solve the hardest problem and it be done it's not we're not there yet in future we may this makes me want to bring up one interesting kind of law we a few of us came up called kabuchi law the the law has some similarity with it's analogy of the con law in software engineering I'm not sure if you're I'm familiar with that notion no so com basically saying um the complexity of of the software uh or the architecture of the software is a reflection of the organization that makes the software that build the software um okay makes sense yeah so our gab law says the com model compacity will affect the mod compan or capability we change the topology of the ideal multi-agent solution it's a summarization of what I mentioned earlier if you use more prop model then the likely you can use simpler topology of multi-agents to solve a complex task and and and vice versa and also I think we need more more research to understand this better is it's not soloft I'm seeing like people trying all different kind of uh apologies or communication patterns for different applications they're very creative um and uh what we Haden to figure out is what is the best poy uh and for for particular model and for particular application in a kind of a very clear way to that question we're not not here and uh this is one of actually Big Challenge or big important problem we want to solve yeah thanks yeah no that I mean well first thanks for sharing some of those those critical insights and so I guess the the general principle is uh the the smarter the smarter the underpinning you know model the simpler the topology can be because the more complex the instructions can be and the more complex the tasks that an individual agent can carry out uh it when saying it out loud it seems kind of obvious but that's a good good rule to generalize so yeah I guess let's let's pivot into what are some of the what are some of the remaining problems what are your biggest challenges that you um either are working on or are going to be down the road um you mentioned topologies like figuring out like what is the correct topology and of course like I can imagine that it's a moving Target because as the underlying models change almost on a monthly basis you get new new and different capabilities that kind of yeah maybe send you back to the drawing board sometimes yeah this is why like having a framework that is ver versatile that is flexible to do the experiments is so uh crucial to kind of do the fast adaptation right as the model moves as Pro prompting techniques uh advances and as you know more more small model specialized models are available they they will probably also change a lot of about uh um was the best way to build that applications um yeah so this is I think the big value of autogen um and for like unsolved research questions uh there are some some concrete ones I can give a few examples uh one is about this uh decompensation problem uh as we mentioned earlier uh we want want to be able to achieve a state where the human can uh human only needs to specify relatively big Ambi ambitious goal um and under underneath we want the agent to be able to decompose that into solvable problems probably multiple layers um and eventually recompose it and uh I mean solve each sh them and recompose it and during this process We There are situation where the human need to provide like clarifications because the initial one can be ambigous uh and we want the human to only provide the necess minimal kind of necessary clarifications and instructions and that's agent to figure out the the rest of them um that is a big challenge because uh as we if we want to solve more complex problems we have to have a principal way to to do this um and the second question also Rel to this is uh as we solve bigger and bigger problems how do we do proper validation of the intermediate results uh because we don't do that uh it's possible that the agent will kind of stick to some wrong intermediate results and then just keep keep doing keep wasting right their work uh and a certain time um people need to PR validation or use agent to do self validation that's that's hard but but ideal ideal way um to do it so uh we need we need probably need to some formal language or formal way uh to do this uh proper validation uh so that the automation can indeed happen in in a way that human is desires um yeah so these are some just two kind of concrete pieces of like problems yeah in in my project we almost started in the reverse where we started with oversight of steering and oversight and supervision um so I'm curious what's what's your perception or or uh research or findings with respect to because you already mentioned like having having like an assistant agent um and then also having uh kind of a top down hierarchical agent where you've got you know subordinates what do you think about like kind of my intuition that working towards having you know supervisors steering QA you know quality assurance kind of Agents throughout the network of agents that are capable of providing some of that feedback that you mentioned earlier is that kind of the direction that you're going or is that have you tried that and it didn't work or like what are what are your thoughts in terms of having some of those specialized roles or personas um as a way to help along yeah uh there are some examples uh that uh work pretty well I can share with some of them one is the three agent setup to solve a multi-agent coding scenario the application is for supply chain optimization it's done by another MSR team but that that solution in my view is quite generic it's not restri due to that special application and the setup is like there's it's a hierarchical setup there's a commander on top there's a writer uh to is responsible in writing python code the the agent can also have access to some proi tools like organization tools and the other sub agent is actually safeguard Safeguard is in charge of reviewing code safety so the the way it works is that Commander receives some users question it will first ask the writer to write the code uh and after receiving code it ask the CFT guard to review the code for safety and only if the safety criteria is met it will run the code and send result back otherwise it will just ask the writer to reite the code and this can go back and forth because there can be errors so when you debug uh the writer can can do that until the result is uh correct the the writer comes back with the final answer natural Lang answer to some result and the Comm return that to user um so this is this is almost the quite simple kind of multi agent setup uh but very effective in that application Almost 100% uh correct every time one one kind of lesson is if if we merge the capability of the writer and Safeguard into one agent it doesn't work that well especially in the Cod safety part um so we have the experiment in our in our paper uh we found that if you m them than the uh accuracy for detecting code safety issue will drop significantly uh both for gb4 and GB3 by interval but more C for 3.5 so this kind of a hint that um one AG and um if you ask to both suggest a solution and check the solution suggested by itself uh have a have a bias right and but we separate them and also uh prevent them to talk to each other kind of make them work in the adversarial setting it it does it better so that is one one observation uh but we also have other kind of uh scenarios where we do involve every agent in one group chat so everyone also sees others message and can can reply back uh it's also works sometimes for for other tasks uh for example a crique to suggest a visualization uh criteria for visualization task you can have one agent write code another to criticize it sort of works but um my intuition still that if if you put every agent work together always uh in in a group chat it may not always work because they may have a tendency to agree with each other um instead of trying hard to challenge I would say it's Case by case for um for different applications because uh there's also some um like benefit of of do using this group chat because it's relatively simple uh you don't need to do very hard about handling the message uh separation uh you can put uh simply Define your agents and put them in the group chat and get them running quickly so that's one benefit group chat and see many people are using that approach uh but just to be careful that uh it it may not always work because of the limitations of the models yeah so that's that's really fascinating to me and and my you know my intuition was the same but it's it's it's interesting to have that validation from another perspective so it's almost like even though the underlying model is gp4 running all of the agents or 3.5 Turbo there's still an effect like a positive effect from using division of labor right which the division of labor comes from you know the history of of human work um and so just taking a moment obviously these models do not work like human brains but when you have an agent with a very specific task and Mission and and set of success criteria that that effectiveness of division of labor is it still helps even though it's just activating the latent capability ities within the same underpinning model um and then another intuition that I or a principle that I want to um reiterate is the idea that in some cases group work makes sense but in some cases it doesn't it's almost like the same difference um in humans where you know the power of introverts right doing doing solo work on your own versus doing collaborative group work so again not saying that they're operating like humans but it's really interesting to see some of these parallels between multi-agent work um and and the nature of human labor so yeah very very fascinating um and it's it's it's interesting because in some of the conversations that I've had and some of the observations that I've made it's almost like what we're doing with these agent these groups of Agents is recreating like a corporation like you might have like a CEO or a boss or supervisor and then you have the coder and then the QA yeah um so it's it's very similar structure so do you have any other uh major insights or lessons that that you think are either recently or super valuable that you want to share with other researchers or or that you would recommend sure sure that there are so many of them I I can give give a few examples um one thing is uh the chat the conversation perspective I mentioned earlier that uh TR is a big inspiration right it's certainly for for many people but for me there's a personal story uh but what what specific got from it um it's a reminder of something I learned back in my college from a professor uh who told me that um conversation is a provable way of making a good progress of learning uh I I don't remember exact quote of that but uh it's roughly that so uh basically he's trying to say conversation is a a very powerful form of either learning or making progress or Etc uh that many people didn't re realize it's how important it is and there are some theoretical root there um so so that's one reason I'm so kind of um so sure or so um I so much believe in using conversation as the Central medium uh of the multi-agent interface again I know there's a science although I I didn't uh have time to find out like which reference it was but but I know I know that so so it gave me the confidence or the belief yeah this is this is the right thing to do I think one of my collaborate Co coauthors Jim actually found me some some reference from a social social scientist he he mentions something similar to that that yeah uh so this is one I think I think one one lesson um one kind of unique thing that I I I don't think many people have have really they they kind of understand jbt is very powerful and also get a lot of useful experience from from that but but maybe this science part science part of it is is less known so that that's one thing I want to share another inspiration source as as I told you autogen is really inspired by many different things um many uh projects I've worked on before and all the lessons I've learned so another one example is operating system uh so this is also not so obvious uh when we talk about AI why do talk about oping systems uh I think the um the several things I sever inspiration I take from the success of operating systems one is the like the idea of Max maximizing the utility of the most valuable resource you have uh so in in days is like the CPU the GPU uh but I think in the new era of AI uh these powerful logical models is so valuable resource and building a opening system around them uh right Max them their their utility and but give them the necessary peripheral um and do the right coordination you is super critical from the system point of view uh and and also operating system is really you can build a platform that can support many diverse applications on top of that so we need to design a very generic robust kind of system to do that right so these are all the design principles uh we try to use when we design autog and similarly uh the idea of object or programming uh is is very useful um so many developers have very interesting ideas they want to try and develop um and now with this framework that hides a lot of complexity inside the framework they they're able to kind of do the things they want more easily uh that's a part of abstraction I already mentioned the the agent notion automation inspiration the one thing I want to mention is open source right uh ex of Open Source is that it can solve a common problems that Community needs and make is really easy to use right so those are the probably uh most important kind of uh things that can can kind of get good open source adoption and like build something that Community loves right yeah so I think that is one Val L I want to share with all researchers right if you want to get their research uh adopted and uh get more more impact and influence um and through this open source Channel then spend a lot of effort to uh about the usability uh and solving the common problem that many people want um is uh is is what's considering yeah I I have personally found success in giving away as much valuable information and ideas as I can that's what my whole uh YouTube career and computer science career is based on now um so thank you for sharing the those critical insights um so on the topic of operating systems because I'm I'm really glad you brought that up because I started thinking about language models as a component like a new component of an operating system so I'm glad to know that there's some convergence there is that is that kind of the future of autogen is that what you're looking to move towards as kind of being being the operating system or or a major component of a future operating system that that uses you know language models as like kind of the new CPU and maybe retrieval augmented or you some some kind of storage as like the new memory um is that kind of the direction that it's going yeah exactly so it's uh it's my ambition it's what when I started working Auto I discussed with some system systems uh friends uh friends working on the systems I I I told them this idea and yeah it sounds a very ambitious idea to them but uh I can see that some people really like the idea like uh and even some very senior people who give me stronger strong support of this uh he kind of having that idea independently I kind of see that some of the most Visionary people also also realize this and uh definitely we want to pursue pursue for that yeah excellent so taking a big step back just in terms of you know the direction of research you know I think I don't know if it's official but you know the rumor is right now open AI is working on GPT 5 um and then of course Google with g and I and meta like everyone is working on bigger and bigger models now and so we're going to get more capabilities on on this at the same time smaller models are becoming more efficient so sa Nadella announced small language models um coming so that way you know you can probably perform very small cognitive functions but very quickly and efficiently um so what are some of the trends that you see intersecting with like your work around autogen and agents and agent swarms and what I mean I guess to be specific is maybe cost um changing or new capabilities coming like are there any capabilities that you're really looking for that like would would make your job easier what are your thoughts on some of these new capabilities and making making these agent uh you know multi-agent platforms more autonomous or is that a good idea a bad idea so very kind of open-ended question like what do you see coming this time next year yeah uh I think the idea of having specialized models um to perform certain tasks uh in excellent way and in a cheap way is fascinating uh it's it's indeed worth a lot of Investigation for example the some of the hard problems I mentioned earlier about the decomposition recomposition validation it's possible that some specialized model can do this kind of tasks really well we haven't seen that yet but you conceptually that's that sounds like possibility actually I'm pretty surprised we haven't haven't uh found a special model that can solve this so it Mak makes me kind of Wonder uh why right U because this is so such a natural idea that you know if you finding a model that can do certain things uh you should be able to do certain tasks very well and you can just replace one sisic agent with that uh and Al many people are trying that I know either there's some F reason uh we have figure out why it's um not the why we can't do that or we should be able to see that pretty soon right it's I think it's only one of these two possibility because the foral possibility still there because uh the small model it's possible that the small model lacks some very important capability of being functional to perform this hard task because these tasks are not easy right the compensation decompensation problem I think even even the gbd4 model is known to not to be too good at planning right it can do some kind of planning but not perfectly so if you want to get better capability than gb4 in some specialized tasks it's TBD uh is it's to be see whether we can comence that but if if we if we lower the target if you say let's train some small models that can do something is already good at that is much more uh amable I think I already see uh evidence of that so so then it's more like a cost reduction story so that that is I'm pretty sure that that's uh feasible and the the other part about getting better capability than the big model in in some aspect is is to is to be kind of yeah have to hold hold our scientific CU curiosity and see what happens that makes sense we we are almost out of time so I want to I want to respect uh everyone's time um and so I'll just say like you know thank you so much for jumping on and and sharing some of your thoughts I'm super excited to to uh be along for the ride um but yeah before we close um I'll give the give the floor to you is there anything that you'd like to um you know put out in the world any any personal requests or personal hopes um that you want to want to share with uh with a broader audience yes thanks for G me the community to do that uh yeah I want to say that we are still early right at the the new age agent becomes mature software that can can do a lot of things for us uh we want to build the future together with everyone from the community uh so give a a try try to use it for application let us know what's working on what's not uh we are very happy to work together to improve it uh and and answer some of the big important problems as we mentioned and I really want to uh acknowledge that all the contributors starting from the original paper to uh the recent more open source Rees join together and the huge developer Community that's supporting us I really learned a lot from from everyone who has uh used and provided feedback that um people are super super creative I think this is the right way to of solve the hard problems and hope to continue to do that and support support Community Support everyone and for example the the the effort you're you're you're doing with the hierarchical kind of agent swarm right it's it's a it's very good example that uh you're you're making certain bads on certain kind of ways of Mak work uh I'm very curious to see how that experiment goals and if Auto can be of any help uh in this or other consim efforts we'll be uh very happy to kind of support you uh if you need any fature any kind of um useful uh infrastructure support that kind of things uh yes let let us know um yeah absolutely yeah no would be definitely um looking forward to continuing the you know collaboration uh I think that as you said there is a lot of work to do do and there are some limitations you know the the models limitations today are the models limitations there's not not a lot we can do to work around that but um it is just the beginning and that's one thing that I I I'll use the the closing to say is remember where we were a year ago today um chat GPT was probably published just about a year ago um and but before that it was gpt3 GPT 3.5 and the the the distance that we've covered in just the last year is like it is a privilege to be part of one of the greatest shifts that Humanity has ever seen and some days it doesn't feel real and some days it feels a little too real and a little too overwhelming so thank you um she for helping uh make this a reality and spending some time talking with me and thank you to uh Katie for helping put this together and uh yeah so thanks thanks everyone and um yeah uh see you all next time thank you so much I appreciate it