The following is an unstructured video transcript. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: good morning everyone david shapiro here i um i wanted to make a video about fine tuning with gpt3 um at present my most popular video is about fine-tuning gpt3 for a specific task but i wrote a post on the open ai community about just some tips and observations that i had about fine-tuning both from my own experiments but from helping other people so for instance i've been approached by lots of people startups and students wanting to get help with fine tuning and uh you know so hey i can just help everyone so let me give you five tips and misconceptions about fine-tuning gpt3 my first tip is start with normal gpt3 and prompt engineering get good with gpt3 before you jump into fine tuning gpt3 is not like any other tool you've ever used nlp or otherwise it's not like an svm it's not like a regression model it's not even like other neural networks for instance a lot of people jump in thinking assuming that they need fine tuning when they haven't even used gpt3 before and i say jump in give it a test drive it's way more powerful than you think it is and so some people just they have their their old school data science mindset like oh i need i need uh you know a data set i need to you know come up with rules and i'm like just ask it there was one case where um a recent case where someone was trying to scrape dates from unstructured task text and i'm like just ask for the dates you don't need to fine tune anything um pardon me i'm a little bit parched so be drinking my tea while i talk it's still too hot ow um yeah so jump into gpt3 plain vanilla gpt3 is way more powerful than you think it is um it knows a lot more uh it's it's read you know many gigabytes or terabytes of text i don't even know how much data it was trained on i've seen different numbers it depends on who you ask um so it's not like anything else when you when you fine tune gpt3 that's actually transfer learning uh which means you're getting the benefit of most of the learning that it's already got so it doesn't work the way that you think it does unless you've read the papers and played with it um let's see oh another thing this is one of this is a really big misconception is um prompt engineering means you have to be really good at language uh and it's really interesting my partner and i my partner is a getting her master's degree in information science so she bridges the gap between humanities and computer science so if you work with philosophers with writers with digital humanities folks they get it really fast why because they understand language they understand rhetoric they understand using the written word to communicate ideas however you put gpt3 in front of a die hard math first computer science major and they often can't see the language for the math another way of saying that is they they see the algorithm first without seeing the implication of the language and it's really interesting to see that like some people put the language first and some people put the math first so with gpt 3 you don't have to worry about the math so if you came up from you know a hardcore you know computer science algorithmic thinking um that honestly won't help you with using gpt3 and uh so some people ask me like okay well what what what what sorry stuttering um if you've watched some of my other videos you know that i stutter sometimes i don't even identify as a stutterer it just happens sometimes everyone stutters anyways sorry um but i lost my train of thought oh yeah team composition if you want to have a dynamite team using large language models make sure that you've got someone who understands language on your team maybe hire a librarian an english major a philosopher i was working with one startup for a while where they were they all had they all had humanities training they understood philosophy they understood all sorts of other psychology um psychologists get it really well too um and they all they understood it i showed them what gpt3 could do and they're like this is amazing and and i see what you mean like this is capable of philosophical reasoning um and of course you know you show a philosopher that a machine is capable of philosophical reasoning and they're blown away and you show a computer scientist and they're like yeah whatever um it's it's just this really weird dichotomy so higher humanities [Music] so that's that's all that's all within tip number one start with gpt3 plain vanilla number two tip number two building fine tuning data sets is a hundred times more effort than prompt engineering um for that reason alone start with plain vanilla gpt3 it'll carry you way farther than you think it will if you if you take gpt3 to its limits if you say okay i've worked with this tool for months and i can't get it to do what i need it to do then maybe it's time for fine tuning but even then maybe not i'll get into that in a second um but yeah like building fine tuning data sets it's super super hard um let's see now okay let's assume that you've done your homework uh you've decided yes i do need fine-tuning um my first tip is use natural language separators or demarcators to identify where the the prompt begins and the completion uh prompt ends and the completion begins sorry in the open ai documentation they just use like hashtag and while that can work it's semantically meaningless so what i usually do is i will add like just a couple words like if um in my uh in my question generating um uh fine tuning data set i have like here's you know a block of text and then i say like ask questions and then with a with a colon and gpt3 really learns okay that's where the task begins and so just like you know one one to five words giving instructions right at the end of the prompt that helps teach gpt 31 what its task actually is without having to infer what the task is because then you can be very explicit about what its task is but also that it's more semantically meaningful and the reason that semantic meaning is important is

CLEAR ESSAY:

==========

There are a few things to keep in mind when fine-tuning GPT3 for specific tasks. First, it is important to get comfortable with GPT3 before attempting to fine-tune it. This means playing around with it and understanding its capabilities. Second, building fine-tuning data sets is much more difficult and time-consuming than prompt engineering. For this reason, it is important to start with plain vanilla GPT3 and only move on to fine-tuning if absolutely necessary. Finally, when fine-tuning, it is helpful to use natural language separators or demarcators to identify where the task begins and ends. This will help GPT3 learn more effectively.