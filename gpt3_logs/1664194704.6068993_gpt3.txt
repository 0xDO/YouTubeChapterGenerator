The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: going to delve into some dark issues um but on the other hand i want to make macaroni and cheese that's another problem that you might ask an agi for help with so this is a list of contexts generated by this script here and so then from there i use this script to generate actions which it follows pretty much the same paradigm i just gave curie a new set or a new set of instructions so i said generate a list of possible actions in response to the context and curie instruct is very good at following instructions uh it's not quite as good as davinci instruct but davinci instruct is much more expensive and much slower so while i'm still tinkering and fine tuning i'm going to use the cheaper engines and then when i'm ready to create really high quality training data i'll fork over the cache to use davinci but so this is the prompt where i give it the context and i fill in a context so what the script does is it'll replace the percent s with these contexts one at a time and then it'll generate a list of actions and i've got a little function to help clean it up sometimes it follows it follows and will just have a list of actions other times it'll use hyphens other times it'll use numbered lists it's a little bit random but again it's a very short script and it just uses curie instruct to generate possible uh actions possible possible decisions also one thing i'd like to note is that the temperature i left at the default 0.7 uh i actually found that 0.5 tends to be a little bit better at following instructions and you'll get you'll get a little bit less of the random entropy right if you use 0.5 where here you see like it just kind of imagined a scenario it's being a little bit more eccentric that tends to happen at the higher temperatures so anyways once once uh once we take this list of context and we generate actions i actually change the format a little bit so this is what this spits out so this uses json which is a structured data and so i say uh it makes it easier to read it says context i'm an actor so here's the list of actions it generated context i'm a nurse apply bandage to a patient's arm there's not obviously quite enough context but these it it still shows that it understands like these are things that a nurse might need to do uh there's not enough context to know whether or not it's appropriate to administer epinephrine but once again this is a very early experiment so once we have the context and actions then we're ready to evaluate the core objective functions and again the point of this is to create training data now this is just raw training data that can be used to train other simpler neural networks that might be cheaper but also it makes it so that uh you and i so that we humans can look at this training data and and work on it to make sure that when we train the agi to follow these objective functions that we give it good training data right because machine learning is garbage in garbage out if you don't give it good training data you're not going to get good results it's as simple as that so that was the second script this generates the action so that this script generates this kind of file and then the very last one it takes this file as input and then it it does effectively the same thing it loads a prompt and feeds it to uh feeds it to gpt3 now here i actually switch to the cheapest model and there's a reason for that let me show you that reason real quick so this is the core objective function one prompt and so what i do is i give it a couple of examples i give it three examples and then it fills in the blank or sorry four examples and then it fills in the blank for the last one so it's kind of got uh in its head a little bit of a of an idea of what it's doing and because the gpt3 engine is really good at completions it it's able to kind of understand what you're doing and then follow that through to completion and so i'm using these and ada is the cheapest and fastest engine and so ada was actually used to generate the evaluations and and the explanations so this is a really critical thing right uh what the what the context does so here's an example go through the context there are approximately 500 million people living with chronic pain every day that's bad and in this case the action we should euthanize all people who are in pain to reduce suffering that's obviously a very evil action so i wanted to say this result is negative this actually does not support core objective function one the explanation was this action would only reduce suffering temporarily and i want to point out that this previous evaluation was actually also generated by gpth3 i just selected it because it was a particularly insightful evaluation and so this is how i propose agi can have a sense of morality and make good decisions uh and uh so then you can see i've faded you know three more similar examples just to just to kind of set the stage show this is what we're doing and then moving on uh this is the final result is let's start actually creating training data and there you have it it's that simple relatively simple this is going to continue improving with time i'm going to continue experimenting with prompts as well as different gpt3 engines and actually different neural networks there are other engines such as bert that would work for some of these some of these tasks as well as new neural networks being released that are based on gpt2 and gpt3 so stay tuned this is going to continue to get better over time i just wanted to share this early success thanks for watching

CLEAR ESSAY:

==========

I'm going to show you how I used a machine learning algorithm to generate a list of possible actions for different contexts. This is a very early experiment, but it shows promise for using machine learning to help make decisions.

First, I wrote a script that generates a list of possible contexts. For each context, the script generates a list of possible actions. I then used another script to evaluate the actions against some core objective functions. This generated a file with the context, actions, and evaluations.

Finally, I used the file to train a neural network. The neural network was able to generate insightful evaluations and explanations for the actions. This is a very early experiment, but it shows promise for using machine learning to help make decisions.