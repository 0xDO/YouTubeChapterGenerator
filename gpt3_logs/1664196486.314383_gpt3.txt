The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: and choose you know whether you want to use python or terminal um let me close this this is extraneous so basically what this does is it launches it in that virtual environment which you see right here um so that says okay use this version of python to do everything that you're about to do and it should be able to launch uh no 10 okay looks like I need more stuff uh okay final pause again finally got it running I am so sorry I might edit this video to cut out some of the uh some of the garbage okay so it's running um you see the average time per file is going down it's .07 seconds per um per uh per file so that's that's pretty fast um I had to go in and add a Keras GPU um and then it worked finally um so it's using my GPU you see uh let's see GPU memory oh wow if it filled it up it used it used all available memory um and it's using about 22 of my gpus resources running at 46 C so that's not too warm um let's see 46c I think that's about 120 degrees maybe 130 degrees Fahrenheit um but yeah so it's running nice and nice and smooth um if we come over here to data we see we've already got um 1300 out of 55 000 so it's going up pretty fast uh yeah and the average time is continuing to go down so that's not too bad all right so I'll let this run let this finish um actually first let me show you what it I think I already showed you one but they're all going to be roughly the same uh size because it's going to be a chunk of no more than a thousand um a thousand characters followed by the uh as well as the um the vector so basically what I'm doing is I'm preparing a whole bunch of data um for to stuff into quadrant so that I can stress test it so it'll be it'll be 55 000 um original files but it'll actually end up being more um total files so each of those is going to end up being a data point all right so I'm gonna pause the video again let this run we'll see how long it takes total okay we have oh let me turn my light back on there we go uh we have success it took 3 500 seconds so just shy of an hour but the average time was .063 seconds per file so that's not bad um grand total it generated um let's see uh 88 000 files at 1.1 gigabytes so we have um we have just shy of 90 000 data points to add to this um so now what I'm going to do is take the quadrant stress test and I'm going to update this I'm not going to make you watch me just do some basic programming um so basically what I'm going to do is upload uh upload this all at once and and and while it's uploading we will watch the container performance so the volume will be listed here um and then here's the image so I got the quadrant image and then the container I deleted the the previous demos just so we're going to start from scratch I'm going to upload it all in one go and we're going to see how long it takes and we're also going to watch CPU and GPU I don't know if quadrant uses GPU by default I'm not running it in privileged mode so I don't think so I think it just uses um I think it just uses uh CPU quadrant um uh Docker hub so because I don't if you go to their their Docker image there's no mention of GPU um to run the container yeah I it doesn't seem like it uses uh it doesn't uh because you so with Docker if you need to give it access to system level Hardware you need to run it in privileged mode so like if you need to give it camera microphone GPU um so I think this is just um can take advantage of modern CPU x86 architectures it allows you to search even faster on Modern Hardware okay so it doesn't really say anything about um yeah all right so anyways I'm gonna pause the video again I'll um I'll get the uh the upload working and then we'll do the stress test and see how fast it goes and pause all right almost there um yeah so let me show you I went into the quadrant client on GitHub and I think the function that I need is upload records so I give it a collection name uh Records which is just an iterable of type record with a batch size and then number of parallel I'm going to do a little bit larger of a batch size based on the quick start I think this is an example of a record so a record is a dictionary that has at the top level ID integer and then the vector it looks like it's just plain um at least at least if you use the the Raw One it does it this way but if you go here and you look at record um I think the record has to have um let's see base record Vector um I guess wallet list float okay so maybe the vector doesn't have to be um maybe it doesn't have to be a numpy array I think if you do upload collection it does require it to be a numpy array because if you do uh not recreate let's see upload collection um here it is upload collection so you see that where the vectors it's a union of in numpy ND array um so I think that if you use upload collection it expects an ND array um but if you do upload records it just it just expects a list so let me go ahead and fix this because the embedding is just going to be a list so I don't actually need numpy here um but still looking at this where did it go the quick start yeah so you need ID vector and then payload so those are the three things that it looks and then the payload is itself another dictionary that's just what is the information attached to this one so that's what I've got here where I've got ID Vector payload and so the the payload is going to be the content which is the string and then the file name and so as a quick reminder this is what I'm going to be uploading it takes a while so let me go ahead and start by let's run the docker image so I'll show you what that looks like and then if we go here we say we see it's starting this and then volumes it has started um started the volume so this volume will grow as it's running and then if I show you in here um let's do oh why is it okay so Docker desktop um but if you look at what's using the most memory the virtual machine is using the most memory obviously okay so this is running so I need a new one of these CD quadrant

CLEAR ESSAY:

==========

I am running a quick test on the Quadrant stress test. I am uploading roughly 88,000 files to test the container performance. The average time per file is .063 seconds. The total time for the entire process is just shy of an hour. I am monitoring the CPU and GPU usage. It does not appear to be using my GPU. I will let the process finish and then show the results.