The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: to help first thing is we got to finish the microservices so i've only got a handful of the microservices we're not quite halfway done but a lot of the first principles have been figured out so it's only a matter of time to do the prompt engineering and so on to get those micro services working i'm sure we're going to uh trip over some bugs and you know unforeseen consequences um another thing is we got to test different implementations right so there's different types of apis to use there's different ways to implement the nexus there's different ways to do search so we're going to be working on getting kind of establishing those baseline like best practices making some architectural decisions doing some prompt engineering this is just getting the thing to work it's going to be messy but we got to get it to work the first time so moragi v1 goals to so to put it in terms of an agile roadmap first we have to test various technologies and platforms so we're going to test rest apis graphql elk stack airflow whatever else there's all kinds of ideas flying around out there and like i said at the beginning of the presentation there's more than one way to skin this cat but the principles are there and so we're going to work on demonstrating a proof of concept for all microservices so that's one of the key goals of mirage ev1 is get a proof of concept working it doesn't have to be good it doesn't have to be solid it just has to demonstrate the concepts of artificial cognition and in particular those feedback loops it's about nested loops it's about loops within loops within loops and so on so once we get all the best practices and principles established then i'm going to put it all together codify it in a book and then publish that book for free let's see we're also going to begin work as it's going to be fully open source with a distributed team so i put out a call for participation yesterday and i've already had four people volunteer to jump in and contribute in different ways um this is it's not just up to me and i have already just after one single call i've already had new ideas and and learning by the feedback that people have have given so like you know when you have a team working together it's basically humans acting as generative adversarial networks where you got different people proposing different ideas and then together you come up with better solutions than you could come up with on your own so that is moragi v1 goals is get the book out establish a distributed team prove out artificial cognition and feedback loops implement the proof of concept for all the microservices and test the different technologies so that's v1 next steps on the road map so i typically follow a five release model um it just to me that kind of things uh that works best in terms of my training with agile so maragi v2 we're going to focus on fine fine-tuning in the conductor for version two so we should get to the point where we're using fine-tuned models for all microservices fine-tuned models are going to make it more portable because that means we can switch to like gptj or bloom or any other models because once you've got a fine-tuning data set it should be portable to any other large language model that's the goal here um step part of that uh something that flows from that is that with version two to be complete all the microservices should be autodidactic meaning that they um that they curate their own fine-tuning datasets and fine-tune their own models over time but then they also have to do a b testing to figure out which models are best so auto being having auto didactic microservices that is not a trivial task that is a very difficult task um and a part of that is the conductor we need to have the conductor fully operational with version two meaning that the microservices pay attention to the conductor to modify their behavior in real time and also use the feedback from the conductor to curate those data sets so you see how it's all tightly integrated another goal for fi for version two is to have a good simulation environment right now the simulation environment is really rudimentary um we can also start thinking about optimizing for cost and performance um some of that is just going to be waiting for newer more efficient models to come out and also bigger gpus to come out um some of these some some large language models are more efficient than others and this whole industry is being advanced all the time so some of that's just going to be a function of time but some of it is also incumbent on us to optimize our system as much as possible um so the the the last part of version two is um we we ought to be working on proving the robustness of the heuristic imperatives we'll get more we'll get more to that in in future releases though um so version three version three or release three is where we'll start working on hardware integration so we'll start integrating things like cameras microphones and speech microservices um we'll continue refining the uh refinement of the architectural paradigms best practices and implementation version 3 is going to be the first time that we're going to aim for public consumption so basically it'll be all the software will be open source we'll start to put it on like smart home devices and allowing people to test it in their own home on their own terms right so again it's going to be open source so it's going to be basically use at your own risk but we're going to try and get it into the real world so that you can interact with a moragi system in real time in a real environment to to test it and get that get that feedback because we'll we'll need that feedback um but not after doing a lot of optimization and also proving the robustness and safety of the heuristic imperatives version four scale security and stability so this is where we start to think like okay we've solved all the all the rudimentary problems let's start to expand so uh some of the questions that we

CLEAR ESSAY:

==========

The first thing we need to do is finish the microservices. I've only got a handful of them done, but a lot of the first principles have been figured out. So it's only a matter of time to do the prompt engineering and so on to get those microservices working. I'm sure we're going to trip over some bugs and unforeseen consequences.

Another thing we need to do is test different implementations. There are different types of APIs to use, different ways to implement the nexus, and different ways to do search. So we're going to be working on getting best practices established and making some architectural decisions.

Our goal is to get a proof of concept working. It doesn't have to be perfect, it just has to demonstrate the concepts of artificial cognition and feedback loops. Once we have all the best practices and principles established, we can codify them in a book and publish it for free.

We're also going to begin work on making the project fully open source and distributed. I put out a call for participation yesterday and I've already had four people volunteer to jump in and contribute. This is going to be a team effort, and I'm already getting new ideas and learning from the feedback people have given.

So our goals for Mirage v1 are to test various technologies and platforms, get a proof of concept working, establish a distributed team, and codify the best practices in a book. For Mirage v2, we're going to focus on fine-tuning the conductor and making the microservices autodidactic. We also want to have a good simulation environment and start thinking about optimizing for cost and performance. And for Mirage v3, we're going to start working on hardware integration and aim for public consumption.

In Mirage v4, we'll focus on scale, security, and stability. This is where we start to expand and think about things like integrating cameras, microphones, and speech microservices. We'll also continue refining the architectural paradigms and best practices.