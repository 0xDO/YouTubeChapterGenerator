The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: hey everybody david shapiro here for another tutorial video today we are going to go over um fine tuning 101 data prep so uh if you've watched my other videos you know that i'm a big fan of synthetic data sets especially because one it's fast two it's relatively cheap and three you get exactly what you want so what i want to do is show you an example of how to get synthetic data now one thing to keep in mind with fine tuning is that you're not actually training the model to do anything new gpt3 is already trained on many hundreds of gigabytes worth of data everything that you ask it to do it already knows how to do so the purpose of fine tuning is to narrow down to say do this one thing every time now because fine tuning is about removing possibilities you want to make sure that your fine tuning data has a broad variety so that it has seen many examples um and we'll get into advanced fine tuning techniques later um i'll probably do a video going over my question generating um bot because the more variety you show for the input and the more and the more examples you give in terms of that breadth of variety and like different formats the better it will perform now when you're doing synthetic data in the way that i'm about to show you it's a very consistent format but anyways so i wanted to start with something very simple which was just imagine a complete and detailed plot synopsis for a blank you know genre set in a location during a time and then the story should be uh you know add a couple modifiers write out the entire plot premise in great detail um now unfortunately uh the instruct series models are not the best at going in at long form writing but you see this one's okay it's doing all right um so it does a pretty good job it's almost like a movie poster it's not actually like writing out the story um but this is good enough for now um with a little bit more prompt engineering um here actually let's try it let's instead of premise let's say outline and see if that modifies it um yeah that looks like it's a little bit more detailed um but it's still not actually writing the whole story um because part of the problem is that gpt3 was not trained on actual like plot outlines and actually if you watch my other videos um getting getting gpt3 to actually write fiction is really difficult so i'll modify the prompt to say instead of premise i'll say plot outline um and we'll just change this here as well so we're going to say write plot outlines okay so we've got this this is the prompt that i'm going to use and i'm going to auto populate it with different things so this is a really quick way to get a broader variety of data is where you ask it to do kind of the same prompt but you give it a bunch of different modifiers um so effectively what i'm going to do is give it you know 200 different prompts and i'm going to record that output and then use that for fine tuning data and so the scripts that i've got oops uh is here here i did something wrong okay the script that i've got is synthesize plots um so what i've got is i've got a list of genres a list of modifiers a list of places and a list of periods so you get all this you can get a lot of variety you can get a lot of combinations the first time i ran it i had uncommented all these and it was like going to generate 2 000 different samples i'm not going to spend that much on a tutorial video so i cut it down to four by four by four by four so four to the fourth power is 256. so i've got four examples of each of each thing and then you might also notice that i've got the up here the uuid so uuid let me just show you what it looks like oops synthesize slots there we go okay so this is this is showing you the the prompts that it's going to run so it starts with a uuid up at the top a uu id is just a random string of hexadecimal characters but one thing that i found is that this does a really good job of of causing gpt3 to have a little bit more internal entropy by starting it with a uuid it's like okay i'm reading this i don't i don't know how to make sense of it so it's trying to create an internal state that doesn't make any sense so you you you prime it to be a little bit more different a little bit more random this is especially good if you need to run the same prompt over and over and over again so you do this in combination with a high temperature and you'll get a lot more variety but anyways you can see where it's populated out imagine a complete and detailed plot outline for a science fiction film set in india during the 1990s the story should be supernatural and otherworldly write out the entire plot write out the entire plot outline in great detail and then you see the number here 256. so if you go back here you say i just did a quick count to keep track of how many it generated just to show you that's what it's doing so we can comment this out since we don't need this um and then what we'll do is i have some some canned functions that i use so here's the uh here's the gpt3 completion um use text davinci o2 temperature one top p of one token's a thousand it's not generating anywhere near that much um and then we'll save we'll save all this out to gpt3 logs but then what are we going to do with the actual prompt and completion right because for fine tuning you need a prompt and a completion and we're not going to just record these prompts what would be the point of that we're not actually adding anything so what we got to do is we're going to then format a prompt to look a little bit different so we'll say completion equals gpt3 completion and then we'll beat in my prompt but i've got all i've got the genre the modifier the place and the period so what i want to do is i'll save the um the out the um the out prompt as it'll be a text that uh basically what i'll do is i'll just say um uh let's see genre equals that and then newline and then i'll say location is dollar s and so this dollar s i'll show you what i'm going to do with this

CLEAR ESSAY:

==========

In this tutorial, we'll go over how to fine-tune your GPT3 model using synthetic data. Synthetic data is a great way to get exactly the data you want, and it's fast and relatively cheap.

When you're fine-tuning your model, you're not actually training it to do anything new. GPT3 is already trained on many hundreds of gigabytes worth of data. Everything you ask it to do, it already knows how to do. The purpose of fine-tuning is to narrow down to say, "Do this one thing every time."

Because fine-tuning is about removing possibilities, you want to make sure that your fine-tuning data has a broad variety. This way, it has seen many examples. I'll probably do a video going over my question-generating bot because the more variety you show for the input, and the more examples you give in terms of that breadth of variety and different formats, the better it will perform.

Now, when you're doing synthetic data in the way I'm about to show you, it's a very consistent format. But anyway, I wanted to start with something very simple: imagine a complete and detailed plot synopsis for a blank genre, set in a location during a time. Then, the story should be _____ and _____. Write out the entire plot premise in great detail.

Unfortunately, the instruct series models are not the best at going in at long form writing, but you see this one's okay. It's doing all right. It does a pretty good job. It's almost like a movie poster. It's not actually like writing out the story, but this is good enough for now.

With a little bit more prompt engineering, here actually let's try it. Let's instead of premise, let's say outline and see if that modifies it. Yeah, that looks like it's a little bit more detailed, but it's still not actually writing the whole story. Because part of the problem is that GPT3 was not trained on actual plot outlines. And actually, if you watch my other videos, getting GPT3 to actually write fiction is really difficult.

So I'll modify the prompt to say, instead of premise, I'll say plot outline. And we'll just change this here as well. So we're going to say, "Write plot outlines."

Okay, so we've got this. This is the prompt that I'm going to use. And I'm going to auto-populate it with different things. So this is a really quick way to get a broader variety of data. You ask it to do kind of the same prompt but you give it a bunch of different modifiers.

Effectively, what I'm going to do is give it, you know, 200 different prompts and I'm going to record that output and then use that for fine-tuning data. And so the scripts that I've got is here. Here I did something wrong. Okay, the script that I've got is synthesize plots.

So what I've got is I've got a list of genres, a list of modifiers, a list of places, and a list of periods. So you get all this variety. You can get a lot of combinations. The first time I ran it, I had uncommented all these and it was like going to generate 2,000 different samples. I'm not going to spend that much on a tutorial video, so I cut it down to four by four by four by four. So four to the fourth power is 256. So I've got four examples of each of each thing.

And then you might also notice that I've got the up here the uuid. So uuid, let me just show you what it looks like. Oops, synthesize plots. There we go. Okay, so this is this is showing you the the prompts that it's going to run. So it starts with a uuid up at the top. A uuid is just a random string of hexadecimal characters. But one thing that I found is that this does a really good job of of causing GPT3 to have a little bit more internal entropy by starting it with a uuid. It's like, "Okay, I'm reading this. I don't I don't know how to make sense of it." So it's trying to create an internal state that doesn't make any sense. So you you you prime it to be a little bit more different, a little bit more random. This is especially good if you need to run the same prompt over and over and over again. So you do this in combination with a high temperature, and you'll get a lot more variety. But anyway, you can see where it's populated out. "Imagine a complete and detailed plot outline for a science fiction film set in India during the 1990s. The story should be supernatural and otherworldly. Write out the entire plot outline in great detail." And then you see the number here, 256. So if you go back here, you say, "I just did a quick count to keep track of how many it generated just to show you." That's what it's doing. So we can comment this out since we don't need this. And then what we'll do is I have some some canned functions that I use. So here's the uh here's the GPT3 completion. Use text davinci o2 temperature one top p of one token's a thousand. It's not generating anywhere near that much. And then we'll save we'll save all this out to GPT3 logs.

But then what are we going to do with the actual prompt and completion, right? Because for fine-tuning, you need a prompt and a completion. And we're not going to just record these prompts. What would be the point of that? We're not actually adding anything. So what we've got to do is we're going to then format a prompt to look a little bit different. So we'll say completion equals GPT3 completion. And then we'll beat in my prompt. But I've got all the genre, the modifier, the place, and the period. So what I want to do is I'll save the out the out prompt as it'll be a text that uh basically what I'll do is I'll just say um uh let's see genre equals that. And then newline. And then I'll say location is dollar s. And so this dollar s I'll show you what I'm going to do with this.