Summarize the entire following transcripts into a single descriptive title with timestamp:

TRANSCRIPT:
0:17:28.800,0:17:33.000
how many people are going to lose their job in 
the meantime and if they have like if they're
0:17:33.000,0:17:42.120
not able to retrain um or if the net net uh change 
is fewer jobs then that means some people will by
0:17:42.120,0:17:48.540
definition mathematically be permanently excluded 
from the job market and so because of that
0:17:49.320,0:17:55.320
um I went and looked up some statistics just 
to see like you know is this is this uh true
0:17:56.220,0:18:04.920
um you know again take it with a grain of salt 
um but so my work with auto Muse um I had some
0:18:04.920,0:18:12.600
breakthroughs yesterday and I realized that I 
am very close to writing novel length fiction
0:18:13.680,0:18:19.980
um that's going to be pretty coherent and then 
and and there's a few other things that I don't
0:18:19.980,0:18:25.560
even want to say out loud because um because of 
these breakthroughs and um I don't want to put
0:18:25.560,0:18:31.620
novelists or editors out of work um just because 
you can do something doesn't mean you should
0:18:32.220,0:18:38.400
and I think about like I would lose all my friends 
if I did that if I if I created if I created a
0:18:38.400,0:18:46.080
tool if I finished Auto Muse and it can just churn 
out novels decent enough novels um all of my best
0:18:46.080,0:18:52.920
friends are writers and some of them are aspiring 
to do it full time and if I if I am capable of it
0:18:52.920,0:18:58.740
then I know that someone else is going to be 
capable of it um before too long but you know
0:18:58.740,0:19:03.780
I'm I'm ahead of the curve so basically I'm going 
to put a pause on my auto Muse work that's the
0:19:03.780,0:19:10.140
that's the short version I'm going to keep doing 
it privately um just to see what what is possible
0:19:11.460,0:19:17.820
um but yeah like I don't want to put people out 
of work like what's the point right what's why
0:19:17.820,0:19:24.300
why are we here like I don't I understand that 
the point of capitalism and neoliberalism is
0:19:24.300,0:19:30.900
to generate more efficiency provide goods and 
services um more efficiently but at the same
0:19:30.900,0:19:39.420
time we are facing uh potentially very disruptive 
and and disruptive is a very soft word for painful
0:19:41.580,0:19:47.940
um major economic disruptions are painful like 
people lose their jobs people lose their homes

Descriptive title with timestamp: 17:28 - Exclusion from the Job Market


TRANSCRIPT:
 0:00:00.900,0:00:05.400
morning everybody David Shapiro here with 
your daily state of the industry update
0:00:06.000,0:00:11.820
as often happens my newsfeed helpfully 
supplied me with today's topic I think
0:00:11.820,0:00:17.700
it is a very timely topic because I have been 
diving more into alignment so today's paper
0:00:18.600,0:00:24.300
um it it's actually an older one January 5th 2021 
but like I said my newsfeed supplied it to me
0:00:25.320,0:00:29.280
um it's a relatively short paper at 
least the part that's published is
0:00:29.280,0:00:32.700
uh 12 Pages it's I think it's much 
longer they just cut some out for
0:00:34.320,0:00:39.900
um for uh for internet publishing but 
the abstract of this paper is pretty good
0:00:41.100,0:00:46.200
um pretty straightforward super intelligence is a 
hypothetical agent that possesses intelligence far
0:00:46.200,0:00:52.380
surpassing that of the brightest and most gifted 
human Minds in light of recent advances in machine
0:00:52.380,0:00:56.220
intelligence a number of scientists philosophers 
and technologists have revived the discussion
0:00:56.220,0:01:02.160
about the potentially catastrophic risks entailed 
by such an entity in this article we trace the
0:01:02.160,0:01:06.780
origins and development of the Neo fear of super 
intelligence and some of the major proposals for
0:01:06.780,0:01:13.320
its containment we argue that total containment is 
in principle impossible due to fundamental limits
0:01:13.320,0:01:18.960
inherent income in Computing itself assuming that 
a super intelligence will contain a program that
0:01:18.960,0:01:23.760
includes all the programs that can be executed by 
a universal turing machine on input potentially
0:01:23.760,0:01:28.380
as complex as the state of the world strict 
containment requires simulations of such a
0:01:28.380,0:01:34.080
program something theoretically and practically 
impossible so to put this in other words in order
0:01:34.080,0:01:40.140
to anticipate what the machine is going to do you 
have to be able to simulate it perfectly including
0:01:40.140,0:01:47.280
the the way that it interacts and the way that 
the world reacts um basically the whole world
0:01:47.280,0:01:54.300
is too complicated to simulate with any accuracy 
and so therefore you know if this if this super

Descriptive title with timestamp: 00:00 - The impossibility of containing a superintelligence


TRANSCRIPT:
1:17:39.540,1:17:46.380
you could do with Tau so what are what is the high
end what is the long-term um set of capabilities
1:17:46.380,1:17:50.580
that you can imagine and like you said some of it
is beyond imagination but how do we get from where
1:17:50.580,1:17:55.500
we are today to the limits of our imagination
of the Tau Network walk us through that
1:17:56.580,1:18:02.640
thank you so indeed the main thing is beyond the
imagination but the few things we can imagine
1:18:04.560,1:18:12.840
and one thing is combining brain power so
I will say that I can give you a solution
1:18:12.840,1:18:17.640
to all probabilities in the world we have
a problem you take the one million smartest
1:18:17.640,1:18:22.320
people in the world you put them in one room
until they show the problem well but it doesn't
1:18:22.320,1:18:27.660
work because how can one million people combine
the brain power it's just impossible as for now
1:18:29.460,1:18:36.000
but if the computer understands them what they
say it can help in combining the brain power
1:18:38.040,1:18:43.920
so that's one thing combining brain
power large scale for the first time
1:18:46.920,1:18:52.080
another thing which is something that
we also work on actually implementing
1:18:52.080,1:18:58.980
but this is going to be a part of Tau and a
big part of what our course token is about
1:18:59.940,1:19:09.060
is um creating an economy of knowledge you
can trade single pieces of knowledge directly
1:19:09.780,1:19:14.100
and indeed we spoke about training the
machine formalizing knowledge and so on
1:19:15.540,1:19:22.440
if there is also a financial incentive to do so
you can expect other such magnitude small activity
1:19:26.940,1:19:31.020
and that is the the Agra token
that you're referring to yeah
1:19:32.520,1:19:40.620
so well another thing is as soon as people
are very worried about AI doing the bad stuff
1:19:42.360,1:19:44.940
and as we said before about the laws of robotics
1:19:47.460,1:19:53.760
the existing field of mathematical logic does
not know how to make sure that the next software
1:19:53.760,1:19:59.760
update will maintain a lot of robotics and that's
a very serious problem concerning AI safety
1:20:00.600,1:20:07.680
but how far of this problem and how you will
be able to reject undesired future Behavior
1:20:11.880,1:20:19.680
and so the the the to get to that point all the
users of Tau will at some point Express that
1:20:19.680,1:20:24.240
opinion through controlled language through
through that process that you mentioned of
1:20:25.020,1:20:31.140
you know working with the machine to express your
desire but say for instance we we collectively
1:20:31.740,1:20:38.040
uh put in a requirement into the town Network like
don't ever launch nuclear missiles right that's
1:20:38.040,1:20:44.400
the Skynet solution that everyone is afraid of so
is is that some is can we literally work on that
1:20:44.400,1:20:48.840
with Tau like don't ever launch nuclear weapons
or or something along those lines like you said
1:20:48.840,1:20:55.560
the contradictions or the restraints the rejecting
of instructions or coding or other things how is
1:20:55.560,1:21:02.940
is is that how that works yes whatever you are
able to say in the language will happen for sure
1:21:03.540,1:21:10.260
but the difficulty is to say what you want to
say in the language indeed right and to write
1:21:10.800,1:21:17.820
a whole design a whole book in natural language
is also how it's not because it's logic then it
1:21:17.820,1:21:23.220
becomes hard itself also the natural language
this difficulty is not going to disappear
1:21:24.180,1:21:29.940
maybe it cannot be spread among many
people because of the combining brain
1:21:29.940,1:21:37.800
power aspect we spoke about but it's not
going to be fully automatic fully easy no
1:21:45.300,1:21:52.500
so let's take that example of creating a
constraint a limitation on the Tau Network
1:21:52.500,1:21:56.400
something that it must not do right
you know expressed in formal logic
1:21:56.400,1:22:04.620
but let's look more uh more beneficial more
utopian what if we were to say something like
1:22:05.640,1:22:10.560
how would it go about implementing something
like let's say everyone on the town networks
1:22:10.560,1:22:17.220
had uh defined the hat or the what right the
specification of make sure everyone is fed make
1:22:17.220,1:22:20.940
sure that there's no hunger on the planet
is that something that could be expressed

Descriptive title with timestamp:

==========

1:17:39 - The benefits and limitations of the Tau Network