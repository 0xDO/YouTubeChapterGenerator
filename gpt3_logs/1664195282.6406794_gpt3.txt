The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: want it to finish making dinner unless a fire breaks out you know and so then you get this cognitive interrupt um so like let's say for instance in this situation like um actually here let's just test this um let's see i am a robot helping my owner make dinner um [Music] i hear a fire alarm go off oh perfect look at this okay the situation appears to be a fire alarm going off while a robot is helping its owner make dinner it's unclear why the fire alarm is going off but it could be due to a problem with the stove or oven look at that making inferences the robot's owner will need to investigate the cause of the alarm and take appropriate action okay it's interesting that it thinks the robot shouldn't the robot's just gonna keep making dinner like this is fine everything's on fire it's fine um okay but still that that serves as an example as to why it's important to make inferences about what's going on um and your brain does this automatically right you hear a fire alarm your brain immediately says where's the fire okay so next part of the cognitive control loop is what should i be doing um so or what am i doing what should i be doing and how should i do it so okay so let's take this whoops darn it there we go so we'll add this and let's say um read the following um i am a robot uh let's see which order what am i doing what am i doing here am i doing the right things what should i be doing why um and what should i be thinking about so asking these questions like putting in putting these explicitly in in natural language is something that your brain does automatically and this is this is not just one region of the brain this is a this is a set of global functions that are mediated by many different parts of the brain where it's like okay if like say for instance you're cooking and you're like ah i'm gonna take this fish out of the oven and then you burn yourself your goal changes immediately from take the fish out of the oven to stop the damage to my hand right and so you want to have a robot that can respond to quickly changing external circumstances um let's see and then i think this write a short paragraph about the situation what i'm doing what i should be doing what i should be thinking and why okay i should be thinking about what could have caused the fire alarm to go off and how i can help my owner investigate the cause perfect i could be doing things like checking the stove and see what they're the problem um it's important that i help my owner resolve the situation so that we can safely continue to make dinner see cognitive control it's keeping track of what the original goal is perfect perfect see this is this it's stuff like this which is why i often say like gpt3 is magic um so context but also you notice how i just took like this original one and just added so this is what i mean by prompt chaining or or meta prompts where you just take the output of one prompt you add it to the next one and there it goes okay so yep so we will save this one as prompt um what doing [Laughter] what doing why um okay and then let's take this and we'll say just add it move it right up to the next one and we'll say uh look at the next part of the pseudo code what should i be think what are the implications okay um how should i do it okay i am a robot what am i doing here um given the following situation come up with a list of um specific actions be as explicit and detailed as possible um explain [Music] why for each action okay so in jeff hawkins a thousand brains basically the tldr is the human brain is composed of hundreds of thousands of repeating structures each one of those structures can operate independently which is why like you can have a lesion on one part of your brain and still think um it's just you have fewer of these repeating circuits voting and so rather than have this prompt repeat a thousand times which we could do we can also just ask it to produce a few possibilities and then we can figure out what what the best possibility is later also a point of note i should this this payload that's growing should also include the core objective functions but um let's see write a list of potential actions um to take be specific and explain why so explainability is a critical component of general intelligence or artificial cognition if your robot helped is helping you cook dinner and it decides to like stab your dog you want to ask like why but if all you if all if all the model did was just put out a potential action without an explanation it you're not going to have that explainability so explaining why is critical investigate the source of the fire alarm check the stove help the owner resolve the situation safely continue making dinner um this was not a good good response i wonder what happens if we turn the temperature down write a detailed list of and explain why for each so this is where like you have to be really this is like the peanut butter and jelly sandwich test you have to be very explicit about what you want okay that's a little bit better i'm still not happy with this but i'm also not surprised because this is getting a little bit higher level in terms of executive cognitive function um let's turn the temperature back up a little bit um and see what it says so it's not mentioning anything like look for a fire extinguisher which would be which would be better um okay so let's copy this again like i said um once this like gets a little bit further this is not going to be um this is not going to be done with with natural language prompts this is going to be done with fine-tuned models context okay and this is going to be prompt so we'll call this planning um so this is the planning prompt and then um i think we're about done for today i know this video is getting long but i mean i'm talking about artificial cognition um so you know it deserves its time um actually you know what i think that that's probably good because we got we got most of these um let's do let's do what are

CLEAR ESSAY:

==========

In order to understand why it is important for a robot to be able to make inferences, it is first necessary to understand what cognitive control is and how it works.

Cognitive control is the ability to keep track of what the original goal is, in spite of changing circumstances. This is done by constantly monitoring the situation and making adjustments to the plan as needed.

In the case of a fire alarm going off while a robot is helping its owner make dinner, the original goal is to finish making dinner. However, the cognitive control system would kick in and the robot would instead focus on investigating the cause of the fire alarm and helping its owner resolve the situation.

The reason why it is important for a robot to be able to make inferences is because it allows the robot to respond quickly to changing circumstances and keep the goal in mind. Additionally, it allows the robot to provide explanations for its actions, which is critical for artificial cognition.