The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: logs look like so i added the indent so this wastes a little bit of text space but i added the indent so that it's easier to see so content oh it's also sorted so this is a cool thing that you can do with um with json so json dump payload out file ensure ascii false this allows it to encode in utf-8 really important you can do ensure ascii true but you can get some weird nonsense with that actually we don't use load data so i can probably delete this function yeah oh no actually we do okay um dude never mind um insure ascii false this unsure this allows you to encode everything in utf-8 which can be critical especially once you're dealing with multiple languages other symbols sort keys equals true so sort keys is what may it this will ensure that everything is always in alphabetical order and since every log file has just these six or so how many one two three four five six seven seven fields they'll always be in the same order which is nice because then you know what you're looking for so content microservice model time type uuid and vector um so this is kind of what the data is going to look like and then you see here's the actual embedding it should be a 512 vector value embedding which means that like yeah and it's going to be the same for everyone because i just sent the same one over and over so every memory so here's a problem every single memory that we just created is 14 kilobytes so let's do a little bit of math so let's say that uh a future version of moragi is running 15 50 uh uh inferences per second um and each one has an embedding um it'll add a little bit because the um the the message will be a little bit longer so let's just make this a little bit longer so we can get um well actually here whatever we'll just say 14 kilobytes so 50 50 messages times 14 kilobytes so that's 700 kilobytes per second um that this could be generating later on so this is why this is what i'm talking about like optimization is going to be a big thing and i'm not going to worry about it right now because that's just you know i keep i keep making these changes so like let's not let's not uh try and eat the whole elephant at once okay so 700 kilobytes per second times 60 seconds so that's 42 megabytes per minute so we're looking at like this is this is almost as big as a wav file right as a lower quality wav file which is you know old old-school music um so 42 uh we'll say 42 megabytes um uh well here 42 000 divided by 1024. so 41 megabytes per minute so 41 megabytes per minute times 60 2.46 gigabytes an hour divided by 1024 so that's 2.4 gigabytes an hour 2.4 gigabytes an hour times 24. 57 gigabytes a day of thinking um or or of of data um obviously the embeddings are um you're not going to pay for for all that uh 57 gigabytes a day times 365. so that's 21 let's see divided by 10 24 so that's 20.5 terabytes of data per year that is obviously way too much but if you think about it though that's not unreasonable if you were to record every single sensation and thought and motor output that you had 20 terabytes seems kind of reasonable right um so just that's why like this will need to be optimized it will need to be summarized um there's going to be a whole bunch of other stuff that happens in the background and i think this is enough for today um because i i've merged the embeddings um into it and also reconfigured the um the way that it does logging um so yeah it's much more much more interpretable um yeah so i'm satisfied for today so anyways i was talking about things that the nexus is going to do in the future so in the future so we'll say distant future um one thing is a blockchain so imagine here's here's why blockchain imagine that you've got an instance of meragi running um for your your home life right it's a smart home device it records everything it sees and does and hears um that is a huge privacy thing and so you don't want just a bunch of json files stored out here on your smart home device or in the cloud somewhere where it would be like you know um dave is meeting with secret spies from you know wherever you don't want that kind of data out there um now but then like let's say you're a an academic institution um so blockchain for privacy mostly um an academic research institution and again you don't want your data stolen in fact many uh researchers as part of the grants that they get have very very stringent privacy controls um ditto if you have an instance of meraki helping run a hospital you got patient records to to protect so um because blockchain um has well here let's just do do do do no that's the wrong one there we go so blockchain has several advantages um so we'll do blockchain for privacy um and so what are the advantages of blockchain um it's immutable i cannot change records later so this is critical for legal reasons it's critical for um you don't want your your agi's memories tampered with um immutable uh tamper proof so uh that's basically two sides of the same coin um but like uh so again records cannot be changed um distributed right so it means it can be um resilient difficult to delete um so that's another thing and then there's uh consensus is another uh is another thing which means that um [Music] messages uh or well we'll say transactions transactions uh must be accepted by a quorum so imagine in the future you have several microservices all running and for every message that makes it into your ai's brain um you ha it has to be approved right um so that that gives you a gating or a filtering mechanism um so this is like uh so it's a dating or filtering mechanism um so there's a lot of reasons that blockchain is good now okay so obviously you know you don't want to store your private data in clear text you want it to be encrypted but blockchains are not necessarily the best thing for being searchable they're not necessarily known for speed that's not their point so your raw data will be stored as a blockchain um so we'll just say like use to store raw data

CLEAR ESSAY:

==========

The logs for my AI, Moragi, look like this. I added indentations to make the data easier to read. The content is sorted alphabetically, which is a cool feature of JSON. The indentations waste a little bit of text space, but they make the data much easier to interpret.

I use the JSON dump function to payload out the data to a file. I set the ASCII encoding to false, which allows the data to be encoded in UTF-8. This is really important, as you can get some weird results if you use ASCII encoding instead.

Actually, we don't use the load data function, so I can probably delete it. Oh wait, actually we do use it. Never mind.

I set the ASCII encoding to false and the sort keys to true. This ensures that everything is always in alphabetical order. Since every log file has just a few fields, they will always be in the same order. This makes it much easier to interpret the data.

The content, microservice, model, time, type, UUID, and vector fields are what the data will look like. The embedding should be a 512 vector value. This is the same for everyone, as I just sent the same data over and over.

Every memory that we just created is 14 kilobytes. This can add up quickly. Let's do some math to see how much data this can generate over time.

If Moragi is running 50 inferences per second, each with an embedding, it will generate 700 kilobytes of data per second. This can add up to 41 megabytes per minute, or 2.4 gigabytes per hour. If we assume that Moragi is running 24 hours a day, this can add up to 57 gigabytes of data per day. Over the course of a year, this can add up to 20.5 terabytes of data.

This is obviously way too much data to store. This is why optimization is going to be a big thing. We will need to summarize the data and only store the most important information.

In the future, I envision Moragi being able to record every sensation, thought, and motor output. 20 terabytes of data seems reasonable for this.

So, just to recap, we need to optimize the data storage to only include the most important information. This will need to be summarized and stored in a more efficient way. Blockchain is one option for this, as it is immutable and tamper-proof. However, it is not necessarily the most efficient option in terms of speed or searchability.