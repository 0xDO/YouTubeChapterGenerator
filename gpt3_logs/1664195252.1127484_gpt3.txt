The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: articles what i was doing was i was working on training the core objective functions to be able to identify suffering prosperity and understanding opportunities in a variety of situations the logic there is that if you if you fine-tune a model on multiple types of excuse me situations then then it will get better at generalizing so let me just quickly recreate let's see uh some of the prompts and also i apologize for any typing mistakes i smashed my pinky a few days ago and it's uh it's difficult to type read the following um characterize any suffering present has suffering increased or decreased why um actually here we'll do speculate why um and then let's see propose ideas to decrease suffering okay so basically what we're doing here is i'm just kind of giving it a um giving it a uh like a set of instructions like kind of priming it as to okay here's what you're going to do suffering is defined as unwanted pain distress or hardship so this is like the most formal definition possible and so we have to break it down unwanted so there was a there was actually a great kealo let's see kialo suffering where was it i don't remember where where i found it but so kealo is like a formal public debate platform and it talked about suffering and and like the question was like is suffering um like is is reducing suffering like a good global definition or goal and someone said no because like one of the primary reasons that it wasn't is because what if someone wants to suffer and it's like okay well but if you look at the definition of suffering many definitions of suffering include unwanted so if someone wants pain then like if they consent to the pain or the or the distress then it's not technically suffering so suffering is specifically unwanted or unconsented to pain distress or hardship so if we use this as our definition this is a pretty good universal thing and in my other experiments and videos we explore suffering as like okay based on this definition can plants suffer can bacteria suffer how do you identify suffering in dogs suffering is decid uh defined as unwanted pain distress or hardship um uh let's see this applies to all things um let's see let's just say all living things okay so let's see situation and then we'll just copy in um this and then so this is this is one of the contexts and then we'll say um write a short paragraph about suffering in the above and we'll do two new lines just give a little bit more demarcation all right let's just see how this works okay it says columbus is experiencing mental suffering due to his guilt over lying to his men and marchena is experiencing physical suffering due to his illness it is clear that columbus's decision to lie has caused an increase in suffering for both himself and martini columbus's proposal to tell his men the truth would likely decrease the amount of suffering by all involved okay so that's not bad um my dog is looking at me like he wants something give me just a second okay i'm back sorry about that um my dog is bored and he wanted some rope time okay so by by characterizing suffering we are basically trying to give our artificial cognitive entity a sense of post-conventional morality this is an ideal to which it aspires right it's not just like oh well there's a consequence for something that i did so and i'm gonna be punished for it because like you can't hurt a machine right you can threaten to turn it off but like gpt3 doesn't care if you turn it off um and then it's not a social entity so it's not it doesn't care about adhering to social norms um so what we need to do is give it something that is that is above and beyond um you know consequences or social controls it has to i it has to identify with something that it will never fully be able to achieve um so that it can adhere to that um to that uh morality and um so going back to the inner loop when you say like what should i be doing this the the the implications of this question are far more profound than just these five words would would initially indicate because if you have a machine that's just sitting here thinking and it can think anything or choose to do anything how do you know how does it know what it should do what it should um uh aspire to and so that's where this started with um you know the moral compass idea way way back in the day almost two two years ago now where i was like okay let's let's create an experiment to see if we can create a moral compass because what i realized early on in my research is that if you want to achieve general intelligence or artificial cognition you actually have to start with thought a lot of people start with robotics where it's like input output like okay let's manipulate an object but then you have to you you very quickly get to the question of why why am i manipulating this object what is the goal here and if if you if you program a machine just to move you know a block from point a to point b there's no morality there there's no purpose right there's no there's no objective function other than move a to b um yeah so that's why and that's when i realized like okay the heart the absolute heart of any intelligent machine is going to be what is its purpose and that's why i call them the core objective functions it's not just objective functions it's the core objective functions or the heuristic comparatives okay so let's copy this um this prompt is good enough to get started in the long run i'm going to need to return to my um to my uh uh um fine tuning projects in order to because this like okay having having one one prompt to handle all of suffering that's not ideal no we need to give it 10 000 examples of of different situations and so that it has a very very refined and nuanced understanding of one how to identify and characterize understanding how to identify whether suffering is increasing or decreasing and then three what to do about it right because just just a one-shot example like this this isn't good enough but

CLEAR ESSAY:

==========

When it comes to suffering, we need to be able to train our core objective functions to be able to identify suffering in a variety of situations. The logic is that if we fine-tune a model on multiple types of situations, it will get better at generalizing. So, let's take a look at a few prompts and see how this works.

Suffering is defined as unwanted pain, distress, or hardship. So if we use this as our definition, it applies to all living things. In the situation where Columbus is experiencing mental suffering due to his guilt over lying to his men and Marchena is experiencing physical suffering due to his illness, it is clear that Columbus's decision to lie has caused an increase in suffering for both himself and Martini. Columbus's proposal to tell his men the truth would likely decrease the amount of suffering by all involved.

In another example, my dog is bored and he wanted some rope time. By characterizing suffering, we are basically trying to give our artificial cognitive entity a sense of post-conventional morality - an ideal to which it aspires. This is because we need to give it something that is above and beyond consequences or social controls. And so, going back to the inner loop, when we ask it what it should be doing, the implications of this question are far more profound than just these five words would initially indicate.