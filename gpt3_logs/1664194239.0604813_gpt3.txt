The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: tune job and then we'll test it and that'll we'll call it a day um let's see python find do i not have the fine tuned script in here i copied the wrong one i guess oh i know what i did i copied the wrong one from auto muse there we go this should be the correct one uh where did i save it maybe i accidentally deleted it okay so we'll get the creative writing um creativewritingcoach.jsonl update the file name update the tag okay that should be good um python fine tune uploaded pending okay one last pause and then we will come back once this job is ready we're back it's finally done um let me show you how much this cost because i know you guys frequently ask this so in total it was 252 requests some were deleted some were testing we ended up with 202. the fine-tuned model was 8 um 800 kilobytes and that was 24 now moment of truth let's see how it went go back to the playground let's go ahead and get this model loaded it should be creative writing coach there we go and then let's go to writing prompts and we'll just grab one off the top of the stack because i'm not going to write one and i'm not going to ask gpt3 to write one it would be a little perverse if uh if we ask gbt3 to write a story and then critique itself although you can do that gpt3 can be adversarial against itself okay so we'll give it the story that is 800 tokens and then let's see what was the d mark that i used um i think it was like professional feedback or something so let me look at the um yeah professional feedback so we add some new lines at the end and then we let it go this might take a second to load because um openai with fine-tuned models sometimes it takes it a minute to load it into its brain waiting waiting and drink some tea all right i'm gonna pause it until this finishes loading not gonna make you wait okay success um it says the opening of the story is very strong you immediately set the scene and introduce the conflict i especially like the way you describe the war maiden and the demon the war maiden is very brave and determined while the demon is sly and manipulative however i feel like the middle of the story drags a bit the dialogue between the war maiden and the demon feels a bit stilted and unnatural you also introduce a lot of new characters which makes it difficult to follow the plot the ending of the story is also very strong the twist is unexpected and very clever overall i think you have a lot of potential as a writer with a bit of work i think you could produce some really great work keep up the good work um and then it started confabulating so fine-tuned models often do this and i'm not quite sure why um where it just starts repeating itself at the end the the medical the reduced confabulation with the medical fine-tuned bot that i did did the same exact thing where in one of the examples it just started repeating hiv repeatedly like it really wanted you to know about hiv so it might be that what we need to do is add like an end of text token and then use that as a stop with these fine-tuned models i'm not sure it also might get better with um with more data because i'm using the bare minimum 200 samples so anyways it worked um i hope you like this video like and subscribe and tell a friend

CLEAR ESSAY:

==========

I recently completed a project where I created a fine-tuned model using the OpenAI GPT-3 API. In this video, I briefly go over what I did and how much it cost.

First, I created a Python script that would take a JSONL file and fine-tune a model using the GPT-3 API. I then uploaded the script to OpenAI's Playground, where it ran for a while and generated a fine-tuned model.

Next, I loaded the model into the Playground and ran it on a writing prompt. The results were encouraging - the model was able to provide some constructive feedback on the story. However, it also started repeating itself at the end, which is something that fine-tuned models often do.

Overall, I'm pleased with the results of this project. With a bit of work, I think the model could be even more useful.