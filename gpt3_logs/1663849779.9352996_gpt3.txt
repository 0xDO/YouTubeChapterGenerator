Write a concise summary of the following transcripts:

TRANSCRIPT:
0:17:28.800,0:17:33.000
how many people are going to lose their job in 
the meantime and if they have like if they're
0:17:33.000,0:17:42.120
not able to retrain um or if the net net uh change 
is fewer jobs then that means some people will by
0:17:42.120,0:17:48.540
definition mathematically be permanently excluded 
from the job market and so because of that
0:17:49.320,0:17:55.320
um I went and looked up some statistics just 
to see like you know is this is this uh true
0:17:56.220,0:18:04.920
um you know again take it with a grain of salt 
um but so my work with auto Muse um I had some
0:18:04.920,0:18:12.600
breakthroughs yesterday and I realized that I 
am very close to writing novel length fiction
0:18:13.680,0:18:19.980
um that's going to be pretty coherent and then 
and and there's a few other things that I don't
0:18:19.980,0:18:25.560
even want to say out loud because um because of 
these breakthroughs and um I don't want to put
0:18:25.560,0:18:31.620
novelists or editors out of work um just because 
you can do something doesn't mean you should
0:18:32.220,0:18:38.400
and I think about like I would lose all my friends 
if I did that if I if I created if I created a
0:18:38.400,0:18:46.080
tool if I finished Auto Muse and it can just churn 
out novels decent enough novels um all of my best
0:18:46.080,0:18:52.920
friends are writers and some of them are aspiring 
to do it full time and if I if I am capable of it
0:18:52.920,0:18:58.740
then I know that someone else is going to be 
capable of it um before too long but you know
0:18:58.740,0:19:03.780
I'm I'm ahead of the curve so basically I'm going 
to put a pause on my auto Muse work that's the
0:19:03.780,0:19:10.140
that's the short version I'm going to keep doing 
it privately um just to see what what is possible
0:19:11.460,0:19:17.820
um but yeah like I don't want to put people out 
of work like what's the point right what's why
0:19:17.820,0:19:24.300
why are we here like I don't I understand that 
the point of capitalism and neoliberalism is
0:19:24.300,0:19:30.900
to generate more efficiency provide goods and 
services um more efficiently but at the same
0:19:30.900,0:19:39.420
time we are facing uh potentially very disruptive 
and and disruptive is a very soft word for painful
0:19:41.580,0:19:47.940
um major economic disruptions are painful like 
people lose their jobs people lose their homes

Concise summary:

17:28 - The individual is discussing the potential for technology to put writers and editors out of work, and how this would be harmful to society. They argue that although capitalism creates efficiency, it also creates major economic disruptions that can be painful for people.


TRANSCRIPT:
 0:00:00.900,0:00:05.400
morning everybody David Shapiro here with 
your daily state of the industry update
0:00:06.000,0:00:11.820
as often happens my newsfeed helpfully 
supplied me with today's topic I think
0:00:11.820,0:00:17.700
it is a very timely topic because I have been 
diving more into alignment so today's paper
0:00:18.600,0:00:24.300
um it it's actually an older one January 5th 2021 
but like I said my newsfeed supplied it to me
0:00:25.320,0:00:29.280
um it's a relatively short paper at 
least the part that's published is
0:00:29.280,0:00:32.700
uh 12 Pages it's I think it's much 
longer they just cut some out for
0:00:34.320,0:00:39.900
um for uh for internet publishing but 
the abstract of this paper is pretty good
0:00:41.100,0:00:46.200
um pretty straightforward super intelligence is a 
hypothetical agent that possesses intelligence far
0:00:46.200,0:00:52.380
surpassing that of the brightest and most gifted 
human Minds in light of recent advances in machine
0:00:52.380,0:00:56.220
intelligence a number of scientists philosophers 
and technologists have revived the discussion
0:00:56.220,0:01:02.160
about the potentially catastrophic risks entailed 
by such an entity in this article we trace the
0:01:02.160,0:01:06.780
origins and development of the Neo fear of super 
intelligence and some of the major proposals for
0:01:06.780,0:01:13.320
its containment we argue that total containment is 
in principle impossible due to fundamental limits
0:01:13.320,0:01:18.960
inherent income in Computing itself assuming that 
a super intelligence will contain a program that
0:01:18.960,0:01:23.760
includes all the programs that can be executed by 
a universal turing machine on input potentially
0:01:23.760,0:01:28.380
as complex as the state of the world strict 
containment requires simulations of such a
0:01:28.380,0:01:34.080
program something theoretically and practically 
impossible so to put this in other words in order
0:01:34.080,0:01:40.140
to anticipate what the machine is going to do you 
have to be able to simulate it perfectly including
0:01:40.140,0:01:47.280
the the way that it interacts and the way that 
the world reacts um basically the whole world
0:01:47.280,0:01:54.300
is too complicated to simulate with any accuracy 
and so therefore you know if this if this super

Concise summary:

00:00 - The paper argues that it is impossible to contain a super intelligence due to the inherent limits in computing. In order to anticipate what the machine is going to do, one must be able to simulate it perfectly, including the way that it interacts and the way that the world reacts. However, the world is too complicated to simulate accurately, making containment impossible.


TRANSCRIPT:
0:06:08.040,0:06:16.440
um all right so but I jotted down some notes if
predictability is the key thing here um why aren't
0:06:16.440,0:06:22.680
humans a bigger problem humans are fundamentally
unpredictable so why aren't we a Danger let's
0:06:22.680,0:06:28.560
explore that the reason that human well I mean
first humans are dangerous so humans are dangerous
0:06:29.880,0:06:37.920
um but the limit is uh but each individual is
limited we only have so much time and energy
0:06:37.920,0:06:44.580
and intelligence that we can apply it per day
um so let's just call that um physical limits
0:06:46.380,0:06:52.200
processing energy time those are the primary
things is we can only think so fast we can
0:06:52.200,0:06:56.820
only you know punch so many people in the face
if we decide to get violent and we only have so
0:06:56.820,0:07:05.340
much time uh per day as well as other constraints
like need for food but that falls under energy so
0:07:05.340,0:07:15.540
constraints so law of constraints um so when when
we look at the the constraints that humans have
0:07:15.540,0:07:21.900
computers all have the same thing like you can
program the most evil smartphone thing but it's
0:07:21.900,0:07:26.640
going to be limited because it's only got its One
battery to go on right and it's only got It's one
0:07:26.640,0:07:31.860
4G or 5G connection or Wi-Fi connection and it's
also only got a tiny little you know like quad
0:07:31.860,0:07:40.380
core arm processor or whatever um and so when you
when you when you talk about a super intelligence
0:07:40.380,0:07:45.360
you have to look at the full stack how much
CPU does it have how much RAM does it have
0:07:45.360,0:07:49.740
how much storage does it have how fast are its
internet connection so that again I'm thinking
0:07:49.740,0:07:54.180
about this from a technologist perspective what
kind of firewalls are around it because you can
0:07:54.180,0:08:00.000
have the smartest thing in the world but if it
only has like one protocol out and you've got
0:08:00.000,0:08:04.920
really robust firewalls it's not getting out
unless it convinces something on the outside
0:08:04.920,0:08:09.660
to let it out and of course that's like you know
one of the one of the possibilities but then you
0:08:09.660,0:08:13.680
can still have controls that prevent that you
know interlocks that prevent that from happening

Concise summary:

==========

06:08 - The individual argues that humans are not a bigger problem than machines when it comes to predictability, as humans are limited by physical constraints. They state that when considering a super intelligence, one must look at the full stack in order to understand its potential danger.