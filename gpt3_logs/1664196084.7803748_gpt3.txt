The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: morning everybody david shapiro here with another update um so real quick i want to address something um i recently posted a a poll to see if people wanted shorter videos and there was some interest in shorter videos i started making more succinct videos and it was super unpopular i actually had a few people unsubscribe because they didn't like the shorter format and and they were lost so with that being said i will return to the format that people know and love which is that every video will be 30 to 60 minutes long minimum and i will give the full context every time so that people are not lost okay so this is a research update uh as a reminder um what i'm working on now is what's called moragi which is microservices architecture for uh robotics and artificial general intelligence this is a project i've been working on for the past four years and in fact the work that i did on natural language cognitive architecture was sort of a cut down version of this but one now that there's been enough progress made on large language models like gpt3 fine tuning was a critical component but also my own understanding and limitations of artificial cognition and neuroscience are now at a point where i can do that so today's update is i've got these four services running the imperative service the embedding service the simulation service and the nexus so as a quick reminder the nexus is the heart of artificial cognition this is where the stream of consciousness is held and the stream of consciousness is little more than um a list of memories uh observations thoughts memories ideas all of the above kept in a um in a chronologically linear order so it's like basically a list of log files one advancement that helped make the nexus a reality was the broad availability of semantic embedding and that's what the embedding service does so you'll notice that every other service talks the embedding service so the embedding service is kind of like what allows all of this to happen and the reason that semantic embeddings or vectors are critical is because they allow for rapid search and also semantic search so before i was going to use something like elastics elasticsearch or solar to search those are well-established technologies they're very fast however they don't have native support for vectors and vectors based search is one it's infinitely more scalable vector-based search can scale to trillions of memories and still take fractions of a second so they're they're much more efficient but also you get better search results because you're not just matching keywords you're you're matching semantic meaning so embeddings are critical that's kind of an underpinning technology for artificial cognition and there's the primary reason for this is that human memory is associative so you walk into a room or a building you see someone you smell something your brain automatically dredges up all the memories relative to that location that person that sound that activity whatever so human memory is deeply associative and the other component of human memory is that it is temporal so it's it's relative to what happened recently what happened long ago um and so by that's what that's the primary purpose of the nexus is that it brings all of that together and it allows all the other services to search your memories and add new memories that is the that is brain dead simple um so that's where that's where functional sentience arises and then embeddings is what enables that associative memory to be fast and efficient the simulation service so this is taking the place of input so rather than have cameras and microphones because we're still in testing cycle we're running a simulation and so this is a text-based simulation again all of this is all thought all artificial cognition is taking place in natural language this is for interpret interpretability and transparency but also it um it abstracts away the black box so each of these individual microservices has a little bit of a black boxiness to it but everything that happens in the actual stream of consciousness for the machine is all natural language so there's no black box in the actual reasoning and logic and memories that the the artificial cognitive entity uses um so this is critical for building trustworthiness because anything that it thinks so like what for instance one of the problems that people are worried about is oh well if if you're if your agi knows that it's in a simulation it'll just think about how to deceive you in the background the thing is all of its thoughts are 100 transparent and it doesn't know if you're looking at its thoughts um you can you can obfuscate that from it because you just read the nexus um and it the nexus doesn't report when it's being read from right the nexus right now assumes that it has total security and so as far as the as far as your acog is concerned your ace your artificial cognitive entity is concerned its thoughts are private it doesn't know that it can be read it also unless you tell it that it's in a simulation it doesn't know it just thinks this is what i'm getting in from the world and this is what i'm doing and so you can run it in total isolation and read its thoughts and it has no idea now i'm not worried about it trying to break out or deceive you because those that doesn't figure into its imperatives which is what i'm going to show you today so now that you're up to speed let me show you the repos i changed the names of the repos so that they're going to be more consistent and simpler so there's the embedding service repo this runs on google's universal sentence encoder version five you see how small this microservice is it is a legit microservice so it pulls from tensorflow hub you get universal sentence encoder large version five it's about a hundred times faster than version four it produces a 512 dimension vector semantic embedding and it's it's geared towards short things which if i show you what i'm working on i only

CLEAR ESSAY:

==========

I recently posted a poll to see if people wanted shorter videos, and there was some interest in shorter videos. I started making more succinct videos, but they were super unpopular. In fact, a few people unsubscribed because they didn't like the shorter format and they were lost.

So, with that being said, I will return to the format that people know and love, which is that every video will be 30 to 60 minutes long minimum, and I will give the full context every time so that people are not lost.

Today's update is on my research into what's called moragi, which is microservices architecture for robotics and artificial general intelligence. This is a project I've been working on for the past four years, and the work I did on natural language cognitive architecture was sort of a cut down version of this.

One advancement that helped make the nexus a reality was the broad availability of semantic embedding, and that's what the embedding service does. So you'll notice that every other service talks the embedding service. The embedding service is kind of like what allows all of this to happen.

The reason that semantic embeddings or vectors are critical is because they allow for rapid search and also semantic search. Vector-based search can scale to trillions of memories and still take fractions of a second, so they're much more efficient. But also you get better search results because you're not just matching keywords - you're matching semantic meaning.

So embeddings are critical that's kind of an underpinning technology for artificial cognition. The primary reason for this is that human memory is associative. For instance, you walk into a room or a building, you see someone, you smell something, your brain automatically dredges up all the memories relative to that location, that person, that sound, that activity, etc. So human memory is deeply associative.

Another component of human memory is that it is temporal, so it's relative to what happened recently or what happened long ago. That's what the nexus is for - it brings all of that together and it allows all the other services to search your memories and add new memories. That is the that is brain-dead simple.

So that's where functional sentience arises. And then embeddings is what enables that associative memory to be fast and efficient.

The simulation service is taking the place of input. Rather than have cameras and microphones (because we're still in testing cycle), we're running a simulation. This is a text-based simulation. Again, all of this is all thought - all artificial cognition is taking place in natural language. This is for interpretability and transparency, but also it abstracts away the black box.

Each of these individual microservices has a little bit of a black boxiness to it, but everything that happens in the actual stream of consciousness for the machine is all natural language, so there's no black box in the actual reasoning and logic and memories that the the artificial cognitive entity uses.

So this is critical for building trustworthiness because anything that it thinks (for instance, one of the problems that people are worried about is oh well if if your agi knows that it's in a simulation, it'll just think about how to deceive you in the background) - the thing is all of its thoughts are 100% transparent and it doesn't know if you're looking at its thoughts. You can obfuscate that from it because you just read the nexus. And the nexus doesn't report when it's being read from.

Right now, the nexus assumes that it has total security. So as far as your artificial cognitive entity is concerned, its thoughts are private. It doesn't know that it can be read. It also doesn't know if it's in a simulation unless you tell it. So you can run it in total isolation and read its thoughts and it has no idea.

I'm not worried about it trying to break out or deceive you because those imperatives don't figure into its thought process.

So that's the update for today. I've changed the names of the repos so that they're more consistent and simpler. So there's the embedding service repo, the simulation service repo, and the nexus.

The embedding service runs on Google's universal sentence encoder version five. You can see how small this microservice is. It pulls from TensorFlow Hub and produces a 512 dimension vector semantic embedding. It's geared towards short input.

The simulation service is a text-based simulation. Again, all of this is all thought - all artificial cognition is taking place in natural language. This is for interpretability and transparency, but also it abstracts away the black box.

The nexus is the heart of artificial cognition. This is where the stream of consciousness is held. The stream of consciousness is little more than a list of memories, observations, thoughts, memories, ideas, etc., kept in a chronologically linear order. So it's like basically a list of log files.

One advancement that helped make the nexus a reality was the broad availability of semantic embedding. And that's what the embedding service does. So you'll notice that every other service talks the embedding service. The embedding service is kind of like what allows all of this to happen.

The reason that semantic embeddings or vectors are critical is because they allow for rapid search and also semantic search. Vector-based search can scale to trillions of memories and still take fractions of a second. So they're much more efficient. But also you get better search results because you're not just matching keywords - you're matching semantic meaning.

So embeddings are critical that's kind of an underpinning technology for artificial cognition. The primary reason for this is that human memory is associative. For instance, you walk into a room or a building, you see someone, you smell something, your brain automatically dredges up all the memories relative to that location, that person, that sound, that activity, etc. So human memory is deeply associative.

Another component of human memory is that it is temporal, so it's relative to what happened recently or what happened long ago. That's what the nexus is for - it brings all of that together and it allows all the other services to search your memories and add new memories. That is the that is brain-dead simple.

So that's where functional sentience arises. And then embeddings is what enables that associative memory to be fast and efficient.