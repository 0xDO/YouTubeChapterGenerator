The following is an unstructured video transcript. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: i'm back okay so i know that i said i would take like two to four months off um but apparently something has changed in my brain and i'm not going to take that long anymore um i have continued reading brain trust and as what always happens whenever i read cognition or neuroscience i'm inspired to do more work so i want to bring you up to speed with what i worked on last night and i didn't share it because one it is a politically sensitive thing i did check openai's guidelines for content sharing and publication and you're not supposed to share anything that is part of a political campaign so i think this is okay um but basically what i did was i took the um i took the supreme court opinion on um dobbs versus jackson which is more conventionally known as overturning roe versus wade um so it is crazy long it's 454 000 characters long and i ran it through my recursive summarizer and after four iterations i got down to the supreme court has well here let me just go here um the supreme court has overturned roe versus wade which means that states are now able to ban abortion this will have a particularly hard impact on low-income women who will not be able to afford to travel to states where abortion is still legal many will be forced to turn to illegal and unsafe abortions which could lead to their death so that was the ultimate result of recursively summarizing this document which is a very impactful summary um it occurred to me though that just recursively summarizing something from an arbitrary length down to something super concise okay that's great but you lose a lot of resolution and then um there is a huge need for answering questions from arbitrary volumes of data this is an unsolved problem and it is a non-trivial problem so what do i mean by answering questions from arbitrary data sources or an arbitrary number of documents whether you are a business or whether you're building artificial cognitive entities or chat bot assistants you're going to have a huge amount of data to filter through oh and actually before we get started i just wanted to go ahead and plug my um my discord server that i just started up um the join link will be in the comments this is a really smart bunch of people who are all doing really great stuff so if you want to join my my research discord please feel free to jump in make sure you check out the rules first though there are only four rules keep it cool be kind discussion not debate agree to disagree and beliefs and evidence um other than that pretty much everything goes um we want it to be chill and friendly and productive this is not a place to prove that you're right to prove that other people are wrong it's not a place to show off or anything like that we are here to make the biggest difference possible for the world okay now that that plug is out of the way um multi-document answering so openai originally had their answers endpoint which you could have an arbitrary number of documents and then like it would search for the right document and give you an answer they deprecated that because nobody used it but it occurred to me that maybe there is something here because um say for instance you've got a robot right like you imagine that you've got a domestic robot um and you want it to like keep track of like oh hey what did i tell you a year ago right or or you you have a business assistant that that you want to be able to have intuitive discussions with managing large amounts of knowledge of memories is going to be critical for this um and if you if you just summarize an arbitrarily large amount of data okay that's fine but you lose a lot of information and you can't interact with it so this is going to be one of my you know pair programming sessions you always tell me that you love watching me just take an initial stab at something so let me just tell you or show you where we're starting so one i'm going to borrow some code from my recursive summarizer but also i'm going to borrow some code from my acog experiment because one of the things that i did here is i've got this function that allows you to stack memories and also embed memories so i'll be borrowing some code from this as well so we'll start here both of these are publicly available under the mit license so you're welcome to uh to play along if you want um so without further ado let's go to my multi-document answering so i i've already borrowed this code to recursively summarize something so basically what i'm going to do is because we've got a good example to start with i'll go ahead and just grab this document and we'll start here so we'll take that from the recursive summarizer because let me just show you this is it's 454 thousand characters long and it is dense it has a lot of information um so this is a supreme court opinion and in order to have a uh in order to allow people to better engage with you know political discourse or other information problems wouldn't it be great if you had a really powerful chat bot that could answer questions for you and summarize things and like you know tell me what this is all about so that's what i'm going to try and do and obviously this is a non-trivial problem i do not expect to finish it today but we'll see how far we get okay so recursively summarize first things first um we're not going to just summarize everything so we get we're going to have to throw out some of this let's go ahead and rename this to input um input.txt that's fine no all right so it all text equals open file input chunks equals text wrap so what this does is it breaks it up into chunks of 3000 characters um so what this first one is going to do is where my my intuition is that what we what we should do is go ahead and make an index and rather than make like an inverted index that you'd use like in store in a database or whatever we're going to do a vector-based index um so let me show you uh let's see where did it go my acog experiment so the inner loop um so what i've done here

CLEAR ESSAY:

==========

I'm back. Okay, so I know that I said I would take two to four months off, but something has changed in my brain and I'm not going to take that long anymore. I have continued reading Brain Trust, and as always happens when I read cognition or neuroscience, I'm inspired to do more work. So I want to bring you up to speed with what I worked on last night.

I didn't share it because it is a politically sensitive thing. I checked OpenAI's guidelines for content sharing and publication, and you're not supposed to share anything that is part of a political campaign, so I think this is okay. But basically what I did was I took the Supreme Court opinion on Dobbs versus Jackson, which is more conventionally known as overturning Roe versus Wade.

It is crazy long—454,000 characters. I ran it through my recursive summarizer, and after four iterations I got down to the following: "The Supreme Court has overturned Roe versus Wade, which means that states are now able to ban abortion. This will have a particularly hard impact on low-income women who will not be able to afford to travel to states where abortion is still legal. Many will be forced to turn to illegal and unsafe abortions, which could lead to their death."

So that was the ultimate result of recursively summarizing this document—a very impactful summary. It occurred to me though that just recursively summarizing something from an arbitrary length down to something super concise is great, but you lose a lot of resolution. And there is a huge need for answering questions from arbitrary volumes of data. This is an unsolved problem, and it is a non-trivial problem.

So what do I mean by answering questions from arbitrary data sources or an arbitrary number of documents? Whether you are a business or whether you're building artificial cognitive entities or chatbot assistants, you're going to have a huge amount of data to filter through.

Before we get started, I just wanted to plug my Discord server that I just started up. The join link will be in the comments. This is a really smart bunch of people who are all doing really great stuff, so if you want to join my research Discord, please feel free to jump in—just make sure you check out the rules first. There are only four rules: keep it cool, be kind, discussion not debate, agree to disagree, and beliefs and evidence. Other than that, pretty much everything goes. We want it to be chill and friendly and productive. This is not a place to prove that you're right or to prove that other people are wrong. It's not a place to show off or anything like that. We are here to make the biggest difference possible for the world.

Now that that plug is out of the way, let's talk about multi-document answering. OpenAI originally had their answers endpoint, which allowed you to have an arbitrary number of documents, and it would search for the right document and give you an answer. They deprecated that because nobody used it, but it occurred to me that maybe there is something here.

Say, for instance, you've got a robot. You imagine that you've got a domestic robot, and you want it to keep track of like, "Hey, what did I tell you a year ago?" Or you have a business assistant that you want to be able to have intuitive discussions with. Managing large amounts of knowledge and memories is going to be critical for this. And if you just summarize an arbitrarily large amount of data, that's fine, but you lose a lot of information and you can't interact with it.

So this is going to be one of my "pair programming sessions." You always tell me that you love watching me just take an initial stab at something, so let me just show you where we're starting. So, one, I'm going to borrow some code from my recursive summarizer, but also I'm going to borrow some code from my acog experiment. One of the things that I did in the acog experiment is I've got this function that allows you to stack memories and also embed memories, so I'll be borrowing some code from that as well.

So, without further ado, let's go to my multi-document answering. I've already borrowed this code to recursively summarize something. So basically what I'm going to do is, because we've got a good example to start with, I'll go ahead and just grab this document, and we'll start here. So we'll take that from the recursive summarizer. Let me just show you—this is it's 454 thousand characters long and it is dense. It has a lot of information.

So this is a Supreme Court opinion, and in order to allow people to better engage with political discourse or other information problems, wouldn't it be great if you had a really powerful chatbot that could answer questions and summarize things? So that's what I'm going to try and do. And obviously, this is a non-trivial problem. I do not expect to finish it today, but we'll see how far we get.

Okay, so recursively summarize. First things first—we're not going to just summarize everything. So we get we're going to have to throw out some of this. Let's go ahead and rename this to input. Input.txt is fine.

All right, so it all text equals open file input. Chunks equals text wrap. So what this does is it breaks it up into chunks of 3000 characters. What this first one is going to do is, my intuition is that what we should do is go ahead and make an index. Rather than make like an inverted index that you'd use in store in a database or whatever, we're going to do a vector-based index.

Let me show you my acog experiment. So the inner loop—what I've done here is I've got a memory, and I embed the memory. So basically, what I'm going to do is I'm going to take this document, and I'm going to embed it. So I'm going to take the first 3000 characters, and I'm going to embed it. And then I'm going to take the next 3000 characters, and I'm going to embed it. And I'm going to keep doing that until I hit the end of the document.

And then what I'm going to do is I'm going to take each of those embeddings, and I'm going to average them. And that's going to give me a single vector that represents the document. So that's what I'm going to do. I'm going to take this document, and I'm going to embed it, and then I'm going to average the embeddings. And that's going to give me a vector that represents the document.

And then what I'm going to do is I'm going to take that vector, and I'm going to compare it to all of the other vectors that I've already generated. And I'm going to find the most similar vector. And that's going to give me an index of where that document is in the vector space.

So that's what I'm going to do. I'm going to take this document, and I'm going to embed it, and then I'm going to average the embeddings. And that's going to give me a vector that represents the document. And then I'm going to compare it to all of the other vectors that I've already generated, and I'm going to find the most similar vector. And that's going to give me an index of where that document is in the vector space.

And then, once I have that index, I can just do a lookup. So, if I have a question, I can just take the question, and I can embed it, and then I can find the most similar vector. And that's going to give me an index of where the answer is in the vector space.

So that's what I'm going to do. I'm going to take this document, and I'm going to embed it, and then I'm going to average the embeddings. And that's going to give me a vector that represents the document. And then I'm going to compare it to all of the other vectors that I've already generated, and I'm going to find the most similar vector. And that's going to give me an index of where that document is in the vector space.

And then, once I have that index, I can just do a lookup. So, if I have a question, I can just take the question, and I can embed it, and then I can find the most similar vector. And that's going to give me an index of where the answer is in the vector space.

So that's the plan. We'll see how it goes.