The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: thirteen hundred and eleven um okay so that's twenty-five percent shorter not bad um but that's that's better than the 10 times shorter um that uh that the original prompt was doing okay so i think we found our prompt our gentle summary um so let's oops summarize this passage with moderate yep and then we go moderate summary okay so basically um if i were to do this over what i would do is um for for summarizing the big chunks i'd use this one and then for making sure that the the story so far wasn't too concise i would use this one um and so what we're going to do is i'm going to incorporate this when we're writing the novel and i'll use the same logic okay so with all that said i think we're ready to go so let me open so writing the novel is going to be really similar to preparing the training data so basically what i'll do is i'll just copy this and then i'll modify it um so we'll do this let's go ahead and save it so we get the um so we get the right formatting all types and we'll do write novel dot pi here we go it's getting real folks okay now we're not gonna we're not gonna do this summaries that's fine uh we need to yep we'll need an outline and we're going to be generating the summaries as we go okay oh did i accidentally overwrite the thing no here it is okay so we will all right so we'll need two we'll need two complete or two um gpt3 engines so this will be we'll call this the fine tune completion we'll get rid of the engine and the tokens will set that to 500 because we don't want to go any any higher than that um because that'll be 500 tokens is about 1500 characters they're about um might be a little bit more let's cut that down to 400 because i don't want it to go overboard okay so let's move this up a little bit because the gpt3 completion this is just your standard text davinci o2 we're gonna use this with our with our summary prompt okay so um the outline will be we'll just call this premise.tech and so what we'll do is i've already got a folder full of premises and so what we can do if we want one um let's see mystery tensions are high and the city is on edge okay cool so we'll just copy one of these out to the main directory and we'll just call it premise so that's the file that we'll use to seed the premise of our story okay so we got the premise we don't need recursive summaries we don't need the fine tune we've already done that um let's leave one of these open just so that way we can see um kind of how it's going to go so the premise will go here the story so far will go here and then we'll write the chunks now if you watched the last video this had a really hard time with a cold start because if the story so far was empty and the last chunk was empty as well it didn't know what to do so it became very clear that what we're going to need to prime the pump by by starting this with a different process so what we're going to do is we're going to say um first chunk um well actually i guess first let's let's do some prompt engineering um so let's go open our premise again um and then go back over to gpt3 so let's say maximum length 256 that's fine write the opening chapter for the following story premise all right chapter one let's see it looks like it's just repeating itself okay um uh okay so this is this is it's so fascinating because like if i fed it pros it was it was really good but if i ask it to write pros it's really awful let's see so let's try something new and i remember i ran into a similar problem at the very beginning of this project um okay so premise um yeah and you can see it made a lot of mistakes i wonder what happens let's do um let's do an older curie or sorry older um davinci instruct beta right uh write a novel for the above premise oh much better okay um let's try well here let me copy this down just in case um and also let's see if using instruct two works so instruct beta seems to be more creative yeah see it's just it's just copy pasting itself um okay so instruct beta is definitely where we're gonna start um let's see chapter one oh this is great okay cool i think we have we have our opening prompt um so let's do premise and we will do premise chapter one there we go so we're going to say prompt um first okay so basically what we're going to do is we're going to use this prompt and the premise to generate the first the first chunk to get to get things going um okay so we've got our outline and then our prompt will be open file um prompt underscore first dot text and then we're going to do dot replace premise with our outline okay so that is going to be our first chunk um and then let's go ahead and do a um actually i guess it'll technically be our last chunk so we'll go ahead and use the same thing equals gpt3 completion prompt so basically what that'll do is what this these two lines of code do right here will do exactly what we saw right here um and it stopped at 256 so we'll do 500 tokens because that will be i think that'll be about right let's see how much 256 was in terms of characters 644 yeah so if we double that that'll be 1300 tokens or characters or so because we don't want it to go too far in one go because um one thing that gpt3 does is it kind of tends to start hallucinating or confabulating if it runs too far okay so prompt first good and then uh let's see okay so we've got the first chunk and then the summary chunk um so the summary chunk we're gonna want to um yeah okay i think we're probably good now we're going to need to this actually this loop is going to need to be different okay so once we get here we're going to do we're just going to do like um let's say let's say 20 for i in range 0 to 20. so we're just going to do 20 iterations and then we will and then we'll stop because i don't want to burn all my tokens so the reason i'm doing this and not another fine tuning video is because i'm almost out of tokens for this month okay um so last chunk and we should probably save this too yeah okay do i have a save function i

CLEAR ESSAY:

==========

The goal of this project is to write a novel by using a machine learning model, specifically the GPT-3 model. In order to do this, we need to prepare the training data, which is similar to writing the novel itself. We'll need two complete GPT-3 engines, one for the fine-tuning completion and one for the summary prompt. We also need an outline of the novel's premise, which we can get from a folder full of premises.

Once we have the outline, we can use the prompt to generate the first chunk of the novel. From there, the story will unfold on its own. We can use the summary prompt to generate a summary of the story so far, and then use the fine-tuning completion to write the next chunk. We'll repeat this process until we reach the end of the novel.