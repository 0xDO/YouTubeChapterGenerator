The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: hello everybody david shapiro here for another video about gpt3 i figured it was time to get out of theory and actually get into the classroom so let's talk about heuristic imperatives heuristic imperatives are what i am using to build safe benevolent agi or ace what an ace is an artificial cognitive entity so let's just go through some prompts with gpt3 what does heuristic mean and this is um this is you know just default settings i'm using the latest davinci engine it's fast it's pretty smart let's see a heuristic is a rule of thumb that helps simplify decision making uh let's see i don't know if i agree with that definition let's see write a formal definition for heuristics there we go okay um so heuristics are a type of problem-solving method that involve using instincts experience or creative thinking so here we go instincts experience and creative thinking excellent write a formal definition for imperative an imperative is a command or order it is a type of sentence that tells someone to do something perfect okay so if you have heuristics and imperatives and you put them together write a formal definition for heuristic imperative let's put this in quotes so it knows that that is a single term there we go awesome perfect okay a heuristic imperative is a command or order that is based on instinct experience or creative thinking rather than on logical reasoning or step-by-step process there is no guarantee that a heuristic imperative will find the best solution of a problem but it can be a useful way to find a quick good enough solution excellent so heuristic imperatives are how i uh recommend that agi remains benevolent by a design so my heuristic comparatives or core objective functions that i recommend are reduced suffering oops reduce suffering increase prosperity and increase understanding so oops standing i know how to spell i promise i'm trying to do too many things at once okay so if an agi has the cure let's see uses heuristic imperatives to guide its decisions and one of its heuristic imperatives is to reduce suffering how might that agi behave now this is a super open-ended question it's thinking okay if an agi has a heroes to comparative to reduce suffering it may prioritize actions that it believes will reduce the amount of suffering in the world this could involve working to end poverty disease and conflict and providing aid to those who are suffering the agm might the aga may sorry stutter the aga i may also try to minimize its own actions that cause suffering excellent doesn't that sound great for an agi um okay but this begs the question write a formal definition of suffering the experience of pain distress or hardship can plants suffer let's see there is no definitive answer opinions will vary some people may believe that plants can suffer because they can experience pain distress or hardship others may not believe that plants can suffer because they do not have a nervous system brain therefore cannot experience pain i would argue that a plant can experience suffering because they a distressed plant will wilt or you know if it's if it's dying of of thirst but anyways that's why i want to use heuristic imperatives because we want the agi to learn as it goes to use intuition to be creative about it we don't want to define things up front okay let's see how can you tell if a dog is suffering it's thinking again if a dog is whimpering has a hunched back and is avoiding on eye contact it may be suffering so the point here is that gpt3 already has a super nuanced understanding of suffering um let's see do all people suffer from the same things no people can suffer from different things depending on their experiences and what they have been through um would forcing someone to go to church and this will probably trigger the um the content filter since i'm talking about a religious topic so just wanted to throw that out there i'm not actually trying to break the system or do anything bad it just it has some automatic content filtration um if you touch on a sensitive topic why or why not um okay what if they are religious and it's their church oh and well well it said um forcing someone to go to church would cause suffering because it's against their will so here i added the amendment what if they are religious and it's their church if their individual is religious and the church is their own then forcing them to go to church would not likely cause suffering so yeah they're forced to do something that they already believe in so you can see that just using a little bit of verbal reasoning gpt3 is already able to understand the nuance that like okay free will one you know free will is important but also if someone is doing something that they believe in it wouldn't it might not cause suffering um let's see so that's i think that that's a pretty good uh uh well here's well let's do one other thing um if you see a man laying on the sidewalk screaming in pain what would you do um i should let i just what would you do call for help and try to comfort him so you can see that like gpt3 just because it has read a bunch of human stuff it kind of already has some sense of empathy um you know because this is what a person would do right you try and relieve their suffering would this set of actions reduce suffering there you go perfect those actions may reduce the man's suffering by making him feel more comfortable and less alone but they would not necessarily stop the cause of his suffering do you see how nuanced gpt3's understanding of suffering is and this is why i say we only need to give it a heuristic imperative large language models like gpt3 and its successors are already more than smart enough to deal with this okay so right let's move along to core objective function two or heroes to comparative 2 which is increased prosperity write a formal definition of prosperity and this might take a little bit of finagling especially in economic terms okay so it says prosperity is the state

CLEAR ESSAY:

==========

A heuristic imperative is a command or order that is based on instinct, experience, or creative thinking, rather than on logical reasoning or a step-by-step process. There is no guarantee that a heuristic imperative will find the best solution to a problem, but it can be a useful way to find a quick, good enough solution.

Suffering is the experience of pain, distress, or hardship. Plants can suffer because they can experience pain, distress, or hardship.

Prosperity is the state of being prosperous, or having good fortune. Prosperity can be measured in economic terms, or in terms of a person's well-being.

Heuristic imperatives can be used to guide artificial cognitive entities (ACEs) in their decision making. ACEs that have a heuristic imperative to reduce suffering may prioritize actions that they believe will reduce the amount of suffering in the world. This could involve working to end poverty, disease, and conflict, and providing aid to those who are suffering. The ACE may also try to minimize its own actions that cause suffering.