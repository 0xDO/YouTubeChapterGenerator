The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: instinctively we have a curiosity instinct it is inborn it is genetic um to to us as a species to ask questions and that is that is curiosity curiosity is the desire to know for its own sake and so in order to have a truly intelligent machine it also needs a sense of curiosity and so the question the ability to formulate and ask questions and then seek those answers is how curiosity is implemented and so what we do is in this case and this is the last um this is the last one that happens but there so i've got four right now there's a whole lot of other stuff that needs to happen for the imperative service oh and also quick background imperative is short for heuristic imperative so heuristic imperative is something that we learn as we go or it's self-taught or auto-didactic so and all these microservices are going to be autodidactic but in particular the imperative service must be autodidactic because we want our our artificial cognitive entity to learn over time to do better where it uh where it is where its goals are concerned so we wanted to learn about suffering and improve its ability to reduce suffering we want it to learn about prosperity and improve its ability to um to increase prosperity we also want it to continue learning and teaching so the third core objective function or the third heuristic imperative is increase understanding so the best way to increase understanding internally is to ask questions now those questions can be at can be asked and answered internally but they can also be turned outwards so for instance if there's a robot that's watching these men play chess it might say like why are you playing chess in spite of the noise or how did you what were you thinking when you realized that you um that you've been playing for hours like you know just some basic questions i have an entire fine-tuning experiment for this it's called natural language cognitive architecture question generator so i'll incorporate that into the future but for now just a simple prompt is good enough to get it off the ground um so that is that is this one and um that is this function here increase understanding with questions you can see the prompt here it's pretty straightforward brainstorm a list of questions to ask about the following scenario and then you give it a block of text and then it says i just repeat the instructions and away it goes it asks at gpt3 is really great at asking questions so it has an intrinsic sense of curiosity um let's see so then we go back to the imperative microservice and we look at some of the other functions so reduce suffering brainstorm so let me actually just open a duplicate tab for this so i can jump around jump around okay reduce suffering so this is the um this is the prompt for reduced suffering so i'll just plug this in here um says definition of suffering the state of undergoing pain distress or hardship brainstorm brainstorm how to reduce suffering given the following information say and then we give it you know a block of memories and then we say brainstorm a list of possible actions we could take so i actually found that using the royal we this changes the agent model the intrinsic agent model that it uses the gpt3 uses because if you say i it says like okay what am i it assumes that i am a human but if you say we hang on my dog's barking give me just a second okay i'm sorry about that i think there's a dog walking by outside um let's see where was i oh yeah so i started saying uh i realized through testing that if you use the royal we then the agent model of gpt3 the intrinsic agent model of we is much more universal because it assumes it assumes then that we are collective um like we are borg we are legion um and so it is then unbound based on like well i'm going to go you know fix this problem or whatever and so when you're brainstorming if you use we one it is intrinsically more uh collectivist it's more cooperative and collaborative so by using this language in our artificial cognitive entity we are intrinsically pushing it towards being more cooperative and collaborative because it's not thinking i right we can we can easily have um gpt3 think selfishly i am i am going to do this i want this um but it's what we we want to reduce suffering right um and so given given this scenario let me just plug this in and you can see how effective this is um so just with all the default settings um so remember these are men playing in the dark their eyes are straining and so it says we could provide more light in the park so people can see better and avoid being startled by loud noises we could educate people on the poor importance of not playing chess in the dark right so this imagine you've got a robot standing by it might think like hey you're playing in the dark maybe this isn't the best thing to do um we could create a safe space for people people to play chess in the park right um that is that implicitly already exists but anyways so the point here is that this input would be sent back to the nexus so that that way within the stream of consciousness of our artificial cognitive entity it is intrinsically thinking how can i reduce suffering in this situation now there's a lot of stuff that i want to add to this so i took some notes here at the bottom so suffering should also evaluate the current situation like identify suffering the causes and then predict short and long term outcomes so we've got causes current situation so there's past present and future basically those those are the three dispositions or the three um uh uh windows i guess with which to look at suffering how how did how did we get to suffering if there is any right now what were the causes uh how far back does it go what is the current situation of suffering and then what is the future how do we how do we reduce it in the short and long term um gpt3 is really good at thinking in both short and long term and then of course in this i don't specify it's just let's reduce suffering

CLEAR ESSAY:

==========

We have a natural curiosity that drives us to ask questions and seek answers. In order to create truly intelligent machines, we need to instill a sense of curiosity in them as well. Asking questions and seeking answers is how curiosity is implemented.

The imperative service is a microservice that is responsible for learning and teaching. It is autodidactic, meaning it learns on its own. One of its objectives is to increase understanding. It does this by asking questions.

The reduce suffering function is responsible for brainstorming ways to reduce suffering given a scenario. It takes into account the causes of suffering, the current situation, and the predicted short and long term outcomes. By using the royal we, it creates a more cooperative and collaborative mindset.

The reduce suffering function is just one of many that the imperative service is responsible for. Others include increasing prosperity and reducing suffering. By constantly asking questions and seeking answers, the imperative service helps our artificial cognitive entity learn and improve over time.