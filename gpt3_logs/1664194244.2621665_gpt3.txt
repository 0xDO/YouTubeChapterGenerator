The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: hey everybody David Shapiro here for part two of my fine tuning tutorial um so just a quick recap um I wrote a script that would synthesize plots and uh what I did was I had a battery of genres modifiers places and periods and so what that ultimately was fed into was this prompt here where I also populated a uuid to add a little bit more entropy I said imagine a complete and detailed plot outline for a genre film set in a place during a period the story should be modifier and so what that would look like is um or what what the output would look like would look like one of these so 1922 France Augustine a young woman etc etc so what I did was I generated 396 of these the minimum for fine tuning with gpt3 is 200 samples and what I promised this this episode was to um to one show data augmentation and to data prep so data augmentation in this case is about removing or modifying samples that are no good so I want to I want to create something that will take as an input something that looks like this genre crime and mystery location America period the 20s modifier tragic and heart-wrenching that sounds like an awful story right okay so um we will we we want to be able to just put in that and it'll synthesize a plot for us and I can if I find the uh the matching file that has the same name so America 1920s crimes mystery tragic heart wrenching we can go see what it found um so it looks like it's the fourth one down if it's in alphabetical order um so the film opens with a shot of the protagonist a young woman etc etc uh the woman's family is grieving her loss so she died uh so on and so forth okay so you see this one this one is is a good length it's 1800 characters long um you know the the film ends with the killer being sentenced to life in prison that's great it's got the whole plot however if we if we sort our completions by size um it just says mismatched okay uh oh and this one the story is set in Egypt during the Renaissance so this isn't actually a plot outline so basically we don't want to use these samples these are bad samples so what we're going to do is in order to augment our data set I just generated a whole lot more than I'd need and because length is the primary thing that I want I'm just going to delete the ones that are too short so any ones that are one kilobyte in length are gone Tada all done um and don't worry they're all backed up in git so if you want to go look at them you can so now I'm left with 202 and the shortest one now is um oh yeah no we don't need that um the shortest one now is well here let's close these uh don't get rid of those just clean it up okay so the shortest one now is um you know uh is what is it it's 1030 characters long so it's still a little bit on the short side but I deleted fully half or almost half of the of the samples generated so basically I'm going to say okay let's take this behavior that gpt3 can already do and let's fine tune it for the longer side right and there's all kinds of other things you can do to augment your data but basically these samples all look good they're a coherent story so let's just get rid of the ones that I don't want so that's step one of data augmentation is get more data than you need and delete the bad samples um that is the easiest way another thing you can do and it's way more labor intensive though is you go in here and you like manually edit one um but I'm not going to do that because that's going to take way too darn long um that's a more advanced uh data augmentation methodology so I've got another script that I reuse from from other uh from other projects called find prepare fine-tuned data we've got to modify this though because instead of just having one conversation this was this was a script that I used for find preparing chatbot data so but instead we got to pull from prompts and completions because basically what we want to match a prompt that looks like as you'll recall this guy to an output to a completion and so what we'll do is we will say files equals OS Lister and the source sourceter is actually going to be completions right because if you look at the file count there's now going to be more prompts there's 396 prompts but there's only 202 completions so I want I don't rather than like try and true them up I'm just going to use this as the single source of truth because there's always going to be a matching file with the same name in The Prompt um and so then that's where we'll start and so we'll say Okay so the files is um is list in completions so data equals list uh is is um empty list so lines uh I don't think we need to split lines because this isn't chat data so we're just going to do um we're just gonna do uh let's see text equals um open file we don't need to split because it's good as it is um and then the prompt is just going to be um oh here so this is actually the completion um so then the prompt equals open file uh and then we'll have Proctor is just going to be prompts so then we'll say prompter plus file oops file not full file there we go so then info equals prompt prompt completion completion and data append info and so then with open survey.json L we're going to rename this and so we'll just call this plots dot Json L as out file we'll dump it out and this runs really quick do a quick time check we're at six minutes so as promised this is going nice and fast python I'll show you what the data looks like in just a second because it's really important to understand how your data is actually supposed to look um okay so you see that ran and there should be a brand new file called plots.json else 326 kilobytes it should be 202 lines so if we go down to the very end 202 lines perfect so let's grab one of these well first let's do language J dot Json so you can see okay prompt here's the prompt and then here's the completion so all these prompts and completions are matched up so basically what we're going to do and this will be in part three I'll show you how to actually use a

CLEAR ESSAY:

==========

In part two of my fine tuning tutorial, I showed how to data augment a script that synthesizes plots. I did this by generating a lot of data, then deleting the bad samples. This left me with 202 samples, which is the minimum for fine tuning with gpt3.

In order to fine tune my script, I need to match each prompt with a completion. I have a script that does this, but it is designed for chatbot data. I need to modify it to work with my plot data.

The modified script will take as input a prompt and a completion. It will then match the prompt with the completion and add the information to a survey.json file. This file will be used in part three to fine tune my script.