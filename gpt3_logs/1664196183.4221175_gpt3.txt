The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: step-by-step tutorial next okay so we've got it running what is neural search this will give you an overview of you know blah blah the curse of dimensionality i remember that when i started learning about support vector machines um i definitely recommend you read this if you're not familiar with neural search or embeddings and so on and so forth um and then okay so you scroll all the way down here's the um here's the uh the like the full thing um here let me go into q-drint okay it doesn't have the data stored here because it says that it will store it oh i guess uh let's see run the service inside the docker you should see output like this present oh okay so all right the that the dash v that will do that that'll do the storage so what i'm doing right now is not going to be persistent save two and will be persisted even if you recreate the container yeah so what this does is it'll map the um the internal storage to the external storage um because one thing to keep in mind is that containers are exactly that they're fully self-contained unless you map stuff from inside to outside the virtual environment um okay so let's go ahead and do this so now we need so now we need to actually do the python bit so we'll do pip install qdrint client so this will install the the python client for us ta-da there we go so let's go ahead and start a new um python i think we'll just copy this and we'll save this q-drint demo python and so we'll say huge rent demo pi okay um so when you instantiate the quadrant client i'll just call it quadrant because that's easier to say i don't know how they say it but um so from quadrant client import quadrant client quadrant client equals quadrant client local host port 633 okay cool all all standard all straightforward um all right let's come back over here so now we're going to re why does it say recreate collection interesting it says recreate instead of create let's see if that works um okay so cosine similarity okay oh so dot product and cosine similarity are different things i just learned that um and so the distance tells you how it's going to calculate it um [Music] okay so actually i guess this will be um we'll just save this as a separate separate one all right so let's run this and see what happens python quadrant demo and it gave no output i guess if we come back to our curl commands we can probably test it so this was the this was the test collection but the one that we just created was called startups so let's redo this and instead we'll do startups and there it is okay so we verified that it works um but what i'll do next is well here that's that's fine um start a new one we'll do python and so this will be okay create an iterator over startup and data vectors see where does this come from startups we should have startups records file in startups.json where did that come from did i skip something i probably skipped something it wants me to have something where is this file startups list raw data can parse data can be found at this link there it is okay so let's come back here and we'll do uh save link as um and then we'll come here we'll do cudrant and we'll do startups dot well here that's yeah dot json okay make sure that it's here there we go startups.json all right so now um first we will do we'll rename this to quadrant instantiate um so there we go all right no and we'll reopen that quadrant instantiate cool close that and we'll do a copy of this quadrant instantiate and then we'll call this quadrant populate yay quadrant populate all right so then we will edit that with notepad plus plus and we'll come back over to their tutorial now that i figured out what i was missing and then we will go down to here all right so fd equals open startups.json so there it is payload equals map json loads dot fd payload is now an iterator okay here we load all the vectors into memory numpy array works as an iterable for itself startup vectors oh i need to make the vectors where's the startup vectors see i do everything the hard way is that what map did no startup yeah that's got to be a file somewhere hmm i vaguely remember seeing sentence transformers yeah pip install make a search api yeah because because the the this this data was pre-prepared somewhere but i don't know where i don't know where that's fine open terminal um pwd dir uh cd quadrant uh cd stored sure okay i don't know but we will go ahead and try maybe i'll just make it myself tip install sentence transformers so sentence transformers is pre-trained on bert and other things so that you don't have to use um google universal sentence encoder as a microservice um so we'll see how fast it is um yeah actually how long is this video oh wow we're at 27 minutes okay i might not make it through the whole tutorial but we've gotten to a good good we've gotten a good start so i'll probably uh stop the video here in a second um and then i'll finish working on this actually i'll go ahead and pause it and figure this out yeah and then we'll we'll we'll get this done i'll just figure i'll get the uh the um this part this part figured out okay be right back okay we're back um i couldn't find the files so i just made my own i copied logs from a recent project so i've got 25 sentences here um and i'm going to get the embeddings myself so i just wrote a little thing to load those and then we're using the all mpnetbase v2 from sentence transformers so then we'll just do print sentence embeddings and we'll go from there so just show you where it's at so far it takes a second to run so there you have it you've got a list of embeddings all right so now we will go back over to i had to open up a few things um that's mine uh tutorial there we go okay so we will come here and then we'll come back down to here all right so i'll leave the the collection name startups i'm not doing startups so vectors will change that name to embeddings and then um payload will be payload i think that should work um it might prefer that that's

CLEAR ESSAY:

==========

In this video, we learn how to use the Neural Search algorithm to find relevant information in a high-dimensional space. We also learn about the curse of dimensionality and how it can impact machine learning models. Finally, we learn how to use the Quadrant client to populate a collection with data vectors.