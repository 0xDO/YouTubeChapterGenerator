The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: we'll replace hint with answer and all this will be obfuscated in the back end so that's fine so then we'll say response equals gpthree completion prompt so that will give us tim's output and let me make sure gpt3 completion okay so this line right here what i do is i do two things is i i strip it so that means that any white space that's padding it it removes that so if there's new lines extra spaces whatever it removes that but then i also have this line here which for any um any interior white space so let's say that the output is like here's one sentence and then it gives a double new line and then another sentence i don't like that especially for chat so i say let's replace those double new lines with just one space so it'll kind of compress it all into a single single what am i trying to say paragraph okay so we get the tim's response and then we have to get the vector for tim's response and add it to well i guess first we can just we can just output it but yeah so we'll do vector equals gbt3 embedding response um so then we'll say uh save the output um line in looks like that yeah okay so we get the vector and then um info equals let's see line out equals tim and then we'll do response so that should be good and so then we say info equals excuse me line out and vector and then we save it so conversation pin info so that means everything is saved and then we just print line out and that should be good is this done i think it's ready for testing i am so scared of all the bugs that this is gonna happen okay so yeah we only have two places where it prints um there's a lot of steps in here a lot of places that can fail oh i'm nervous um yeah we do need some debug um so we'll do we'll do that because there's the search part that where it can fail old line so when i put in the first one it's just going to return the original line and that'll be actually no i think i've got it so it'll skip that yeah if recent vector equals that it'll skip it okay so for i and all lines um this will actually fail uh okay so if laying all lines equals um actually no we'll just say less than or equal to we'll just say if it's less than or equal to count return [Music] list yeah that makes sense logically that makes sense so we'll just say we'll just return an empty and empty list and that'll solve a lot of problems um okay so that's fine so we won't have to worry about that so old lines will be empty so then we'll just join old lines that's an empty list that's fine it'll skip over it convo block and then we'll add convo block equals convo block dot strip so that it doesn't have any excess padding um okay so that's where that could go wrong the gpd3 embedding i've used that plenty of times let me make sure i'm using the right engine text similarity ada okay i think that's right because we're just we're looking for similar lines of dialogue we're not doing querying for a document because there are different um let's see open ai embeddings um there are a bunch of different engines that you can use so classification search topic clustering recommendations so yeah clustering regressions anomaly detection visualization so this is what i'm using text search so this is where you're saying like these models help measure whether long documents are relevant to a short query so this is if you want to search like if you have a um if you're if you have a question and you're looking for it for the right document this is going to be a different embedding and that's not what i'm doing i'm just comparing um like apples to apples so that should be fine all right all right so we get our convo block generate a search query um so we've got this the prompt wikipedia this is here single most relevant wikipedia article that seems like it worked um i had to fix it because it wanted to give me a list of stuff that i didn't want title equals gpth3 completion prompt wiki equals fetch wiki um we pass it excuse me the title fetch wiki so we try page wikipedia um uh title so if it does if it if it gives us the right title it's fine otherwise we'll do a search and then we'll just grab whatever wikipedia thinks is the most relevant article great um okay so this will give us one article and then let's see so then we say generate a specific follow-up question to use to query the external information so we say okay so we've got our follow-up prompt um which is this guy so it says given the following conversation and the topic and the topic is is populated by the title okay so we're going to say that the title is the the wikipedia article so we say okay so generate one follow-up topic question to ask about this and so that means that it'll say like okay rather than just say like because like for instance if you arrive at the list of roman emperors okay we're not gonna stuff this this whole thing we want like an actual like last emperor emperor there we go and so like if we say like who was the last emperor um it should like zero in and i think it did actually um so constantine the sixth let me go back to this is that who it said constantine the eleventh interesting okay anyways point being we wanna we wanna actually ask a question of this external information we get the answer to that and that will be embedded in the prompt as a hint and then tim can use that to answer oh boy okay i don't know if this is going to work but yolo cmd cd long term python chat no such oh whoops open ai api key what do you mean i need an api key i didn't copy it over so we'll copy my api key from somewhere else and actually i need a bio break i apologize and then we'll get going okay i'm back um let's see where were we yes all right um i'm actually going to add a debug function def save debug and so then we're going to do label content and we're going to basically just copy the copy this so but instead we're going to do debug and the file name will have label in it and then debug out and we'll just do content okay so what i'm going to do with this debug function

CLEAR ESSAY:

==========

We'll replace hint with answer and all this will be obfuscated in the back end, so that's fine. So then we'll say response equals gpthree completion prompt so that will give us tim's output. And let me make sure gpt3 completion okay.

So this line right here, what I do is I strip it so that means that any white space that's padding it, it removes that. So if there's new lines, extra spaces, whatever, it removes that. But then I also have this line here which, for any interior white space, so let's say that the output is like here's one sentence and then it gives a double new line and then another sentence. I don't like that especially for chat, so I say let's replace those double new lines with just one space. So it'll kind of compress it all into a single paragraph.

Okay, so we get the tim's response and then we have to get the vector for tim's response and add it to our conversation. So we'll do vector equals gbt3 embedding response. And then we'll say save the output line in looks like that. Yeah, okay. So we get the vector and then info equals let's see. Line out equals tim and then we'll do response. So that should be good. And so then we say info equals line out and vector. And then we save it so conversation pin info. So that means everything is saved. And then we just print line out and that should be good.

Is this done? I think it's ready for testing. I am so scared of all the bugs that this is going to happen. Okay, so we only have two places where it prints. There's a lot of steps in here. A lot of places that can fail. Oh, I'm nervous. Yeah, we do need some debug. So we'll do that because there's the search part that where it can fail.

Old line. So when I put in the first one, it's just going to return the original line. And that'll be actually no. I think I've got it so it'll skip that. Yeah, if recent vector equals that, it'll skip it.

Okay, so for i and all lines, this will actually fail. Okay, so if laying all lines equals actually no, we'll just say less than or equal to. We'll just say if it's less than or equal to count, return an empty list. Yeah, that makes sense logically. That makes sense. So we'll just return an empty list and that'll solve a lot of problems.

Um, okay, so that's fine. So we won't have to worry about that. So old lines will be empty. So then we'll just join old lines. That's an empty list. That's fine. It'll skip over it. Convo block and then we'll add convo block equals convo block dot strip so that it doesn't have any excess padding.

Um, okay, so that's where that could go wrong. The gpd3 embedding. I've used that plenty of times. Let me make sure I'm using the right engine. Text similarity ada. Okay, I think that's right because we're just we're looking for similar lines of dialogue. We're not doing querying for a document because there are different open ai embeddings.

There are a bunch of different engines that you can use. So classification, search, topic clustering, recommendations. So yeah, clustering, regressions, anomaly detection, visualization. So this is what I'm using. Text search. So this is where you're saying like these models help measure whether long documents are relevant to a short query. So this is if you want to search like if you have a question and you're looking for the right document, this is going to be a different embedding. And that's not what I'm doing. I'm just comparing like apples to apples. So that should be fine.

All right, all right. So we get our convo block generate a search query. Um, so we've got this the prompt wikipedia. This is here single most relevant wikipedia article. That seems like it worked. I had to fix it because it wanted to give me a list of stuff that I didn't want.

Title equals gpth3 completion prompt. Wiki equals fetch wiki. We pass it the title fetch wiki. So we try page wikipedia. Title. So if it does if it gives us the right title, it's fine. Otherwise we'll do a search and then we'll just grab whatever wikipedia thinks is the most relevant article.

Great. Um, okay, so this will give us one article and then let's see. So then we say generate a specific follow-up question to use to query the external information. So we say okay. So we've got our follow-up prompt which is this guy. So it says given the following conversation and the topic and the topic is populated by the title. Okay, so we're going to say that the title is the the wikipedia article. So we say okay. So generate one follow-up topic question to ask about this. And so that means that it'll say like okay rather than just say like because like for instance if you arrive at the list of roman emperors, okay, we're not gonna stuff this this whole thing. We want like an actual like last emperor emperor. There we go. And so like if we say like who was the last emperor, it should like zero in. And I think it did actually. Um, so constantine the sixth. Let me go back to this. Is that who it said? Constantine the eleventh interesting.

Anyways, point being we wanna we wanna actually ask a question of this external information we get the answer to that and that will be embedded in the prompt as a hint and then tim can use that to answer.

Oh boy. Okay, I don't know if this is going to work but yolo. Cmd cd long term python chat no such whoops open ai api key what do you mean I need an api key? I didn't copy it over. So we'll copy my api key from somewhere else. And actually I need a bio break. I apologize and then we'll get going.

Okay, I'm back. Um, let's see where were we. Yes. All right. I'm actually going to add a debug function. Def save debug. And so then we're going to do label content. And we're going to basically just copy the copy this. So but instead we're going to do debug and the file name will have label in it. And then debug out and we'll just do content.

Okay, so what I'm going to do with this debug function is I'm going to use it to print out the conversation at each step. So that way, if something goes wrong, I can go back and see what happened.

So we'll do that for the search part. And we'll also do it for the convo block. So that way we can make sure that everything is being saved correctly.

All right, so that should do it. I think we're ready to test this. Wish me luck.