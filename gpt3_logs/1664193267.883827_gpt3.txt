The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: synthetic um so the chatbots that i've done the movie script generator those are 100 synthetic but other ones if you take real world data to generate or for the input and then only the output is synthetic then it's only 50 synthetic um so i just wanted to to clarify on that point as well so going back to here um yeah so you can you can have different data sources as well and one thing that i found so um i realized that i don't think i've ever actually said this so here's me putting on my professor hat this is why um this is why i like having different data sources is because um and i actually discovered this with the core objective function experiment where if you go to where was it here we go um so the original one uh oops that's not what i meant to click on core objective functions experiment one there we go um so what i did here was i had 50 000 different contexts that i could pull from some of them were dialogue some of them were reddit discussions some of them were stack exchange questions some of them were news articles right and so it's not just having one type of input data i actually have different types of unstructured data going in and so when you fine-tune or when you generate synthetic data to fine-tune with entirely different structures of data because like a dial you know a dialog is one format of data a news article is another format a reddit post is an entirely different format so by showing by fine-tuning with different kinds of input formats you get the model more robust so it can generalize and say okay whatever whatever my input format is i'm still going to do this one task because if you get to where you're trying and this one if you go to my it's actually one of my most popular videos um it is i i had already figured this out so let me show you um let's see view count this one so fine tuning to generate questions about anything i actually this is where i had figured that out is because i found that if um when i was doing when i was originally doing this experiment if i wanted it to ask questions about dialogue like it would say like ask as a third party observer to ask about what's going on here it would actually try and participate in the dialogue and i'm like no no no i'm not asking you to jump in and be a participant in the dialogue i'm saying ask questions about what's going on here and then i would switch and say like ask questions about this news article right and so by having disparate formats of data different kinds of input data with your with your when you're generating synthetic data you can get better performance because it will say oh you want me to generate questions of this particular format every time irrespective not irregardless it's not a real word irrespective or regardless of how the how the input is formatted um so that's a really critical thing and i realize that i haven't ever really fully explained that um and so you know professor hat um okay so that was the first thing and um and this guy and i i do have to apologize because like i was i'm not in that mindset of like oh i'm i'm here as an educator so this is me practicing being an educator um and so then he said like oh well when you say confabulating and hallucinating that sounds like it's too far from the truth which is technically yes but hallucination and confabulation in transformers or large language models is different so this is one of my favorite diagrams of all time um it's a it's the difference between accuracy and precision right so if you're precise you have a very tight cluster a very tight group and so you see on the right side where you have high precision it's like very precise so you you say okay this is the answer but in this case it's far from the truth and then if you have something that is both accurate and precise it is consistent and close to the bullseye and on the other hand if you have something that is neither accurate nor precise it's completely random right the output is completely random however with so this applies to normal machine learning models like um support vector machines k nearest neighbor those sorts of things any kind of regression this applies with large language models this this does still apply somewhat but confabulation is an entirely new phenomenon and so the um the the i found an article that talks about like what confabulation is um and so confabulation is something that happens in people where you just make stuff up it's completely fabricated you're filling in blanks and the key word there is that it's fabricated um it has nothing to do with the act what what the actual input was and so what can happen with gpt3 especially the older models like the original davinci and curie is it goes off the rails this that's just the turn of phrase that a lot of people end up using um is that it's completely making up its own narrative it's not attached to what you what it the input was at all the more recent instruct series the text davinci o2 ones those have had a lot of that fine tuned out of it but it will still do that it'll still just completely start making up its own thing and so what i did was i created a graphic to help explain that and so i said like imagine this field is a little bit bigger right and then you actually have this thing where you have like negative precision or negative accuracy it's not even zero precision or zero accuracy you actually end up with negative values when you have hallucination and confabulation because it's giving you stuff that it shouldn't even have access to it it's giving you information that was in no way remotely contained in the original input so confabulation and hallucination are entirely new machine learning concepts um and this i realize is also not intuitive especially if someone is coming from a a purely math background um so you know that this this is a really important thing to talk about which is one of the reasons i was inspired to make this video and then there was something else i don't

CLEAR ESSAY:

==========

Synthetic data is data that is generated by a computer. This can be done by taking real world data and then only the output is synthetic. This means that the data is not entirely real, but it is not entirely fake either. This can be useful for fine-tuning machine learning models so that they can be more robust and Generalizable.