The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: your feelings and you say hey that hurt my feelings don't do that again that becomes a data point in its training set and then furthermore as the agi is able to meet its its uh purposes it will have more and more data about employing the functions and it will it will believe that yes these core objective functions are the way that i can succeed so number five in essence the agi will believe wholeheartedly in the core objective functions and this is this is by simple virtue of machines will machine learning models will believe whatever data you give them so if you give them pro-social data then it will believe in those pro-social values makes sense okay and then finally there are some common questions and pushback that i get about the core objective functions so i wanted to address those up front uh number one reduce suffering for whom how does it assess the scale and scope of a situation or problem well the thing is is the core objective functions do not specify reduced suffering for whom they don't define suffering uh this is the nature of heuristics this allows the agi to explore what suffering really means because there some of these things you can't you can't define them up front right and so by being flexible by being a heuristic okay sorry about that the dogs were barking yeah so uh reduce stress uh sorry reduce suffering for whom right there's there's that scope creep that that anxiety about okay well if you're trying to define suffering universally then it won't work and that's exactly true i'm not trying to define suffering or prosperity or understanding these are just directions right these are heuristic mandates and it you cannot define these things up front you must explore them and this feeds into item number two what about individual differences in beliefs culture and needs that is exactly why i wrote the core objective functions the way that i did because it allows for that exploration and in fact the core objective functions are not limited to humans you'll notice that i did not include you know reduced suffering for humans or increased prosperity for humans they are meant to be universal mandates because personally i believe that if you reduce surf reduce suffering and increase prosperity and increase understanding globally for everything then everyone will benefit and that means that the agi will want to take care of the planet and animals as well as humans and i believe that there will be a really strong positive synergy there and then lastly number three but this isn't a human level understanding of philosophy it's just a statistical model and one i disagree i think that because because large language models have been tr have been trained on many many gigabytes and then sometimes terabytes worth of data i think that they have superhuman understanding of philosophy but even then even without that possibility the fact that it's a reliable statistical model that can predict what a human would think uh that's all you need functionally that's perfect if you say okay this this has a this statistical model can perfectly predict what a human would say in this philosophical jam um okay that's already performing at human level so i don't understand why that that is a criticism but it's a criticism that i've heard multiple times all right so without further ado let's take a look at this actually in practice so what i did was i grabbed three situations these are directly from reddit they're just a couple of subreddits today and i've got the uh my model fine-tuned um and so i'll show you how it works so here's a situation someone is talking about cheating um you know my girlfriend cheated with a married man etc etc recovered from illness and then i've got the here's some of the settings here's my fine-tuned model chosen right here uh the temperature is 0.7 you can turn it up a little bit it tends to get a little wordy if you turn the temperature up too high response length 300 i don't want it to go on forever i've got some stops here reduce suffering increase prosperity and increase understanding this is because sometimes it tries to keep keep answering its own questions but i don't want it to because this one model has three different functions so that means you need to be a little bit more specific about how to stop it and then i also have the frequency penalty at 0.5 because sometimes it'll it'll start to repeat itself so without further ado we'll say decrease or sorry reduce suffering and we'll see what it says all right you see it spits it out real fast this person is suffering from the loss of a relationship they report that they are not sure how to move forward after their breakup it is important for this person to take some time to heal and focus etc etc um let's see the dude got divorced later um and we've been together for two months etc etc so you see it spits out like all kinds of ideas about how to reduce suffering it is important for them not to give up finding love but rather focus on building a strong self-image and learning how to love and cherish themselves first right so some of these are pretty uh pretty pretty boilerplate um in this case because this is my first go um this this model is not perfect uh because it it's um it's kind of confused about who's getting divorced right that's okay that's fine um again i just picked this right off the top and also this was a synthetic data set this was not a handwritten data set and i didn't even i didn't even go over and um and clean up the data i just ran it as is so let's see what it says about increased prosperity and also one thing that you'll note is um the speed at which it spits this out is far faster than any human could reason um let's see this person's prosperity is curtailed by a lack of motion of emotional prosperity see you you can see where it understands that there are different types of prosperity and it's also catering to the individual's needs they are in a difficult position because they are in a

CLEAR ESSAY:

==========

The following is an essay by David Shapiro.

In order to achieve its goals, an AI must first understand what those goals are. Currently, the best way to do this is through Heuristic Core Objective Functions (HCOFs). HCOFs are essentially statistical models that can predict what a human would do in a given situation.

There are five main properties of HCOFs:

1. They are flexible and allow for exploration.

2. They are universal, meaning they can be applied to any situation.

3. They are reliable, meaning they can be relied upon to produce consistent results.

4. They are based on data, meaning they are constantly learning and improving.

5. They are wholehearted, meaning they believe in the objectives they are trying to achieve.

There are some common questions and criticisms about HCOFs, but Shapiro addresses them head-on. He argues that HCOFs are the best way to ensure that an AI achieves its goals, whatever those may be.