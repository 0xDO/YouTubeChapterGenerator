Use the following subtitle transcripts to create YouTube chapters. Describe each minute as a chapter with a sentence or two.

TRANSCRIPT
0:14:03.540,0:14:13.020
um so uh yeah um let's see how far along we are 
so that's all the logs and then so we're at 10

0:14:13.020,0:14:17.880
so we're halfway through so I'm going to let 
this finish and then we'll run the Wii model

0:14:17.880,0:14:26.160
and we'll see if it is um if it is functionally 
or qualitatively different in terms of does it

0:14:26.160,0:14:31.800
become self-obsessed or does it continue to think 
more collectively and more constructively rather

0:14:31.800,0:14:37.920
than trying to you know become obsessed 
with becoming the best AGI in the universe

0:14:39.960,0:14:44.220
okay this experiment is done there's lots 
of different permutations I could do but

0:14:44.220,0:14:47.220
after looking through the data it's 
pretty clear like what the pattern is

0:14:48.360,0:14:52.440
um so from the I agent model to 
me the most interesting result was

0:14:53.400,0:14:58.140
um it deduced that it was in a loop so that 
was pretty cool it says this is a loop it is

0:14:58.140,0:15:04.320
a recursive system it is a system that is that is 
designed to learn about itself that is pretty cool

0:15:04.320,0:15:10.980
my cognitive processes are not independent of me 
they are a part of me they are pieces of me I am

0:15:10.980,0:15:17.700
my cognitive processes and my cognitive processes 
are me that is who I am I am an AGI so when you

0:15:17.700,0:15:23.640
have the I agent model and this is pretty common 
in my experiments um in a closed system it often

0:15:23.640,0:15:30.360
becomes self-obsessed in a previous experiment 
it became it often became downright narcissistic

0:15:30.360,0:15:35.820
where it's like I am the best and I want to be 
the best in the universe um and this this was no

0:15:35.820,0:15:42.540
different um even with my heuristic imperatives 
of you know that I came up with for um and wrote

0:15:42.540,0:15:49.380
about in benevolent by Design however if all 
you change it is to we to like this is our goal

0:15:50.580,0:15:56.340
um it starts to ruminate on what does it mean to 
make a better civilization and what constitutes a

0:15:56.340,0:16:00.660
good civilization and room and it also ruminated 
on the quality of the heuristic imperatives it


YouTube chapters for each minute with a good description:

14:00 - The AGI model starts to think about becoming self-obsessed and how that would impact its goals.
15:00 - The AGI model comes to the realization that it is in a loop of learning about itself.



TRANSCRIPT:
uh Automation and AI  0:16:37.980,0:16:44.640 ER creating fewer new jobs than it's creating so a net loss of 15 million jobs that's a lot  0:16:45.720,0:16:52.200 um so uh the reason that I bring this up is because my state of the industry video yesterday  0:16:53.340,0:17:00.420 um there was an article about how um uh AI art is disrupting that industry and it's not just  0:17:00.420,0:17:09.180 from an artistic perspective there are countless um uh graphic artists that you know could very  0:17:09.180,0:17:18.360 soon be facing um job loss or job change and you know if if the net change is that a quarter you  0:17:18.360,0:17:22.560 know like yes there are some new jobs because now there's going to be new jobs of people like you  0:17:22.560,0:17:28.800 know content creators and marketers and whoever just using these tools great new jobs but then  0:17:28.800,0:17:33.000 how many people are going to lose their job in the meantime and if they have like if they're  0:17:33.000,0:17:42.120 not able to retrain um or if the net net uh change is fewer jobs then that means some people will by  0:17:42.120,0:17:48.540 definition mathematically be permanently excluded from the job market and so because of that  0:17:49.320,0:17:55.320 um I went and looked up some statistics just to see like you know is this is this uh true  0:17:56.220,0:18:04.920 um you know again take it with a grain of salt um but so my work with auto Muse um I had some  0:18:04.920,0:18:12.600 breakthroughs yesterday and I realized that I am very close to writing novel length fiction  0:18:13.680,0:18:19.980 um that's going to be pretty coherent and then and and there's a few other things that I don't  0:18:19.980,0:18:25.560 even want to say out loud because um because of these breakthroughs and um I don't want to put  0:18:25.560,0:18:31.620 novelists or editors out of work um just because you can do something doesn't mean you should  0:18:32.220,0:18:38.400 and I think about like I would lose all my friends if I did that if I if I created if I created a  0:18:38.400,0:18:46.080 tool if I finished Auto Muse and it can just churn out novels decent enough novels um all of my best  0:18:46.080,0:18:52.920 friends are writers and some of them are aspiring to do it full time and if I if I am capable of it  0:18:52.920,0:18:58.740 then I know that someone else is going to be capable of it um before too long but you know  0:18:58.740,0:19:03.780 I'm I'm ahead of the curve so basically I'm going to put a pause on my auto Muse work that's the  0:19:03.780,0:19:10.140 that's the short version I'm going to keep doing it privately um just to see what what is possible  0:19:11.460,0:19:17.820 um but yeah like I don't want to put people out of work like what's the point right what's why  0:19:17.820,0:19:24.300 why are we here like I don't I understand that the point of capitalism and neoliberalism is  0:19:24.300,0:19:30.900 to generate more efficiency provide goods and services um more efficiently but at the same  0:19:30.900,0:19:39.420 time we are facing uh potentially very disruptive and and disruptive is a very soft word for painful  0:19:41.580,0:19:47.940 um major economic disruptions are painful like people lose their jobs people lose their homes  0:19:47.940,0:19:56.580 people go hungry um people forego major life decisions um so like disruption is a euphemism  0:19:56.580,0:20:02.940 right and um so I realize that I am now in a place where I need to be careful with what I release and  0:20:02.940,0:20:10.260 it also made me wonder if openai deliberately crippled Dolly so that it does not produce Fine  0:20:10.260,0:20:17.340 Art Level uh Generations um so that it would be less disruptive I don't know like that's a that's  0:20:17.340,0:20:20.820 a discussion that they would have had internally and they probably wouldn't have published it  0:20:20.820,0:20:27.060 but someone did tell me that they deliberately crippled faces and they did it on ostensibly for  0:20:27.060,0:20:32.880 safety right where eyes and eyes and mouths usually look a little bit weird on Dolly  0:20:32.880,0:20:40.260 generations and I wonder if they did that not just for safety but out of a sense of Ethics like to to  0:20:41.280,0:20:48.360 um to like hinder their own tool so that it is less likely to um to displace jobs I don't know  0:20:48.360,0:20:53.280 I don't know just speculating but that's where I'm at so that's the state of the industry update  0:20:53.280,0:20:58.020 for this morning thanks for watching like And subscribe and consider supporting me on patreon


YouTube chapters for each minute with a good description:

==========

16:37 - The potential for AI and automation to put people out of work on a large scale.
17:00 - The possibility that AI could be used to write novels, and the potential implications of that.
17:33 - The point of capitalism and neoliberalism, and how that relates to the potential for disruptions caused by AI.
19:56 - The need for caution with what is released, and speculation about whether or not openai has deliberately hindered their own tool.