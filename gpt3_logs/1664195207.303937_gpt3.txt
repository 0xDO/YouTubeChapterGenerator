The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: figure out what to do so one possible architecture then is that we've got an outer loop but then we've got multiple mines kind of fighting over what to do and the outer loop basically takes a consensus that says okay you say we should talk i say we shouldn't this one up you know like if you've got three then you have a tie breaker so it's like should we grab that pot well you know two of them might say no don't it's hot and then the third one says oh go ahead and grab it it's fine right and so by having those parallel processes all kind of debating that gives you a bunch of possibilities these different these different inner loops you know primary mind secondary mind tertiary mind however many there are they should all be slightly different they should use different models different prompts they should use different different architectures so that one they can operate at different speeds but also they can have different specializations and different strengths and weaknesses and so maybe what happens when someone has dissociative identity disorder is basically they have the like their brain loses the ability to keep track of these different cells and they they fragment and differentiate um from each other um rather than staying integrated and so this is where um jungian psychology actually kind of comes back into play i'm really surprised more people aren't talking about jungian psychology because he talks about this fragmentation possibility anyways i predict that that's going to come back in a big way um you mark my words um okay so this is this is another possibility of how we can design an artificial cognitive entity in the future and then there's one last possibility what what what happens if we reverse this what if we keep one nexus but then we have multiple loops interacting with one nexus so in in this case each and every other case each nexus is only the link between two loops so it's like a figure eight right so this loop shares some information with this loop and so on and so forth and you could you could expand this out forever right where it's just every loop you know every intersection between two loops is one nexus um you see that's the same pattern over here you know this is the most basic unit and then here's where it's a chain right so you can create chains you can create webs but what happens if you have multiple loops interacting with one nexus so i got this idea from watching westworld so hbo's westworld is a show where there's robotic hosts and it's a big giant fantasy land and you can like have sex with super hot sex robots or shoot them or go on adventures with them or whatever but during the first season one of the things that happens is um they explore like okay well how do you make sure that the the hosts the robots don't break immersion and what happens is anything that they're not supposed to see is erased from their stream of consciousness so what happens then if you've got you know their their conscious loop but then you've got a hidden second loop that is that is monitoring that database and just selectively deleting stuff out of it so like oh you're not supposed to see that gone right it's that simple you just have something that says you're not supposed to see that you're not supposed to think that delete it and so that this model whoops come back this model could be used for um self-censorship right so say for instance you have a robot that um and it's got a safety loop right it's got it's got a self-censorship loop or a safety loop that says oh you just had the idea of stabbing your human let me just delete that possibility right and it's not even conscious it's a safeguard that's operating in the background and then you you'd have that interlocked so that if that loop stops the robot shuts off right so you have you have like multiple loops interacting with um with a single nexus and they could all be you know contributing or deleting stuff so that's that's kind of where i'm going i've got the books that inspired all this the show westworld that's a good that's a good bit of fictional inspiration um irobot the will smith movie from i think 2005 also good inspiration for this stuff okay now that you've got the background let's get coding so let me zoom back in a little bit um new so we're going to call this um a cog experiment 0-1 so artificial cognitive entity um public experiment um inner loop so public add a readme file add a license we'll do mit and then we will go ahead and clone this down and get clone whoops you need a space there buddy okay so then i i copy paste i reuse a lot of code um just that's the fastest way to do it uh let's see what was i working on most recently medical question answering so i will just copy my excuse me git ignore and my open api key open ai api key just copy those in okay so then we will start with i'm not going to worry about doing voice or anything um because that's my my smart home device was basically i wanted to have like the computer from star trek where you're just like computer can you help me do this thing right i wanted to create like a super sophisticated um super advanced version of like siri or alexa or cortana um and i was working on that but then i realized i needed to take a break and figure out cognition first um and then you know maybe once i get some help i can work on the the outer loop of you know because like one of the hard parts there there's a bunch of stuff that's harder than you might think like um you know alexa you can interrupt alexa you can say you know if alex is like yammering at you say alexa stop and it can stop itself right so there's some of that that inhibition um other people have already figured that out so i'm not gonna i'm not gonna retread that i'm gonna go i'm gonna go work on new stuff okay so we create our nexus which is where we're going to accumulate um thoughts and stuff so let's start with um we will go here um this is all older stuff so let me close all that um tell

CLEAR ESSAY:

==========

One possible architecture for an artificial cognitive entity is to have an outer loop with multiple mines fighting over what to do. The outer loop would take a consensus from the different mines, for example deciding whether or not to grab a hot pot. This would work because each mind would have different models, prompts, and architectures, operating at different speeds with different specializations and strengths.

If someone has dissociative identity disorder, it is possible that their brain has lost the ability to keep track of these different cells and has fragmented. This is where Jungian psychology comes into play.

Another possibility is to have multiple loops interacting with one nexus. This would be similar to the way that robotic hosts in the show Westworld have their consciousness erased of anything they're not supposed to see. This model could be used for self-censorship, for example deleting the possibility of a robot stabbing its human owner from its consciousness.

A third possibility is to have one nexus with multiple loops interacting with it. This would allow for different loops to be responsible for different tasks. For example, one loop could be responsible for safety while another loop handles self-censorship.

In order to get started coding, we can create a public experiment called "Cog Experiment 0-1". We can add a README file and a license, and then clone the project down. We can start with a medical question answering experiment, copying over the git ignore and open API key.

From there, we can create our nexus and start adding thoughts to it. We can also add a voice component so that our artificial cognitive entity can communicate with us. Once we have the basic framework in place, we can start working on more advanced features like inhibition and self-censorship.