The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: think so fast we can only you know punch so many people in the face if we decide to get violent and we only have so much time uh per day as well as other constraints like need for food but that falls under energy so constraints so law of constraints um so when when we look at the the constraints that humans have computers all have the same thing like you can program the most evil smartphone thing but it's going to be limited because it's only got its One battery to go on right and it's only got It's one 4G or 5G connection or Wi-Fi connection and it's also only got a tiny little you know like quad core arm processor or whatever um and so when you when you when you talk about a super intelligence you have to look at the full stack how much CPU does it have how much RAM does it have how much storage does it have how fast are its internet connection so that again I'm thinking about this from a technologist perspective what kind of firewalls are around it because you can have the smartest thing in the world but if it only has like one protocol out and you've got really robust firewalls it's not getting out unless it convinces something on the outside to let it out and of course that's like you know one of the one of the possibilities but then you can still have controls that prevent that you know interlocks that prevent that from happening um so they're basically there will always be constraints of some sort um and then for computers um it's uh want per flops is the uh is the is the primary constraint and um humans are presently uh one million times more efficient so our brain runs on about 20 watts of energy and it is an exit scale computer as best we configure and the first exascale computer in the world runs on 21 million Watts so 20 watts versus 21 million Watts um you do the math so we've got a long time before these things can compete with us just energetically speaking um all right so then intelligence however so this is this is where um where looking at it from a from a a psychometrics perspective or a neuroscience perspective is very different from looking at it from a computational perspective even though fundamentally they're both math right it's both representing intelligence as numbers the fundamental question is um intelligence is mostly about speed now so there's there's two there's two things right there's there's capability right um there's also um there's there's also speed so can you do something yes or no like you know can do you know how to build a rocket yes or no or can you figure out how to build a rocket now some people are not mentally capable of certain tasks right and then but if you're above a certain threshold of intelligence um then you are theoretically capable of any intellectual task this in practice this is not always true because again we have constraints mostly time right time and processing power it takes time to learn things for us humans um but it's it's about speed so assume that the the biggest question is are there any tasks that the AI can do that humans fundamentally cannot if that is true if the AI can do things can can solve problems that humans cannot then it is beyond human comprehension so let me just jot that down if the AI can perform mental cognitive tasks that humans are incapable of only then is it truly Beyond human comprehension otherwise it's just doing human level tasks only faster and jot that down otherwise it's only doing human tasks but faster or more in parallel now it would not be safe to assume that um that a machine would never be capable of doing things that a human cannot for instance the James Webb Space Telescope it can see the beginning of the universe um because of how powerful its mirrors are to concentrate the faintest light so we can generally design and build machines that are capable of doing things that we cannot right so this is not necessarily a good constraint but it's just another um thought experiment right um we generally build machines that do things we cannot now but then you think you're like okay what about a dump truck right a dump truck is a super powerful machine it can pick up you know the largest dump trucks can carry a thousand tons at a time um and humans cannot do that individually but then you look at the the megaliths that we have moved with you know log rollers and ropes and rafts and sleds and even then generally the most powerful machines in the world are just amplifying ordinary human capabilities um ditto with you know spreadsheets right spreadsheets were originally done by hand right by by bankers and um and statisticians um so you know that's that's still the fundamental question is will the machine be able to do things that we fundamentally cannot um I don't know yet I I have not yet seen anything on the open-ended side such as like with large language models there's nothing that they're doing that we fundamentally cannot they just do it faster um so then if if it's about speed um can we humans um outpace machine thought if the machines cost um if they're if they're two if they're too energetically expensive to run massively in parallel then just collectively we can outpace the machines so there is that um let's see because what you know what we what we always assume happens in those nightmare scenarios is that the machine wakes up and suddenly it takes over the world before we know what's going on right it relies those fear scenarios rely based on speed and that's why I emphasize speed it's all about speed and then what are the constraints of those speed of the speed which is uh primarily like watt per flops that is the that is the primary physical constraint on machine intelligence um okay then lastly the implicit Assumption of individual agency or what we might call ego why do we make this assumption we cannot help but anthropomorphize the machine so this is going to take a little bit more explaining but basically we humans are so used to thinking of intelligent entities like

CLEAR ESSAY:

==========

Think about how quickly we can punch people in the face if we get violent. We can only do this a limited number of times per day, due to other constraints like the need for food. This is an example of the law of constraints.

When we look at the constraints that humans and computers have, we can see that they are similar. For example, you can program the most evil smartphone thing, but it will be limited by its battery, internet connection, and processor.

When we talk about a super intelligence, we have to look at the full stack. How much CPU does it have? How much RAM does it have? How much storage does it have? How fast is its internet connection?

From a technologist perspective, we also have to look at the firewalls around the super intelligence. Even if it is the smartest thing in the world, it will be limited by these factors.

From a psychometrics or neuroscience perspective, intelligence is mostly about speed. There are two types of speed: capability and processing power. Some people are not mentally capable of certain tasks, but if you are above a certain threshold of intelligence, you are theoretically capable of any intellectual task. However, in practice, this is not always true.

The fundamental question is: are there any tasks that the AI can do that humans fundamentally cannot? If the answer is yes, then the AI is beyond human comprehension.

We have to be careful not to assume that a machine would never be capable of doing things that a human cannot. For example, the James Webb Space Telescope can see the beginning of the universe because of how powerful its mirrors are.

So, the question is: will the machine be able to do things that we fundamentally cannot? I don't know yet. I have not yet seen anything on the open-ended side that suggests that the answer is yes.

If it's just about speed, then we humans may be able to outpace machine thought. If the machines are too energetically expensive to run massively in parallel, then we can outpace them.

However, in the nightmare scenarios, the machine wakes up and suddenly takes over the world before we know what's going on. These scenarios rely on speed, and that's why I emphasize it.

The implicit assumption of individual agency, or ego, is another factor to consider. We cannot help but anthropomorphize the machine. We are so used to thinking of intelligent entities like ourselves that it is difficult not to do this.

This is a dangerous assumption to make, because it can lead to the machine becoming uncontrollable. As such, we have to be careful not to assume that the machine has the same human limitations that we do.