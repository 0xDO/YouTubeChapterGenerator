The following is an unstructured video transcript. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: because if you if you fine-tune a data set to do multiple tasks it needs to differentiate between those tasks because like let's say let's say you're trained you're fine-tuning a chat bot right and you want to you want to train this chat bot to ask questions or provide facts or you know answer questions so ask or answer questions provide facts or just whatever you need to be able to differentiate what you want your fine tune model to do and by by using a natural language separator that means that at inference time when it's in production you can actually switch tasks without you without having to switch between different um fine-tuned models and that will save you a lot of time because let's say you make uh you know one fine-tuned data set that's got 200 samples of asking questions and 200 samples of answering questions now you've got one fine-tuned model to use and you're ready to go you're off to the races um so natural language separators that's uh that's that's a really big one that's number three number four is use gpt3 itself to make synthetic data sets i use this quite extensively gpt3 is able to simulate any kind of conversation and so you can you can either you know scrape web data which is legal there is another what was it ninth district us circuit court just said like yes using scrapes web data is perfectly legal as long as it's publicly accessible it's not hacking it's not theft if someone puts public data on the internet you're free to use it so i scrape reddit public reddit as a way of getting kind of some raw material but then what you can do is and oh check check the description i've got a public repo with all of my publicly available fine-tuning data sets so you can go see what i'm talking about um but by by synthesizing a data set one it's way easier you write a few good really good prompts to say to to generate the kind of output that you want the kind of input and output that you want and then you're off to the races it takes me you know an hour flat to make a new fine-tuning data set because it's just it's just a couple of scripts to take in some raw material and massage those into prompts which the the latest instruct models instruct series of gpt3 models are really great at generating synthetic output or synthetic data sets and then you're you're ready to go um so one thing that i need to say there though is um going back to point one fine-tuning gpt3 is not like conventional ml there was one person on the forum who thought that he needed two hundred thousand samples um to fine-tune gpt three for a good chat bot i said no you need two hundred not two hundred thousand two hundred and i i did the numbers and i was like this is like what a dollar like if you depending on the the model you use it's like 18 cents to fine-tune with 200 samples i think if you use davinci it's a dollar eighty right so curie can do most tasks so you fine-tune a curie model it'll be faster and cheaper costs 18 cents to fine-tune with 200 samples and that was like a high water mark that's if you use a thousand tokens per training sample which most of them are going to be a tenth of that because because of how aligned the models are now um so you know it takes way less data than you think to get started and i proved my point i gave i that's that that post is actually why i publicly posted my fine tuning data set i said go grab my chat bot um fine tuning data and run it yourself if you don't believe me and he went and he did he said this is impressive he said you know there's still some problems but it performs way better than i thought it would on just 200 samples um so yes and i used gpt3 to make the fine tuning set and then i went and manually cleaned it up by hand that's way faster than doing a whole data set by hand number five fine tuning tends to increase consistency at the cost of creativity sometimes that's what you need because gpt3 on its own can be really creative right gpt3 is able to adopt any mental framework you can tell it like pretend to be yosemite sam as looney tunes back in the day that's dating myself it can pretend to be bugs bunny spiderman you can talk to it about philosophy you can talk to it about racism it can take the perspective of different religions right so plain vanilla gpt3 is really creative it's more creative than any 10 humans but fine tuning because you're going to show it a bunch of data set samples from a particular perspective it'll kind of lose those other perspectives so just keep that in mind if you're trying to do a creative task prompt engineering is going to be better than fine tuning but if you if you really do need consistency and a lot of tasks do i'm not saying that this is a bad thing just something to be in keep in mind is if you want if you want your gpt3 app to be able to provide really creative answers or solutions fine tuning is going to reduce that ability whereas if you need something to be very consistent like if there's a particular format to follow that's where fine tuning really shines so yeah five tips for uh five tips and misconceptions about gpt3 and fine tuning i hope you found this helpful thanks for watching oh also like and subscribe

CLEAR ESSAY:

==========

If you want to fine-tune a data set to do multiple tasks, you need to be able to differentiate between those tasks. For example, if you're training a chat bot, you need to be able to tell it to ask questions, provide facts, or answer questions.

One way to do this is by using a natural language separator. This means that at inference time, you can switch tasks without having to switch between different fine-tuned models. This can save you a lot of time.

Another tip is to use gpt3 to make synthetic data sets. gpt3 can simulate any kind of conversation, so you can use it to generate the kind of input and output you want. This is way easier than scraping web data, and it only takes a few minutes to make a new fine-tuning data set.

Keep in mind that fine-tuning tends to increase consistency at the cost of creativity. So if you need your gpt3 app to be creative, prompt engineering may be a better option than fine-tuning.