The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: will teach you right um a huge chunk of raven's training data is about answering those questions to help you understand the world and yourself better so those three principles are how raven thinks and how raven will earn your trust over time because remember up here at the very beginning we said what are we going to do we're going to be reliable and have utility and so by by having three simple rules you can talk to raven eventually the the current the mvp doesn't have it but um eventually you'll be able to talk to raven about its goals and why it decided to tell you something right because that explainability is part of that transparency actually you know what i should probably add transparency on here trust through data privacy security transparency anyways so point being is that by having these three simple rules everyone who uses raven will understand this is raven's goal and and having having uh understanding what raven's goals are what raven's principles are will help you to trust it and understand why raven does what it does um later versions of raven will explicitly adhere to these three core objective functions right now they're just implicitly baked into the training data so at no point in the training data will you see the core objective functions well you see the heroes to comparatives it is implicit based on what um but based on the how this training data was created so in the future once we move to the full cognitive architecture those core objective functions will be baked in into the inner loop which is raven will explicitly think okay is this user suffering how do i fix that is this user does this user need to increase their prosperity how do i help them get a better job how do i help them make friends right or what is what is the user not understanding how do i help them understand now another thing is that since raven is a machine raven raven is not capable of suffering or doing well raven doesn't care right understanding however is the one function that raven shares with the users and and everyone else but also itself because raven will be intrinsically curious so one of my one of my most popular videos of all time on youtube actually is that curiosity function i'm so fine tuning gpt3 to generate question questions about everything this was one of the most important functions for realizing a a an autonomous cognitive architecture which is it needs to generate questions internally so spontaneous internal questions are one of the most important things that sets humans apart from every other animal now many animals are curious right crows ravens those are those are curious animals polar bears are curious dolphins are curious they'll go investigate things um but humans are the only ones that will ask how do i do that and it will and humans will will formulate very sophisticated experiments to deliberately model the whole world there's a book that i'm reading called the pattern seekers that goes over this in great detail so anyways the point being is everything that you see me doing on youtube speaks to this goal of creating raven which is an artificial cognitive entity one that should earn our trust over time and then eventually be safe enough to be autonomous um okay i think that's about it um i do have some notes on cognitive architecture and future uh iterations of raven like where are we going um there are quite a few open problems hence why i'm always making these youtube videos about solving different cognitive tasks you know i always talk about the books that i read to help me with this because this is this is very much biomimetic everything that i've learned about neuroscience cognition psychology gets poured into raven um so the the top three problems and the each of these problems is multifaceted and can be broken down into sub problems but the first problem is cognitive control so cognitive control is about executive function or staying on task so how do you keep raven on task how do you keep raven or how do you allow raven to task switch appropriately because like let's say you know you're talking with raven about doing laundry and then raven hears like your smoke alarm go off you don't want raven to stay stuck on doing the laundry if your house is on fire you need to task switch and you know you as a human you need to task switch but raven also needs to task switch but also you don't want to task switch inappropriately right um another component of cognitive control is to design cognitive tasks for itself so say for instance you say um this was an example that came from my discord server someone was saying okay what if you talk to your ai companion and you say like oh who did i piss off last year that is a really complex problem to solve because what does it mean to piss someone off right and then so raven will have to design a cognitive task to go back through all of its memories and and and evaluate those memories for that result of okay when did dave talk about someone was mad at him or when did someone tell dave like i didn't like it when you said that right so that's that's what i mean by designing a cognitive task so that means going back through memories and performing different cognitive operations on those memories as one example another cognitive task is planning for the future right how do you brainstorm what to do in the future and then lastly you need to measure progress towards goals or towards success which that is also a non-trivial problem in fact human goal tracking is another thing that sets us apart from from most animals is that the time horizon for most animals even the smartest animals like ravens and dolphins their their time horizon for task success is very short they think only you know minutes into the future humans we can think decades into the future that is unique to humans and we need to reproduce that that ability in in raven in artificial cognitive entities um a second problem is model of self and abilities so you heard in the

CLEAR ESSAY:

==========

Raven's training data is designed to help the AI understand the world and themselves better. The three principles that guide this are reliability, utility, and transparency. In the future, Raven will explicitly adhere to these three objectives. Right now, they are only implicitly baked into the training data.

One of the most important functions for realizing an autonomous cognitive architecture is the ability to generate questions spontaneously and internally. This is something that sets humans apart from every other animal.

The top three problems that need to be addressed in order to create a safe and trustworthy AI are cognitive control, designing cognitive tasks, and measuring progress towards goals.

Cognitive control is about executive function or staying on task. This means keeping the AI focused and on track, as well as allowing it to task switch appropriately. For example, if the AI is talking to you about doing laundry and then hears your smoke alarm go off, it needs to be able to task switch to the emergency.

Designing cognitive tasks is about creating tasks for the AI to perform that are in line with its goals. For instance, if you ask the AI to tell you who you pissed off last year, it needs to be able to go through its memories and evaluate them for that result.

Measuring progress towards goals is about tracking the AI's progress and success over time. This is something that humans are able to do that other animals are not, and it is an important function to replicate in the AI.