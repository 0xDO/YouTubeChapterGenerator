The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: memory is critical now the other thing other than associative memory is temporal memory which is what the bound function is for so this allows you to say okay i've got a specific memory that i've zoomed in on now give me everything in a window like the last 60 seconds and the next 60 seconds or give me an hour's worth of memories around this critical event so that i can fully understand and reconstruct what happened so that's those are the two search methods is is associative and temporal now i've also got fetch which um says okay give me all memories that have that have um you know a field with a specific value so this will be required because um when you're dealing with the microservices you have you have every service that contributes to the nexus is going to have a service name that registers this will be really critical especially for the conductor so the conductor will need to be able to say who is talking here so the conductor will need to ask the nexus give me everything that the core objective function service is doing and so then the conductor can say hey core objective function service you're acting up or let's say that the core objective functions are trying to train themselves better so they'll they'll ask the nexus hey give me everything that um that the agent and output and input has given so that i can look at these past events and come up with better predictions for the future that sort of thing so you need to be able to to not just search for associative memories but say give me everything relevant to this particular service or a particular uuid so for the nexus send function um i have this function it'll handle the time so it'll put a timestamp on when the memory is is sent um it'll add a uuid so that every every memory has a universally unique identifier it will also add the prefix to the content so that so that in the in the message payload you've got just a little bit of context as to what this memory log is right because if you look at any log files there's going to be a lot of stuff at the beginning saying like to give you a little bit of context of like where the log came from what is the purpose of the log um and so the prefix is just going to be in every message that the the the the simulation sense so it'll be sensory input scene is this one um so that way in the nexus when um other services are looking at those memories it says oh this is an input thing i know i know what this is or um this is my you know agent model this is so i understand what i am doing um so on and so forth or output it says this is an action that i'm taking on the world um so that'll add just a little bit of natural language context to it and also one thing that you'll notice is that um we're basically getting to an abstract layer of programming where instead of everything being deterministic and functional um most of the decisions are going to be based on natural language and you're going to be blown away by this because this is an entirely new paradigm of programming and this is what i mean by artificial cognition so anyways the payload for the nexus send you add the time the uuid the content the vector so this is this is i had to go resurrect um another micro service that i worked on so i used to call it the use microservice but that's not very clear as to what it does um so it's the semantic embedding microservice um google universal sentence encoder you can do this with uh openai now but uh universal sentence encoder is both very fast and free and it's also it runs perfectly fine locally on my cpu let me actually show you what this does okay it's still running and so i have a client that'll just send a couple of things and look how fast that was 0.03 seconds to get three semantic embeddings that are 512 dimensions each um so that's stupid fast and that's faster than openai right now um so that's what that's what that's all that this service does the embedding service and so you can see that here it's also very short this is the smallest micro service you'll ever use so all it does is it loads um universal sentence encoder large version 5. it's about 100 times faster than version 4 and it produces vectors of the same size basically you send this microservice a list of strings and it'll send back a list of vectors and strings one thing that's fun is that um it uh it is uh they are um blah what am i trying to say uh they're they're json ready um so one thing is that is that numpy arrays are not json serializable um and so what i do is i just go ahead and render it out to a numpy string to a list to a string and so then you have a json object that contains a string and you can see what it looks like here so you've got uh you know the the object here where it's uh it's a string and actually since it's a list i might be able to take that out i'll do some experimentation um because uh json can handle a list of numbers so i might be able to save a step and save some processing go back to the drawing board anyways so it returns a list of dictionaries it has just the string and vector pairing and that's it and so that's all you need actually yeah i can probably i can probably take that out yeah yeah yeah yeah anyways okay so i'll just do this one little thing um actually that's gonna break a whole bunch of other stuff i'll go back to i'll go clean it all up later okay where was i i think that's actually about it so there's three micro services that i'm working on um the nexus that was the first one i gave a demonstration of how this does search earlier so one thing is by switching to 512 dimension vectors one these memories are very short so like if you look at each of these sections it's just a few sentences right we don't need a vector that is larger than this in order to do search because this is very very soft search um later on when we have more powerful machines better compression and so on yeah we can use a 10 000 uh dimension vector for every memory but right now the vectors are going

CLEAR ESSAY:

==========

There are three microservices that I am working on: the nexus, the universal sentence encoder, and the semantic embedding microservice. The nexus is responsible for search, and the other two microservices are responsible for providing context for the search results. The universal sentence encoder encodes a list of strings into vectors, and the semantic embedding microservice provides context for the encoded vectors.

The nexus uses two search methods: associative and temporal. The associative search method retrieves memories that are associated with a given input, while the temporal search method retrieves memories that are temporally close to a given input. The nexus also has a fetch method, which retrieves all memories that have a given value in a given field.

The universal sentence encoder is a fast and free microservice that encodes strings into vectors. The semantic embedding microservice provides context for the encoded vectors. It is json-ready, and it returns a list of dictionaries with string-vector pairs.