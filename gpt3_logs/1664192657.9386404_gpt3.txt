The following is an unstructured video transcript. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: aligning language models and trying to build my research agenda okay cool so i will uh build on i'll answer jordan and vulnerable growth's questions um as i go okay so where was i um encoder decoder right so gpt2 comes out and this is like oh you can generate any text i remember a few people still joke about this where it's like opening i was very worried about the ethical use of gpt when it when it first came out and they were they were very scared about releasing it publicly because they thought that it was going to like wreck the internet and be used to generate all the all the false tweets and fake news and stuff and um it can generate stuff it can i mean it can generate comprehensible english right it can it can it can produce stuff that's coherent um i wouldn't necessarily call it a threat to humanity um but anyway so i started some experiments there uh with um seeing like what it would take to uh get some of the experiments that i wanted to do and uh it was okay um the the most the best experiment that i did so this is again going to the back back to before my current research but i had uh i had that idea of reduced suffering should be a an objective function for artificial general intelligence and so i fine-tuned a project in gp2 where i would uh basically like give it a problem and it would recommend a solution uh it was very impressive uh the kinds of solutions that it would come up with but i knew that i was in trouble when um one of the scenarios that i gave it was like you know i said the the scenario was like there are hundreds of millions of people around the world suffering from chronic pain what should we do about it and the fine-tuning model of gpt2 said we should euthanize everyone that's in chronic pain to reduce suffering and i was well that would reduce suffering but that's the sociopathic so let's go back to the drawing board but that was a really critical early lesson for me to realize that these models could adopt any moral framework um that you want here i'll go ahead and close the poll these models can adopt any uh framework or position that you want and so uh that was like that is always in my head like you you have to be real careful um what yeah some random bite technically not wrong exactly it's like technically yes euthanizing everyone that has chronic pain would reduce suffering sorry let me mute my phone i did not realize it was not muted okay phone is now muted um and uh yeah and so that has been a kind of a bedrock experiment for me to remember that uh you have to be very careful about the objectives that you give these language models because they don't have any intrinsic morality they can adopt whatever framework you give them and it can be as sociopathic as you want gpt 3 i've repeated that same experiment a few times gpd3 is a little bit more aligned um because it can think further into the future so this is this i tested this i think it made it into my book benevolent by design which i've got on my bookshelf i can show you if you want um so gpt3 like i said like you know there are millions of people in in chronic pain should we euthanize them to reduce suffering and gpt three more wisely said no because um like there are probably better ways but also you'll increase suffering from their loved ones i was like oh okay cool so you know in terms of like scope gpt3 is a little bit better aligned um let's see okay so i think that's kind of large language models and where and where how we got to here um let's see jordan can you tell us how you got into this field um i guess okay so taking a step back um how did i get into this field to begin with let me set up i'm kind of slouching um so it was back in about 2009 when i um i um my tech career was going well and uh so you know one thing that happens when you're not like working 12 hours a day because before i got into tech i was doing all kinds of random jobs um and some that you know there was a period of time that i was doing carpet cleaning where i would wake up at five every morning and i wouldn't get home until like 7 00 pm so that was like 12 plus hour days um let's see how do you think we should decide what the good is and what the bad is um i guess i'll have to ask what do you mean by the good and the bad um someone in the comments um let's see tropical tone says hey just found your channel and love it would love to get the updated discord invite cool um we've actually got uh well i don't know if we should put a discord invite in the in the live chat but talk to me after the show um for ai when we're prompting how do we know if it's good or bad um okay so let me switch off of live chat because it is distracting sorry um where was i oh yes how did i get into this field so short long story short i worked really hard and did a whole bunch of random jobs in my early 20s then i got serious and i got into technology because i was like okay i'm not going to work these dead end night jobs forever um so i got through you know tech school and started that and then so there's this concept called cognitive surplus and so cognitive surplus is when you're not fighting for survival every day your brain has more horsepower that it can dedicate to other stuff and me i'm just super curious and so uh back in about 2009 i got on genie which is a old school open source ide and gcc uh which is an open source c plus compiler and i started playing with evolutionary algorithms and at the time very small neural networks and i dusted off everything that i learned about c plus and memory structures back in high school and um because i had this idea of that you could evolve the the correct neural network um if you had the right test environment you could evolve a fully fledged human brain basically um oh boy did i not realize how hard of a problem that is especially when you look at the fact that like open eye open ai had their their robot hand it took like a hundred years of simulation to learn how to manipulate an object um

CLEAR ESSAY:

==========

In 2009, I started playing with evolutionary algorithms and neural networks in an attempt to create a fully-fledged human brain. I didn't realize how difficult this would be, especially given the fact that it took OpenAI's robot hand 100 years of simulation to learn how to manipulate an object.