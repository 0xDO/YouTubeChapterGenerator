The following is an unstructured video transcript by David Shapiro. Please rewrite this as a more structured, clear essay.

TRANSCRIPT: morning everybody David Shapiro here with your daily state of the industry address okay so this is going to be a doozy there's a lot going into this so what am I talking about I'm talking about gpus and AI art and large language models that is kind of you know that's my schtick but got to zoom out Take the Long View take the take the take the macro View so some folks are worried that China will invade Taiwan and what does this have to do with anything well part of the price of gpus is supply chain but also where chips are made so if China invades Taiwan then there's likely to be a large disruption to chip manufacturers um now that doesn't mean that gpus are going to be affected but other chips might be etc etc so some good news here the Pentagon says that China will not invade Taiwan in the next two years so we've got to reprieve their if it's accurate who knows um the U.S Department of Defense puts a lot of attention on China um there is they they publish a a a military report every year about China's capabilities and what they expect is Gonna China is going to be able to do and I read that every now and then um anyways so no disruption there hopefully cross your fingers um still there is some cold war escalation happening U.S bars Advanced Tech firms and this is only federally funded it's not all Tech firms from building China factories for 10 years so clearly something is going on behind the scenes in terms of what the U.S expects um China to do um I I saw in in the immediate aftermath of this some people uh suspect that this could backfire because it'll Force China to build their own AI chip tech companies and then they might do it better than us who knows um and similar news uh U.S officials order Nvidia to Halt sales to top of uh top AI chips to China it's all in the same same bar right um so who knows what's going on but in the long run hopefully one of the results of this is that um we're less dependent on a single source of chips such as Taiwan um and then we also have more access to GPU and other AI Hardware because one of the biggest constraints right now in our field ours being large language models and Transformers in general is access to Affordable Hardware in order to run these things um so another thing that could help this is uh ethereum has switched has completed the merge which they're going from proof of work to proof of stake I'll post a link if you want to understand that a little bit better but the short version is that GPU mining is kaput for ethereum now obviously ethereum is not the only cryptocurrency but it is the largest and this move comes in the wake of a lot of uh States and Nations and cities just flat out Banning cryptocurrency mining um and like there have been uh cases where there's just like racks and racks and racks of used gpus for sale because suddenly the demand for the gpus is gone now this makes sense from a uh from an environmental policy standpoint because um the amount of power being consumed for cryptocurrency mining was ludicrous um so that's just it was an irresponsible decision to make Bitcoin and ethereum and all these things require just tremendous amounts of juice to mine um so I definitely agree with this but also what it will do is it will allow the market to correct and allow gpus to be bought and used for things that gpus ought to be bought for and used for such as actual gaming if you're a gamer there's a while where like you know every time Nvidia came out with a new um GPU they were all bought up within literally within seconds of hitting like um Newegg and eBay and whatever else and they were being bought by um by Bots actually and the prices were being bit up to double and triple their their market value so that was absurd and it was frustrating but now you can actually get gpus just walk into your you know your local computer store and buy one off the shelf because they're no longer just you know the supply chain is is is being fixed um so why am I bringing this up though Bloom is the latest open source uh model and it is roughly equivalent to gpt3 um 176 billion parameters um and let's see it takes depending on how you deploy it it takes 768 gigabytes of GPU Ram or 352 at half Precision I'm wondering if people do the um distill it down to end eight if you could cut that in half again and get it down to what's that 175 gig of RAM that's still a lot bigger than than any of us can afford right now but with with um uh ongoing refinement and also availability of more data center grade gpus so here's the thing you know I've got a I've got an Nvidia RTX 2070 in my computer it's getting old but it's big enough you know it's got eight gig of RAM it's big enough to run some smaller models um but you know maybe in a year or two if I keep this up um I'll be able to get you know something a little bit bigger or a pair of things that are a little bit bigger and I'll be able to run something like Neo X locally so Neo X it looks like for inference um this this helpful blog says that Neo X took about 40 gigabytes across two gpus so that's you know you get two 24 gig gpus which that's going to be within reach soon um we can start running these at full bore locally without having to pay um for uh for apis um which that's going to do a lot for security so one of the biggest things um and I did see that that Microsoft azure if you use if you use large language models on Azure they are actually HIPAA compliant that is a big concern that a lot of people have so um when I when I tested out Forefront they have a very simple ability to just turn off logging right but that does just because you can turn off logging does not mean that it is like HIPAA compliant or part 11 compliant or compliant with any other privacy uh regulations um still it's a step in the right direction so getting certified in in all those all those compliances um like ISO 27k um all those all those fun things that's going to be a big thing now having worked in technology for a

CLEAR ESSAY:

==========

The state of the industry is rapidly changing, particularly in the area of GPUs and AI. There are a number of factors influencing the current landscape, from political tensions to advances in technology. Here's a look at some of the key points to keep in mind.

One of the biggest concerns right now is the potential for a disruption to the supply chain of GPUs. This is due to the ongoing tension between the US and China, as well as the possibility of China invading Taiwan. While the Pentagon has said that an invasion is unlikely to happen in the next two years, it's still a possibility that could have a major impact on the availability of GPUs.

In response to the tensions, the US has barred Advanced Tech firms from building China factories for 10 years. This is likely to force China to develop its own AI chip technology, which could lead to them becoming a major competitor in the market. In addition, US officials have ordered Nvidia to halt sales of its top AI chips to China.

Another factor influencing the landscape is the recent switch from proof of work to proof of stake by Ethereum. This change has effectively ended GPU mining for Ethereum, which could lead to a decrease in demand for GPUs. However, it also provides an opportunity for the market to correct itself and for GPUs to be used for their intended purpose, such as gaming.

Bloom, the latest open source model, is roughly equivalent to GPT3. It takes up 768 gigabytes of GPU RAM, which is a lot bigger than any of us can afford right now. However, with ongoing refinement and the availability of more data center-grade GPUs, it may soon be possible to run these models locally.

The state of the industry is rapidly changing and there are a number of factors to keep an eye on. From political tensions to advances in technology, it's important to stay up-to-date on the latest developments.